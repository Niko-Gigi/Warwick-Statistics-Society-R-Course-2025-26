[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Warwick Statistics Society R Course 2025-2026",
    "section": "",
    "text": "R is a very popular coding language, primarily used by statisticians around the world. As such, it is important for new statisticians (or those who will require substantial statistics in their degrees/jobs) to get to grips with the language. This website and the attached Github aim to cover the key steps from first lines of code after you have installed R, to how to fit linear models and perform Explanatory Data Analysis (EDA).\nThis Github was created for the Warwick Statistics Society’s R course. It accompanies the 2 core Warwick R modules: ST117 Introduction to Statistical Modelling and ST221 Linear Statistical Modelling. While I (Nikoloz) have revamped this R course, the foundational work was set by my predecessor, Maria-Louiza Van den Bergh, who originally compiled this Github. The course builds off of the work by previous R Course Coordinators: Neel Shah, Mia Carla Chapman, and Viresh Shah.\nIf you find any corrections, or believe a section would benefit from more explanations, please do reach out and email me 1.\n\n\n\nQR code for website",
    "crumbs": [
      "Home",
      "Welcome"
    ]
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Using R",
    "section": "",
    "text": "Accessing R\nPlease ensure that you have access to R. This can be a local version on your computer (Warwick download link) or online.\nIf you have a local version, it is also worth downloading an IDE (integrated development envrionment). I personally use RStudio.\n\n\nCreating a new document\nThere are many possible files that you can create in R. The simplest is to create an R script. This allows you to write code, run code and produce output. You can also annotate your code through comments by writing # and then adding any relevant text.\nAlternatively, you can create an R Markdown file. This combines chunks of R code with normal text. Thus, you can create lovely reports that blend code output (e.g. figures and tables) with analysis. RStudio has created a detailed guide available here on how to use an R Markdown file.\n\n\nR Studio and R Markdown\nThe following are two cheatsheets produced by R Studio on using their software.\n(If the files are not loading, there also available on the GitHub under the Cheatsheets folder link.)"
  },
  {
    "objectID": "index.html#general-structure",
    "href": "index.html#general-structure",
    "title": "Warwick Statistics Society R Course 2024-2025",
    "section": "",
    "text": "Each section begins with a Welcome that indicates what will be covered by the section. There are then several subsections that cover theory and code examples.\nKey functions appear in purple text like this function(). Longer passages of code appear inside grey boxes with comments denoted using ###| and #. For some code examples, you are able to scroll left and right to see the entire code (this is typically for comments). The code can be hidden or shown by clicking on the triangle (\\(\\triangleright\\)). By default, all code examples are shown and any answers are hidden.\nThe entire code can be copied to the clipboard using the icon in the right corner. Please note that the ```{r} and ``` are used to create code chunks. These are not needed in an R Script or if the code is being copied into an already existing code chunk in an R Markdown or Quarto document.\nFinally, there will be several ‘Check you understanding’ subsections. Answers to these questions (and the code used to produce them) are available just below the questions. However, I strongly recommend you attempt to answer them before reviewing the solutions!\nThe sections of this github cover the following material:\n\n\nThis first section, titled “R-course - Introduction to R”, covers operations, variables, data types and data structures.\nThe second section, titled “R-course - Control structures and functions”, covers if, while and for loops. It also teaches you how to write your own functions.\nThe third section, titled “R-course - Random variables and Plotting”, covers how to generate a random number and how to plot various graphs using base R commands.\nThe fourth and fifth sections, titled “R-course - Linear modelling” and “R-course - Linear modelling assumptions” respectively, cover what a linear model is, how to fit a linear model on categorical and numerical data and how to ensure a linear model meets the necessary assumptions.\n\n\nThe necessary data for this github can be found in the Datasets folder. There is guidance in the relevant sections on how to load in data.\nPlease note that future sections aim to include: model selection; time series modelling; generalised linear modelling; exploratory data analysis; using the ggplot2 package to produce figures; and using the kableExtra and dplyr packages to produce tables. Time permitting, these will be created for the 2024/25 R course and aim to go alongside ST404 Applied Statistical Modelling and provide additional support for ST346 Generalised Linear Models."
  },
  {
    "objectID": "index.html#accessing-r",
    "href": "index.html#accessing-r",
    "title": "Warwick Statistics Society R Course 2024-2025",
    "section": "",
    "text": "Please ensure that you have access to R. This can be a local version on your computer (Warwick download link) or online.\nIf you have a local version, it is also worth downloading an IDE (integrated development envrionment). I personally use RStudio."
  },
  {
    "objectID": "index.html#creating-a-new-document",
    "href": "index.html#creating-a-new-document",
    "title": "Warwick Statistics Society R Course 2024-2025",
    "section": "",
    "text": "There are many possible files that you can create in R. The simplest is to create an R script. This allows you to write code, run code and produce output. You can also annotate your code through comments by writing # and then adding any relevant text.\nAlternatively, you can create an R Markdown file. This combines chunks of R code with normal text. Thus, you can create lovely reports that blend code output (e.g. figures and tables) with analysis. RStudio has created a detailed guide available here on how to use an R Markdown file."
  },
  {
    "objectID": "index.html#footnotes",
    "href": "index.html#footnotes",
    "title": "Warwick Statistics Society R Course 2025-2026",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nMy University of Warwick email is: niko.gigiberia@warwick.ac.uk.↩︎",
    "crumbs": [
      "Home",
      "Welcome"
    ]
  },
  {
    "objectID": "about.html#creating-a-new-document",
    "href": "about.html#creating-a-new-document",
    "title": "Using R",
    "section": "",
    "text": "There are many possible files that you can create in R. The simplest is to create an R script. This allows you to write code, run code and produce output. You can also annotate your code through comments by writing # and then adding any relevant text.\nAlternatively, you can create an R Markdown file. This combines chunks of R code with normal text. Thus, you can create lovely reports that blend code output (e.g. figures and tables) with analysis. RStudio has created a detailed guide available here on how to use an R Markdown file."
  },
  {
    "objectID": "Intro.html",
    "href": "Intro.html",
    "title": "Intro to R",
    "section": "",
    "text": "These pages will cover will introduce some key theory about how R operates and the basic building blocks of coding. It ends with generating plots using inbuilt R commands.\nThis section covers: :::{} * how R stores data/values (data types, data structures and variables), * how to perform operations (arithmetic, comparison and logical), * how to control the structure of your code (if, else, for and while), * how to write your own functions, * random numbers, and * plotting graphs."
  },
  {
    "objectID": "Intro.html#what-data-type-is-this-variable",
    "href": "Intro.html#what-data-type-is-this-variable",
    "title": "Intro to R",
    "section": "What data type is this variable?",
    "text": "What data type is this variable?\nWe can check what data type a variable is using class(). Alternatively, we can confirm if a variable is an integer, logical or a character using is.integer(), is.logical() and is.character() respectively.\n\n\nCode\n```{r}\n###| Character\ncharacter &lt;- \"a banana\"\n\nclass(character)\nis.character(character)\n\n###| Numeric v integer\nnumber &lt;- 5\ninteger &lt;- as.integer(5)\n\nclass(number)\nis.integer(number)\n\nclass(integer)\nis.integer(integer)\n\n###| Decimal value\ndecimal &lt;- 0.5\n\nclass(decimal)\nis.integer(decimal)\n\n###| Logical value\nis.logical(TRUE)\nis.logical(FALSE)\n```\n\n\n[1] \"character\"\n[1] TRUE\n[1] \"numeric\"\n[1] FALSE\n[1] \"integer\"\n[1] TRUE\n[1] \"numeric\"\n[1] FALSE\n[1] TRUE\n[1] TRUE"
  },
  {
    "objectID": "Intro.html#coercion-changing-data-type",
    "href": "Intro.html#coercion-changing-data-type",
    "title": "Intro to R",
    "section": "Coercion (changing data type)",
    "text": "Coercion (changing data type)\nWe can force a variable to switch data type using as.numeric(), as.logical(), as.character() and as.integer().\n\n\nCode\n```{r}\n###| Coercing a boolean variable\nas.numeric(TRUE)\nas.numeric(FALSE)\nas.character(TRUE)\nas.character(FALSE)\n```\n\n\n[1] 1\n[1] 0\n[1] \"TRUE\"\n[1] \"FALSE\"\n\n\n\n\nCode\n```{r}\n###| Coercing a character variable\nas.numeric(\"a\") # this will produce an error!\n```\n\n\nWarning: NAs introduced by coercion\n\n\n[1] NA\n\n\n\n\nCode\n```{r}\n###| Coercing a character variable\nas.character(\"a\")\n\n###| Coercing a numeric variable\nas.numeric(2) \nas.character(2)\n\n###| Coercing to a logic variable\nas.logical(1)\nas.logical(0)\n\nas.logical(\"TRUE\")\nas.logical(\"FALSE\")\n```\n\n\n[1] \"a\"\n[1] 2\n[1] \"2\"\n[1] TRUE\n[1] FALSE\n[1] TRUE\n[1] FALSE"
  },
  {
    "objectID": "Intro.html#check-your-understanding",
    "href": "Intro.html#check-your-understanding",
    "title": "Intro to R",
    "section": "Check your understanding",
    "text": "Check your understanding\nThe following will test your understanding of all of the main data structures in R.\nQuestion 1\n\n\nCreate a nums vector which contains the numbers from 50 to 100 inclusive. Now create a new vector, numsEven, which indicates which elements are even using nums.\n\n\n\n\nCode\n```{r}\n#| code-fold: true\n###| Answer\n\nnums &lt;- c(50:100)\nnums\n\nnumsEven &lt;- nums[seq(from = 1, to = 51, by = 2)]\nnumsEven\n```\n\n\n [1]  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68\n[20]  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87\n[39]  88  89  90  91  92  93  94  95  96  97  98  99 100\n [1]  50  52  54  56  58  60  62  64  66  68  70  72  74  76  78  80  82  84  86\n[20]  88  90  92  94  96  98 100\n\n\nQuestion 2 :::{} * Consider a gambler, with casino winnings from Monday to Friday defined as: + poker_vector &lt;- c(140,-50,20,-120,240) + roulette_vector &lt;- c(-24,-50,100,-350,10) + days_vector &lt;- c(“Monday”,“Tuesday”,“Wednesday”,“Thursday”,“Friday”) + names(poker_vector) &lt;- days_vector + names(roulette_vector) &lt;- days_vector * Calculate the following statistics and print total_daily and total_week: + daily earnings: total_daily + total poker winnings: total_poker + total roulette winnings: total_roulette + total winnings overall: total_week :::\n\n\nCode\n```{r}\n#| code-fold: true\n###| Answer\npoker_vector &lt;- c(140,-50,20,-120,240)\nroulette_vector &lt;- c(-24,-50,100,-350,10)\ndays_vector &lt;- c(\"Monday\",\"Tuesday\",\"Wednesday\",\"Thursday\",\"Friday\")\nnames(poker_vector) &lt;- days_vector\nnames(roulette_vector) &lt;- days_vector\n\ntotal_daily &lt;- poker_vector + roulette_vector\ntotal_poker &lt;- sum(poker_vector)\ntotal_roulette &lt;- sum(roulette_vector)\n\ntotal_week &lt;- total_poker + total_roulette\ntotal_week_2 &lt;- sum(total_daily)\n\ntotal_daily\ntotal_week\ntotal_week_2\n```\n\n\n   Monday   Tuesday Wednesday  Thursday    Friday \n      116      -100       120      -470       250 \n[1] -84\n[1] -84\n\n\nQuestion 3 :::{} * The sum of squares of the first ten natural numbers is \\(385\\). The square of the sum of the first ten natural numbers is \\(55^2 = 3025\\). Hence the difference between the sum of the squares of the first ten natural numbers and the square of the sum of the first ten natural numbers is \\(3025 - 385 = 2640\\). * Write R code to check this. * Find the difference between the sum of the squares of the first 100 natural numbers and the square of the sum of the first 100 natural numbers. :::\n\n\nCode\n```{r}\n#| code-fold: true\n###| Answer\nten &lt;- c(1:10)\nsum_of_squares_10 &lt;- sum(ten^2)\nsquare_of_sums_10 &lt;- sum(ten)^2\n\ndifference_10 &lt;- square_of_sums_10 - sum_of_squares_10\ndifference_10\n\nhundred &lt;- c(1:100)\nsum_of_squares &lt;- sum(hundred^2)\nsquare_of_sums &lt;- sum(hundred)^2\n\ndifference &lt;- square_of_sums - sum_of_squares\ndifference\n```\n\n\n[1] 2640\n[1] 25164150\n\n\nQuestion 4\n\n\nThe following vectors represent the box office numbers from the first three Star Wars movies. The first element for each vector corresponds to the US box office revenue and the second element represent the non-US box office revenue.\n\nNew_hope &lt;- c(460.998, 314.4)\nEmpire_strikes &lt;- c(290.475, 247.900)\nReturn_jedi &lt;- c(309.306, 165.8)\n\nConstruct a matrix, star_wars_matrix, with one row for each movie. The first column should be the US revenue and the second the non-US revenue.\nCalculate the US and non-US revenue.\nWhich movie generated the most revenue?\n\n\n\n\nCode\n```{r}\n#| code-fold: true\n###| Answer\nNew_hope &lt;- c(460.998, 314.4)\nEmpire_strikes &lt;- c(290.475, 247.900)\nReturn_jedi &lt;- c(309.306, 165.8)\n\nstar_wars_matrix &lt;- matrix(data = c(New_hope, Empire_strikes,Return_jedi), ncol = 2, nrow = 3, byrow = TRUE)\n\nUS_revenue &lt;- sum(star_wars_matrix[,1])\nnon_US_revenue &lt;- sum(star_wars_matrix[,2])\n\nUS_revenue\nnon_US_revenue\n```\n\n\n[1] 1060.779\n[1] 728.1\n\n\nQuestion 5\n\n\nDefine the following vectors\n\nplanets &lt;- c(“Mercury”,“Venus”,“Earth”,“Mars”,“Jupiter”,“Saturn”,“Uranus”,“Neptune”)\ntype &lt;- c(“Terrestrial planet”,“Terrestrial planet”,“Terrestrial planet”,“Terrestrial planet”,“Gas giant”,“Gas giant”,“Gas giant”,“Gas giant”)\ndiameter &lt;- c(0.382,0.949,1,0.532,11.209,9.449,4.007,3.883)\nrings &lt;- c(FALSE,FALSE,FALSE,FALSE,TRUE,TRUE,TRUE,TRUE)\n\nCreate a dataframe from these vectors\nThe dataframe is unclear. Add the units to the diameter header.\nPrint the information of the planets who have rings.\nAdd additional column to indicate which planet has humans.\n\n\n\n\nCode\n```{r}\n#| code-fold: true\n###| Answer\nplanets &lt;- c(\"Mercury\",\"Venus\",\"Earth\",\"Mars\",\"Jupiter\",\"Saturn\",\"Uranus\",\"Neptune\")\ntype &lt;- c(\"Terrestrial planet\",\"Terrestrial planet\",\"Terrestrial planet\",\"Terrestrial planet\",\"Gas giant\",\"Gas giant\",\"Gas giant\",\"Gas giant\")\ndiameter &lt;- c(0.382,0.949,1,0.532,11.209,9.449,4.007,3.883)\nrings &lt;- c(FALSE,FALSE,FALSE,FALSE,TRUE,TRUE,TRUE,TRUE)\n\ndf &lt;- data.frame(\"planets\" = planets,\n                 \"type\" = type,\n                 \"diameter\" = diameter,\n                 \"rings\" = rings)\n\nnames(df$diameter) &lt;- \"diameter, as a fraction of Earth's\"\n\ndf[which(df$type == \"Gas giant\"),]\n\ndf$humans &lt;- c(0,0,1,0,0,0,0,0)\n```\n\n\n  planets      type diameter rings\n5 Jupiter Gas giant   11.209  TRUE\n6  Saturn Gas giant    9.449  TRUE\n7  Uranus Gas giant    4.007  TRUE\n8 Neptune Gas giant    3.883  TRUE"
  },
  {
    "objectID": "Intro.html#vectors",
    "href": "Intro.html#vectors",
    "title": "Intro to R",
    "section": "Vectors",
    "text": "Vectors\nA vector is a one-dimensional sequence of data elements of the same type. We create a vector using c().\n\n\nCode\n```{r}\n###| Examples of vectors\nc(\"S\",\"T\",\"A\",\"T\",\"S\")\nc(1,2,3,4,5)\nc(1:5) # will output the same as before!\nc(1,2,\"A\")\n```\n\n\n[1] \"S\" \"T\" \"A\" \"T\" \"S\"\n[1] 1 2 3 4 5\n[1] 1 2 3 4 5\n[1] \"1\" \"2\" \"A\"\n\n\n\n\n\n\n\n\nNote\n\n\n\nAs we see in the last example, if we mix data types, the vector will default to storing all entries as characters!\n\n\n\nVectors: Arithmetic\nWe can apply arithmetic to vectors. We can multiple, add and subtract vectors.\n\n\nCode\n```{r}\n###| Vector arithmetic\nx &lt;- c(1,2,3)\n\nx + 3\nx * 3\nx * x\n```\n\n\n[1] 4 5 6\n[1] 3 6 9\n[1] 1 4 9\n\n\n\n\nVectors: Sequences and repetition\nWe can generate vectors using seq() and rep() to generate a sequence or repeat a value.\n\n\nCode\n```{r}\n###| Sequence 1\n\n# by will create a vector where each subsequent value is 0.1 larger than the previous\nseq(from = 0, to = 1, by = 0.1) \n\n# length.out will ensure 4 values are stored in the vector\nseq(from = 0, to = 1, length.out = 4) \n```\n\n\n [1] 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0\n[1] 0.0000000 0.3333333 0.6666667 1.0000000\n\n\n\n\nCode\n```{r}\n###| Sequence 2\n\nseq(from = 0, to = 10, by = 2.7) # note that 10 is not in this vector!\n\nseq(from = 0, to = 10, length.out = 4) \n```\n\n\n[1] 0.0 2.7 5.4 8.1\n[1]  0.000000  3.333333  6.666667 10.000000\n\n\n\n\nCode\n```{r}\n###| Repeat\nrep(1,6)\n\nrep(1:3,each = 2) # will repeat each value twice\n\nrep(1:3,2) # will repeat the entire 1:3 twice\n\nrep(1:3,length.out=6) # will repeat 1:3 until it reaches the length.out\n\nrep(1:3,length.out=5) # note that this is only 5 long and so only has one 3!\n```\n\n\n[1] 1 1 1 1 1 1\n[1] 1 1 2 2 3 3\n[1] 1 2 3 1 2 3\n[1] 1 2 3 1 2 3\n[1] 1 2 3 1 2\n\n\n\n\nVectors: Indexing\nYou can extract data from a vector if you know it’s index (for example, you can extract the 5th value of a vector) using [].\nWe can extract 1 element at a time (see the first example) or we can extract multiple elements at once using vectors (see the second and third examples). We can also extract using a variable (fourth example).\n\n\nCode\n```{r}\n###| Indexing\nx &lt;- c(1,2,3,4,5)\n\nx[3] # extracts the 3rd element\nx[1:3] # extracts elements 1, 2 and 3\nx[c(1,3,5)] # extracts elements 1, 3 and 5\n\n###| Indexing with a named vector\ny &lt;- c(2,4)\nx[y] # extracts elements 2 and 4\n```\n\n\n[1] 3\n[1] 1 2 3\n[1] 1 3 5\n[1] 2 4\n\n\nYou can change the values of a vector using indexes as well.\n\n\nCode\n```{r}\n###| Changing an element\nx &lt;- c(1,2,3,4,5)\n\nx[1] &lt;- 7\nx\n```\n\n\n[1] 7 2 3 4 5\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe number of replacing values must match the number of replaced values, otherwise there is an error (see next example)!\n\n\n\n\nCode\n```{r}\n###| Mismatch in replacement length\nx[2] &lt;- c(1,3)\n```\n\n\nWarning in x[2] &lt;- c(1, 3): number of items to replace is not a multiple of\nreplacement length\n\n\nCode\n```{r}\nx # only the 1st element is used to replace the 2nd value\n```\n\n\n[1] 7 1 3 4 5\n\n\nYou can also remove an element from a vector using [- ].\n\n\nCode\n```{r}\n###| Changing an element\nx &lt;- c(1,2,3,4,5)\nx[-1] \n```\n\n\n[1] 2 3 4 5\n\n\n\n\nVectors: Check your understanding\nTo practise sequences and repetition, do the following exercises.\n\n\nCreate a vector from 0 to 100.\nCreate a vector from 100 to 0.\nCreate a vector containing all strictly positive even numbers up to and including 100.\nCreate a vector containing 1 once, 2 twice and 3 thrice, in that order.\n\n\n\n\nCode\n```{r}\n#| code-fold: true\n\n###| Answers\nseq(from = 0, to = 100)\nseq(from = 100, to = 0)\nseq(from = 0, to = 100, by = 2)\n\nrep(1:3,1:3)\n```\n\n\n  [1]   0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n [19]  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n [37]  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n [55]  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n [73]  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n [91]  90  91  92  93  94  95  96  97  98  99 100\n  [1] 100  99  98  97  96  95  94  93  92  91  90  89  88  87  86  85  84  83\n [19]  82  81  80  79  78  77  76  75  74  73  72  71  70  69  68  67  66  65\n [37]  64  63  62  61  60  59  58  57  56  55  54  53  52  51  50  49  48  47\n [55]  46  45  44  43  42  41  40  39  38  37  36  35  34  33  32  31  30  29\n [73]  28  27  26  25  24  23  22  21  20  19  18  17  16  15  14  13  12  11\n [91]  10   9   8   7   6   5   4   3   2   1   0\n [1]   0   2   4   6   8  10  12  14  16  18  20  22  24  26  28  30  32  34  36\n[20]  38  40  42  44  46  48  50  52  54  56  58  60  62  64  66  68  70  72  74\n[39]  76  78  80  82  84  86  88  90  92  94  96  98 100\n[1] 1 2 2 3 3 3"
  },
  {
    "objectID": "Intro.html#lists",
    "href": "Intro.html#lists",
    "title": "Intro to R",
    "section": "Lists",
    "text": "Lists\nA list is a one-dimensional sequence of data of different types. Each element of a list can be of different dimensions and types.\nWe start a list using the list() command.\n\n\n\n\n\n\nNote\n\n\n\nIt is important to be careful with indexing for lists. As lists can contain multiple levels, we use [[]] for the first index and then [] for the second.\n\n\n\n\nCode\n```{r}\n###| Example list\nx &lt;- list(c(1,2,3),\n          100,\n          c(TRUE,FALSE,TRUE),\n          list(\"a\",\"b\",\"c\"))\n\nx[3] # Returns the 3rd element of the list\nx[[3]] # Returns the 3rd element of the list\nx[[3]][2] # Returns 2nd element of the 3rd element of the list\nx[3][2] # Empty!\n```\n\n\n[[1]]\n[1]  TRUE FALSE  TRUE\n\n[1]  TRUE FALSE  TRUE\n[1] FALSE\n[[1]]\nNULL\n\n\nWe can also replace elements in a list and and elements to a list using append().\n\n\nCode\n```{r}\n###| Replacing \nx &lt;- list(c(1,2,3),\n          100,\n          c(TRUE,FALSE,TRUE),\n          list(\"a\",\"b\",\"c\"))\n\nx[[2]] &lt;- c(27,29)\nx\n```\n\n\n[[1]]\n[1] 1 2 3\n\n[[2]]\n[1] 27 29\n\n[[3]]\n[1]  TRUE FALSE  TRUE\n\n[[4]]\n[[4]][[1]]\n[1] \"a\"\n\n[[4]][[2]]\n[1] \"b\"\n\n[[4]][[3]]\n[1] \"c\"\n\n\n\n\nCode\n```{r}\n###| Append\nappend(x, values = c(\"m\",\"n\"))\n```\n\n\n[[1]]\n[1] 1 2 3\n\n[[2]]\n[1] 27 29\n\n[[3]]\n[1]  TRUE FALSE  TRUE\n\n[[4]]\n[[4]][[1]]\n[1] \"a\"\n\n[[4]][[2]]\n[1] \"b\"\n\n[[4]][[3]]\n[1] \"c\"\n\n\n[[5]]\n[1] \"m\"\n\n[[6]]\n[1] \"n\"\n\n\nHowever, it is again important that we make these changes very carefully to avoid errors as there are 2 layers in indexing.\n\n\n\n\n\n\nNote\n\n\n\nWe can find the number of elements in the first level of the list using length() (i.e. how many different things are in the list). We can find the total number of elements within each first level element of the list using lengths().\n\n\n\n\nCode\n```{r}\n###| Lengths of a list\nx &lt;- list(c(1,2,3),\n          100,\n          c(TRUE,FALSE,TRUE),\n          list(\"a\",\"b\",\"c\"))\n\nlength(x)\nlengths(x)\n```\n\n\n[1] 4\n[1] 3 1 3 3"
  },
  {
    "objectID": "Intro.html#matrix",
    "href": "Intro.html#matrix",
    "title": "Intro to R",
    "section": "Matrix",
    "text": "Matrix\nA matrix is a 2 dimensional storage of data of the same type. We create a matrix using the matrix() command.\n\n\nCode\n```{r}\n###| Example matrix\nmatrix(data = c(1:9), nrow = 3, ncol = 3)\n```\n\n\n     [,1] [,2] [,3]\n[1,]    1    4    7\n[2,]    2    5    8\n[3,]    3    6    9\n\n\n\n\n\n\n\n\nNote\n\n\n\nBy default, a matrix is filled column-wise first, then row. Using byrow=TRUE inside the matrix() function will switch this to filling row-wise first.\n\n\n\n\nCode\n```{r}\n###| Example matrix\nmatrix(data = c(1:9), nrow = 3, ncol = 3, byrow=TRUE)\n```\n\n\n     [,1] [,2] [,3]\n[1,]    1    2    3\n[2,]    4    5    6\n[3,]    7    8    9\n\n\n\n\n\n\n\n\nNote\n\n\n\nIt is very important to ensure the number of columns and rows is correct!\n\n\n\n\nCode\n```{r}\n###| Errors in matrix \nmatrix(c(1,2,3), nrow = 1, ncol=2) \n```\n\n\nWarning in matrix(c(1, 2, 3), nrow = 1, ncol = 2): data length [3] is not a\nsub-multiple or multiple of the number of columns [2]\n\n\n     [,1] [,2]\n[1,]    1    2\n\n\nAs with vectors and lists, we can select only some elements of a matrix using indexing.\n\n\nCode\n```{r}\n###| Matrix indexing\nx &lt;- matrix(data = c(1:9), nrow = 3, ncol = 3)\n\nx[1,]\nx[1,2]\nx[6]\n```\n\n\n[1] 1 4 7\n[1] 4\n[1] 6\n\n\nAs with vectors, we can perform arithmetic operations of matrices, assuming that the dimensions are correct. Not that for matrix multiplication, we use %\\*%.\n\n\nCode\n```{r}\n###| Matrix arithmetic\nx &lt;- x &lt;- matrix(data = c(1:9), nrow = 3, ncol = 3)\n\nx + 3\nx * 3\nx * x     # entry wise multiplication\nx %*% x   # matrix multiplication\n```\n\n\n     [,1] [,2] [,3]\n[1,]    4    7   10\n[2,]    5    8   11\n[3,]    6    9   12\n     [,1] [,2] [,3]\n[1,]    3   12   21\n[2,]    6   15   24\n[3,]    9   18   27\n     [,1] [,2] [,3]\n[1,]    1   16   49\n[2,]    4   25   64\n[3,]    9   36   81\n     [,1] [,2] [,3]\n[1,]   30   66  102\n[2,]   36   81  126\n[3,]   42   96  150"
  },
  {
    "objectID": "Intro.html#dataframes",
    "href": "Intro.html#dataframes",
    "title": "Intro to R",
    "section": "Dataframes",
    "text": "Dataframes\nA dataframe is a 2 dimensional storage of data of different types. It is always filled vertically - i.e. the first list or vector specified is the first column of the dataframe.\nDataframes can have named columns, allowing us to have more control.\n\n\nCode\n```{r}\n###| Example dataframe\ndf &lt;- data.frame(name = c(\"Harry\",\"Ron\",\"Hermione\"),\n                 age = c(17,18,19),\n                 smoker = c(FALSE,TRUE,FALSE))\n\ndf\n\n###| Indexing a dataframe\n\ndf[3,2]\ndf[,\"smoker\"]\ndf[1:2,\"name\"]\ndf$smoker # we can use $ sign to pull named columns\n\n###| Named columns\n\ncolnames(df)\nnames(df)\n```\n\n\n      name age smoker\n1    Harry  17  FALSE\n2      Ron  18   TRUE\n3 Hermione  19  FALSE\n[1] 19\n[1] FALSE  TRUE FALSE\n[1] \"Harry\" \"Ron\"  \n[1] FALSE  TRUE FALSE\n[1] \"name\"   \"age\"    \"smoker\"\n[1] \"name\"   \"age\"    \"smoker\""
  },
  {
    "objectID": "Intro.html#array",
    "href": "Intro.html#array",
    "title": "Intro to R",
    "section": "Array",
    "text": "Array\nAn array is an n-dimensional storage of data of the same type.\n\n\nCode\n```{r}\n###| Example array\narray(data = c(1:6),dim = c(2,2,2))\narray(data = c(1:12),dim = c(2,3,2))\n```\n\n\n, , 1\n\n     [,1] [,2]\n[1,]    1    3\n[2,]    2    4\n\n, , 2\n\n     [,1] [,2]\n[1,]    5    1\n[2,]    6    2\n\n, , 1\n\n     [,1] [,2] [,3]\n[1,]    1    3    5\n[2,]    2    4    6\n\n, , 2\n\n     [,1] [,2] [,3]\n[1,]    7    9   11\n[2,]    8   10   12"
  },
  {
    "objectID": "Intro.html#check-your-understanding-1",
    "href": "Intro.html#check-your-understanding-1",
    "title": "Intro to R",
    "section": "Check your understanding",
    "text": "Check your understanding\nThe following are some extercises to test your understanding about operations.\n\n\nUse R to determine the area of a circle with diameter of 20cm.\n\nHint: pi is recognised in R.\n\nCalculate the cube root of 14 \\(\\times\\) 0.51.\n\nHint: think carefully about the order of operations.\n\nTest the following statement in R: Not (4 squared is greater than or equal to 15, or (the sum of 7 and 10 is less than 16)).\n\nHint: the output should be FALSE.\n\n\n\n(The code is hidden to give you a chance to practise. However, if you toggle the &gt;, example code will appear.)\n\n\nCode\n```{r}\n#| code-fold: true\n\n###| Answers\n(10^2)*pi\n(14 * 0.51)^(3)\n!( 4&lt;=15 | 7+10 &lt; 16)\n```\n\n\n[1] 314.1593\n[1] 363.9943\n[1] FALSE"
  },
  {
    "objectID": "Intro.html#arithmetic-operators",
    "href": "Intro.html#arithmetic-operators",
    "title": "Intro to R",
    "section": "Arithmetic operators",
    "text": "Arithmetic operators\nThe 4 base arithmetic operators are addition (+), subtraction (-), multiplication (*) and division (/). The following are some base examples of how these can be used.\n\n\nCode\n```{r}\n###| Addition\n3+10\n\n###| Subtraction\n6-2\n\n###| Multiplication\n5*15\n\n###| Division\n23/7\n```\n\n\n[1] 13\n[1] 4\n[1] 75\n[1] 3.285714\n\n\n\n\n\n\n\n\nNote\n\n\n\nIt is important to note that R follows the traditional BODMASS order of operations. As such, we can use brackets to control the order in which operations are performed.\n\n\n\n\nCode\n```{r}\n###| BODMASS\n(1+7)/2\n1 + 7/2\n3*5+2/3\n3*(5+2)/3\n```\n\n\n[1] 4\n[1] 4.5\n[1] 15.66667\n[1] 7\n\n\nWe can also do exponents (to the power of) using ^ or **, and we can find the modulo using %% and %/%\n\n\nCode\n```{r}\n###| Exponents \n5^2\n5**2\n\n4^(1/2)\n4**0.5\n```\n\n\n[1] 25\n[1] 25\n[1] 2\n[1] 2\n\n\n\n\nCode\n```{r}\n###| Modulo\n10 %% 2 # remainder of 10 divided by 2\n10 %% 4\n\n10 %/% 2 # how many times 2 goes into 10\n10 %/% 4\n```\n\n\n[1] 0\n[1] 2\n[1] 5\n[1] 2"
  },
  {
    "objectID": "Intro.html#comparison-operators",
    "href": "Intro.html#comparison-operators",
    "title": "Intro to R",
    "section": "Comparison operators",
    "text": "Comparison operators\nComparison operators compare 2 values to one another and will return TRUE or FALSE.\nThe 2 operators that can be used for any data type are equal to == and not equal to !=.\nWe can also compare two numbers using less than &lt;, less than or equal to &lt;=, greater than &gt;, and greater than or equal to &gt;=.\n\n\nCode\n```{r}\n###| Equal to\n\"a banana\" == \"a banana\"\n\"a banana\" == \"a fruit\"\n\n7 == 5\n5 == 5\n\n###| Not wqual to\n\"a banana\" != \"a banana\"\n\"a banana\" != \"a fruit\"\n\n7 != 5\n5 != 5\n```\n\n\n[1] TRUE\n[1] FALSE\n[1] FALSE\n[1] TRUE\n[1] FALSE\n[1] TRUE\n[1] TRUE\n[1] FALSE\n\n\n\n\nCode\n```{r}\n###| Less than\n5 &lt; 7 \n7 &lt; 5\n5 &lt; 5 # note that this will return FALSE!\n\n###| Greater than\n5 &gt; 7 \n7 &gt; 5\n5 &gt; 5 # note that this will return FALSE!\n\n###| Less than or equal to\n5 &lt;= 7 \n7 &lt;= 5\n5 &lt;= 5 # note that this will return TRUE!\n\n###| Greater than or equal to\n5 &gt;= 7 \n7 &gt;= 5\n5 &gt;= 5 # note that this will return TRUE!\n```\n\n\n[1] TRUE\n[1] FALSE\n[1] FALSE\n[1] FALSE\n[1] TRUE\n[1] FALSE\n[1] TRUE\n[1] FALSE\n[1] TRUE\n[1] FALSE\n[1] TRUE\n[1] TRUE"
  },
  {
    "objectID": "Intro.html#logical-operators",
    "href": "Intro.html#logical-operators",
    "title": "Intro to R",
    "section": "Logical operators",
    "text": "Logical operators\nLogical operators allow us to combine things or negate something.\nIf we want to find the negative, we use the ! operator. For example, we may want to say something is not true. we do this with !TRUE. Or we may want to check if 5 is not less than 7, !(5&lt;7).\n\n\nCode\n```{r}\n###| Negation of TRUE FALSE\nTRUE\n!(TRUE)\n\nFALSE\n!(TRUE)\n```\n\n\n[1] TRUE\n[1] FALSE\n[1] FALSE\n[1] FALSE\n\n\n\n\nCode\n```{r}\n###| Example of negation on relational operators\n5&lt;7\n!(5&lt;7)\n\n5==7\n!(5==7)\n```\n\n\n[1] TRUE\n[1] FALSE\n[1] FALSE\n[1] TRUE\n\n\nWe can also combine operators using AND, &. For example, we may want to check that 5&lt;7 and 10&lt;12. Alternatively, we may want to allow A or B to be true. We do this with |.\n\n\nCode\n```{r}\n###| And on TRUE FALSE\nTRUE & TRUE\nFALSE & FALSE\nTRUE & FALSE\n\n###| And on relational operators example\n(7&gt;5) & (10&lt;12)\n(7&lt;5) & (10&gt;12)\n(7&lt;5) & (10&lt;12)\n```\n\n\n[1] TRUE\n[1] FALSE\n[1] FALSE\n[1] TRUE\n[1] FALSE\n[1] FALSE\n\n\n\n\nCode\n```{r}\n###| OR on TRUE FALSE\nTRUE | TRUE\nFALSE | FALSE\nTRUE | FALSE\n\n###| OR on relational operators example\n(7&gt;5) | (10&lt;12)\n(7&lt;5) | (10&gt;12)\n(7&lt;5) | (10&lt;12)\n```\n\n\n[1] TRUE\n[1] FALSE\n[1] TRUE\n[1] TRUE\n[1] FALSE\n[1] TRUE"
  },
  {
    "objectID": "Intro.html#check-your-understanding-2",
    "href": "Intro.html#check-your-understanding-2",
    "title": "Intro to R",
    "section": "Check your understanding",
    "text": "Check your understanding\nThe following are some extercises to test your understanding about variables.\n\n\nDefine variables called velocity, time and acceleration with 5, 10 and 9.8 respectively. Calculate the displacement.\n\nHint: \\(s = ut+0.5at^2\\).\n\nDefine variables height and width of a rectangle with initial values 5 and 10. Calculate the area of the rectangle.\nExtension: given \\(f(x)=\\frac{1}{\\sqrt{2\\pi}}\\exp{(-\\frac{1}{2}x^2)}\\), find \\(f(5)\\).\n\nHint: look at sqrt() and exp().\n\n\n\n\n\nCode\n```{r}\n#| code-fold: true\n\n###| Answers\nvecolity &lt;- 5\ntime &lt;- 10\nacceleration &lt;- 9.8\ndisplacement &lt;- vecolity * time + 0.5 * acceleration * time^2\ndisplacement\n\nheight &lt;- 5\nwidth &lt;- 10\narea &lt;- height * width\narea\n\n###| Extension question\nx &lt;- 5\nf_x &lt;- 1/sqrt(2*pi)*exp(-0.5*x^2)\nf_x\n```\n\n\n[1] 540\n[1] 50\n[1] 1.48672e-06"
  },
  {
    "objectID": "Intro.html#check-your-understanding-3",
    "href": "Intro.html#check-your-understanding-3",
    "title": "Intro to R",
    "section": "Check your understanding",
    "text": "Check your understanding\nAnswer the following questions using if(), for() and while() loops.\n\n\nGiven a number, print “Positive” or “Negative” depending on if the number is positive or negative. If the number is 0, print both.\nGiven a vector, find the maximum and minimum value. Thus find out the range.\n\n\n\n\nCode\n```{r}\n#| code-fold: true\n###| Answers\nx=-1\nif (x &gt; 0) {\n  print(\"positive\")\n} else if (x &lt; 0) {\n  print(\"negative\")\n} else {print(\"both\")}\n```\n\n\n[1] \"negative\"\n\n\n\n\nCode\n```{r}\n#| code-fold: true\n###| Answers\nx &lt;- c(0,1,2,7,-5)\nn &lt;- length(x)\nmin &lt;- x[1]\nmax &lt;- x[1]\n\nfor(i in 1:n){\n  if (x[i] &lt; min) {\n    min &lt;- x[i]\n  }\n  if (x[i] &gt; max) {\n    max &lt;- x[i]\n  }\n}\n\nprint(paste(\"Range is\",max-min))\n```\n\n\n[1] \"Range is 12\""
  },
  {
    "objectID": "Linear Modelling.html",
    "href": "Linear Modelling.html",
    "title": "Linear Modelling",
    "section": "",
    "text": "Test"
  },
  {
    "objectID": "Intro.html#if-statements",
    "href": "Intro.html#if-statements",
    "title": "Intro to R",
    "section": "If statements",
    "text": "If statements\nThe code of code after an if statement is only exectued if the conditoin within the if statement is met.\nIf statements are of the following form:\n\n\nif (condition with TRUE/FALSE answer) {code to be executed if true}\n\n\nWe have several examples:\n\n\nCode\n```{r}\n###| Example of if()\nif (5&lt;7) {\n  print(\"Hello world.\")\n}\n\n###| Example of if() and else()\nif (5 &gt; 7) {\n  print(\"Not it.\")\n} else {\n    print(\"It.\")\n}\n```\n\n\n[1] \"Hello world.\"\n[1] \"It.\""
  },
  {
    "objectID": "Intro.html#for-loops",
    "href": "Intro.html#for-loops",
    "title": "Intro to R",
    "section": "For loops",
    "text": "For loops\nThe for loop allows code to be exectured repeatedly until a given iteration.\nIf follows the general structure:\n\n\nfor (variable in condition) {exectute code}\n\n\n\n\nCode\n```{r}\n###| For loop example\nfor (x in c(1:4)) {\n  print(x)\n}\n\n###| Nested loop\nfor (x in c(1:4)) {\n  print(x)\n  for (y in c(1:3)) {\n    print(y)\n  }\n}\n```\n\n\n[1] 1\n[1] 2\n[1] 3\n[1] 4\n[1] 1\n[1] 1\n[1] 2\n[1] 3\n[1] 2\n[1] 1\n[1] 2\n[1] 3\n[1] 3\n[1] 1\n[1] 2\n[1] 3\n[1] 4\n[1] 1\n[1] 2\n[1] 3"
  },
  {
    "objectID": "Intro.html#while-loops",
    "href": "Intro.html#while-loops",
    "title": "Intro to R",
    "section": "While loops",
    "text": "While loops\nWhile loop tests if a condition is true and will continue running the code until the condition is false.\nThey follow the general structure:\n\n\nwhile (condition) {execute code}\n\n\nIt is very important to avoid infinite loops!!\n\n\nCode\n```{r}\n###| While loop example\ni &lt;- 1\nwhile (i &lt;= 5){\n  print(i)\n  i &lt;- i + 1\n}\n```\n\n\n[1] 1\n[1] 2\n[1] 3\n[1] 4\n[1] 5"
  },
  {
    "objectID": "Intro.html#check-your-understanding-4",
    "href": "Intro.html#check-your-understanding-4",
    "title": "Intro to R",
    "section": "Check your understanding",
    "text": "Check your understanding\nWrite functions that do the following things:\n\n\nCreate a function which returns integer division of x by y and the remainder\nCreate a function which finds the area and circumference of a circle given a radius r.\nCreate a function that calculates the factorial of some number n.\n\nHint: make sure that n is an integer!\n\n\n\n\n\nCode\n```{r}\n#| code-fold: true\n###| Answer\n\nmodulus &lt;- function(x,y) {\n  remainder &lt;- x %% y\n  multiple &lt;- x %/% y\n  print(paste(\"x modulo y is\", multiple, \"with remainder\", remainder))\n}\n\nmodulus(6,3)\n```\n\n\n[1] \"x modulo y is 2 with remainder 0\"\n\n\n\n\nCode\n```{r}\n#| code-fold: true\n###| Answer\n\ncircle &lt;- function(r){\n  area &lt;- r^2 * pi\n  circumference &lt;- 2*r*pi\n  print(paste(\"Area is\",area, \"and the circumference is\",circumference))\n}\n\ncircle(5)\n```\n\n\n[1] \"Area is 78.5398163397448 and the circumference is 31.4159265358979\"\n\n\n\n\nCode\n```{r}\n#| code-fold: true\n###| Answer\n\nfactorial &lt;- function(x) {\n  \n  if (x%%1 == 0) {\n    \n    factorial &lt;- 1\n    \n    while (x &gt;= 1) {\n      factorial &lt;- factorial * x\n      x &lt;- x - 1\n    }\n    \n    print(factorial)\n  } else {\n    print(paste(x,\" is not a positive integer\"))\n  }\n}\n\nfactorial(2) \n```\n\n\n[1] 2"
  },
  {
    "objectID": "Intro.html#check-your-understanding-5",
    "href": "Intro.html#check-your-understanding-5",
    "title": "Intro to R",
    "section": "Check your understanding",
    "text": "Check your understanding\nWrite functions that do the following things:\n\n\nCreate a function which returns integer division of x by y and the remainder\nCreate a function which finds the area and circumference of a circle given a radius r.\nCreate a function that calculates the factorial of some number n.\n\nHint: make sure that n is an integer!\n\n\n\n\n\nCode\n```{r}\n#| code-fold: true\n###| Answer\n\nmodulus &lt;- function(x,y) {\n  remainder &lt;- x %% y\n  multiple &lt;- x %/% y\n  print(paste(\"x modulo y is\", multiple, \"with remainder\", remainder))\n}\n\nmodulus(6,3)\n```\n\n\n[1] \"x modulo y is 2 with remainder 0\"\n\n\n\n\nCode\n```{r}\n#| code-fold: true\n###| Answer\n\ncircle &lt;- function(r){\n  area &lt;- r^2 * pi\n  circumference &lt;- 2*r*pi\n  print(paste(\"Area is\",area, \"and the circumference is\",circumference))\n}\n\ncircle(5)\n```\n\n\n[1] \"Area is 78.5398163397448 and the circumference is 31.4159265358979\"\n\n\n\n\nCode\n```{r}\n#| code-fold: true\n###| Answer\n\nfactorial &lt;- function(x) {\n  \n  if (x%%1 == 0) {\n    \n    factorial &lt;- 1\n    \n    while (x &gt;= 1) {\n      factorial &lt;- factorial * x\n      x &lt;- x - 1\n    }\n    \n    print(factorial)\n  } else {\n    print(paste(x,\" is not a positive integer\"))\n  }\n}\n\nfactorial(2) \n```\n\n\n[1] 2"
  },
  {
    "objectID": "figures.html",
    "href": "figures.html",
    "title": "Figures",
    "section": "",
    "text": "In R, it is very easy to create scatter plots, line graphs, histograms and box plots. We will cover how to do all 4 using base R commands.\nOther sections will cover how to do these in other packages (namely ‘ggplot2’) to get more control over formatting.\n\n\nWe will start by generating a sample from a \\(\\text{Uniform}[0,1]\\) distribution and plotting a scatter plot.\n\n\nCode\n```{r}\n##| Generating a sample\nsample &lt;- runif(n = 100, min = 0, max = 1)\n\n###| Scatterplot\nplot(sample)\n```\n\n\n\n\n\n\n\n\n\nIf we sort the sample by size, we can create a plot that increases from left to right.\n\n\nCode\n```{r}\n###| Ordered sample scatter plot\nplot(sort(sample))\n```\n\n\n\n\n\n\n\n\n\nThe x and y labs are not clear. We should change these by adding in the xlab and ylab arguments. We should also add a title for clarity!\n\n\nCode\n```{r}\n###| x and y labels and title (called main) \nplot(sort(sample), xlab = \"Ordered index\", ylab = \"Sample\", main = \"Title\")\n```\n\n\n\n\n\n\n\n\n\nWe observe a linear relationship between the ordered samples. Let us test this by adding a line to this graph using ‘abline()’.\n\n\nCode\n```{r}\n###| Using abline\nplot(sort(sample), xlab = \"Ordered index\", ylab = \"Sample\", main = \"Title\")\nabline(a = 0,b=0.01)\n```\n\n\n\n\n\n\n\n\n\nIt is quite hard to see both the points and the line at the same time. We can change the aesthetics (colour, shape and size) to make this easier to see. Additional point shapes are available here.\n\n\nCode\n```{r}\n###| Aesthetics - colour and points\nplot(sort(sample), xlab = \"Ordered index\", ylab = \"Sample\", main = \"Title\", \n     col = \"red\", pch = 3)        # we start a new line for readability :)\nabline(a = 0,b=0.01, col = \"blue\")\n```\n\n\n\n\n\n\n\n\n\nSuppose we wanted to add additional lines, at the Sample = 0.5 and at the 50th index. We can add these using ‘abline()’. We can also distinguish them by changing colour, line thickness and line type. Additional details are available here.\n\n\nCode\n```{r}\n###| Aesthetics - line\nplot(sort(sample), xlab = \"Ordered index\", ylab = \"Sample\", main = \"Title\", \n     col = \"red\", pch = 3)\nabline(a = 0,b=0.01, col = \"blue\") \nabline(h=0.5, col = \"black\", lwd = 1, lty = 3) # Note that h here is a horizontal line at sample = 0.5\nabline(v=50, col = \"black\", lwd = 1, lty = 4)  # v here is a vertical line at index = 50\n```\n\n\n\n\n\n\n\n\n\n\n\n\nNow, we move to generating a line graph. We will generate a new sample, this time from a \\(\\text{Normal}(0,1)\\) distribution.\n\n\nCode\n```{r}\n###| Generate sample\nsample &lt;- rnorm(n = 30, mean = 0, sd = 1)\n\n###| Line graph\nplot(sample, type = \"l\")\n```\n\n\n\n\n\n\n\n\n\nSuppose we also want to show the points. We change the type from “l” to “b”.\n\n\nCode\n```{r}\n###| Line graph with points\nplot(sample, type = \"b\")\n```\n\n\n\n\n\n\n\n\n\nAgain, we can play with the aesthetics of these graphs.\n\n\nCode\n```{r}\n###| Line graph aesthetics\nplot(sample, type = \"l\", lwd = 2, lty = 3)\nplot(sample, type = \"b\", lwd = 1, lty = 5, pch = 17, col = 3)\n```\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSuppose we have another sample generated from a \\(\\text{Normal}(0,2)\\). We can show both lines on the same graph.\n\n\nCode\n```{r}\n###| For reproducibility\nset.seed(68)\n\n###| Generate 2 samples\nsample1 &lt;- rnorm(n=30, mean = 0, sd = 1)\nsample2 &lt;- rnorm(n=30, mean = 0, sd = 2)\n\n###| Line plot with multiple lines\nplot(sample1, type = \"l\")\nlines(sample2)\n```\n\n\n\n\n\n\n\n\n\nWe have something, but it appears the top is cut off the graph (this is beacuse we are adding sample 2 onto sample 1 and sample 2 has a larger range). We can change the y axis limits.\n\n\nCode\n```{r}\n###| Line plot with multiple lines with limits\nplot(sample1, type = \"l\", ylim = c(-4,4))\nlines(sample2)\n```\n\n\n\n\n\n\n\n\n\nWe should also change the colours for readability.\n\n\nCode\n```{r}\n###| Line plot with multiple lines with limits\nplot(sample1, type = \"l\", ylim = c(-4,4), col = \"blue\")\nlines(sample2)\n```\n\n\n\n\n\n\n\n\n\nWe can have different types of lines in the same graph as well.\n\n\nCode\n```{r}\n###| Line plot with multiple line types\nplot(sample1, type = \"l\", ylim = c(-4,4), col = \"blue\")\nlines(sample2, lty = 4, type = \"b\")\n```\n\n\n\n\n\n\n\n\n\n\n\n\nSuppose instead we want to look at the distribution of the sample, and test if it aligns with the distribution we expect. To do this, we will up the number of samples (200) and will look at the histogram graph.\n\n\nCode\n```{r}\n###| Sample\nsample &lt;- rnorm(n=200, mean = 0, sd =1)\n\n###| Histogram\nhist(sample)\n```\n\n\n\n\n\n\n\n\n\nIf we want to have the probability on the y axis instead, we need to change the freq argument to FALSE or we change the prob argument to TRUE.\n\n\nCode\n```{r}\n###| Density graph\nhist(sample, freq = FALSE)\nhist(sample, prob = TRUE)\n```\n\n\n\n\n\n\n\n\n\nThe widths of the boxes are quite large. We can change this with the breaks argument.\n\n\nCode\n```{r}\n###| Set number of breaks\nhist(sample, breaks = 10) # 10 boxes\nhist(sample, breaks = 20) # 20 boxes\n\n###| Different size boxes\nhist(sample, breaks = c(min(sample),-1.5,0,0.5,1,max(sample))) \n      # need min and max to ensure range works\n```\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe can also change the labels and add a title.\n\n\nCode\n```{r}\n###| Labels and title\nhist(sample, breaks = 20, xlab = \"Sample\", main = \"Title\")  \n```\n\n\n\n\n\n\n\n\n\nNow, lets compare this to the normal distribution. First, we can add the density curve of the sample.\n\n\nCode\n```{r}\nsample &lt;- rnorm(n = 1000, mean = 0, sd = 1) # Increasing sample count\n\n###| Density curve\nhist(sample, prob = TRUE)\nlines(density(sample))\n```\n\n\n\n\n\n\n\n\n\nWe can then add the normal distribution curve on top to allow comparison.\n\n\nCode\n```{r}\n###| Normal\nseq &lt;- seq(from = -3, to = 3, length = 1000)\nnorm_seq &lt;- dnorm(seq(from = -3, to = 3, length = 1000), mean = 0, sd = 1)\n\n###| Density curve\nhist(sample, prob = TRUE, ylim = c(0,max(norm_seq)))\nlines(density(sample))\nlines(seq,norm_seq, col = \"red\",lwd = 2)\n```\n\n\n\n\n\n\n\n\n\nThe sample distribution is very similar to the normal distribution curve (although the sample has 2 peaks rather than 1). However, it is confusing to have 2 lines without any labels. So, let us add a legend. Additional details appear here.\n\n\nCode\n```{r}\n###| Normal\nseq &lt;- seq(from = -3, to = 3, length = 1000)\nnorm_seq &lt;- dnorm(seq(from = -3, to = 3, length = 1000), mean = 0, sd = 1)\n\n###| Density curve\nhist(sample, prob = TRUE, ylim = c(0,max(norm_seq)))\nlines(density(sample))\nlines(seq,norm_seq, col = \"red\",lwd = 2)\nlegend(x = \"topright\", # position\n       legend = c(\"Sample curve\",\"Normal curve\"),\n       col = c(\"black\",\"red\"),\n       lwd = c(1,2))\n```\n\n\n\n\n\n\n\n\n\n\n\n\nFinally, we will consider box plots. We can plot the box plot of a single sample.\n\n\nCode\n```{r}\n###| Generating a sample\nsample &lt;- rnorm(n = 100, mean = 5, sd = 2)\n\n###| Boxplot\nboxplot(sample)\n```\n\n\n\n\n\n\n\n\n\nFor multiple boxplots, we can construct a data frame and plot accordingly.\n\n\nCode\n```{r}\n###| Data frame\ndf &lt;- data.frame(\"A\" = rnorm(n = 10, mean = 0, sd = 1),\n                 \"B\" = rnorm(n = 10, mean = 0, sd = 1),\n                 \"C\" = rnorm(n = 10, mean = 0, sd = 1))\n\n###| Box plot\nboxplot(df)\n```\n\n\n\n\n\n\n\n\n\nWe can add labels and titles.\n\n\nCode\n```{r}\n###| Box plot with labels\nboxplot(df, main = \"Title\", ylab = \"Sample values\", xlab = \"Categories\")\n```\n\n\n\n\n\n\n\n\n\n\n\n\nGenerate scatterplots, line graphs, histograms and box plots with samples from Poisson and Binomial distributions. Add legends and appropriate titles to each graph."
  },
  {
    "objectID": "figures.html#scatterplots",
    "href": "figures.html#scatterplots",
    "title": "Figures",
    "section": "",
    "text": "We will start by generating a sample from a \\(\\text{Uniform}[0,1]\\) distribution and plotting a scatter plot.\n\n\nCode\n```{r}\n##| Generating a sample\nsample &lt;- runif(n = 100, min = 0, max = 1)\n\n###| Scatterplot\nplot(sample)\n```\n\n\n\n\n\n\n\n\n\nIf we sort the sample by size, we can create a plot that increases from left to right.\n\n\nCode\n```{r}\n###| Ordered sample scatter plot\nplot(sort(sample))\n```\n\n\n\n\n\n\n\n\n\nThe x and y labs are not clear. We should change these by adding in the xlab and ylab arguments. We should also add a title for clarity!\n\n\nCode\n```{r}\n###| x and y labels and title (called main) \nplot(sort(sample), xlab = \"Ordered index\", ylab = \"Sample\", main = \"Title\")\n```\n\n\n\n\n\n\n\n\n\nWe observe a linear relationship between the ordered samples. Let us test this by adding a line to this graph using ‘abline()’.\n\n\nCode\n```{r}\n###| Using abline\nplot(sort(sample), xlab = \"Ordered index\", ylab = \"Sample\", main = \"Title\")\nabline(a = 0,b=0.01)\n```\n\n\n\n\n\n\n\n\n\nIt is quite hard to see both the points and the line at the same time. We can change the aesthetics (colour, shape and size) to make this easier to see. Additional point shapes are available here.\n\n\nCode\n```{r}\n###| Aesthetics - colour and points\nplot(sort(sample), xlab = \"Ordered index\", ylab = \"Sample\", main = \"Title\", \n     col = \"red\", pch = 3)        # we start a new line for readability :)\nabline(a = 0,b=0.01, col = \"blue\")\n```\n\n\n\n\n\n\n\n\n\nSuppose we wanted to add additional lines, at the Sample = 0.5 and at the 50th index. We can add these using ‘abline()’. We can also distinguish them by changing colour, line thickness and line type. Additional details are available here.\n\n\nCode\n```{r}\n###| Aesthetics - line\nplot(sort(sample), xlab = \"Ordered index\", ylab = \"Sample\", main = \"Title\", \n     col = \"red\", pch = 3)\nabline(a = 0,b=0.01, col = \"blue\") \nabline(h=0.5, col = \"black\", lwd = 1, lty = 3) # Note that h here is a horizontal line at sample = 0.5\nabline(v=50, col = \"black\", lwd = 1, lty = 4)  # v here is a vertical line at index = 50\n```"
  },
  {
    "objectID": "figures.html#line-graphs",
    "href": "figures.html#line-graphs",
    "title": "Figures",
    "section": "",
    "text": "Now, we move to generating a line graph. We will generate a new sample, this time from a \\(\\text{Normal}(0,1)\\) distribution.\n\n\nCode\n```{r}\n###| Generate sample\nsample &lt;- rnorm(n = 30, mean = 0, sd = 1)\n\n###| Line graph\nplot(sample, type = \"l\")\n```\n\n\n\n\n\n\n\n\n\nSuppose we also want to show the points. We change the type from “l” to “b”.\n\n\nCode\n```{r}\n###| Line graph with points\nplot(sample, type = \"b\")\n```\n\n\n\n\n\n\n\n\n\nAgain, we can play with the aesthetics of these graphs.\n\n\nCode\n```{r}\n###| Line graph aesthetics\nplot(sample, type = \"l\", lwd = 2, lty = 3)\nplot(sample, type = \"b\", lwd = 1, lty = 5, pch = 17, col = 3)\n```\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSuppose we have another sample generated from a \\(\\text{Normal}(0,2)\\). We can show both lines on the same graph.\n\n\nCode\n```{r}\n###| For reproducibility\nset.seed(68)\n\n###| Generate 2 samples\nsample1 &lt;- rnorm(n=30, mean = 0, sd = 1)\nsample2 &lt;- rnorm(n=30, mean = 0, sd = 2)\n\n###| Line plot with multiple lines\nplot(sample1, type = \"l\")\nlines(sample2)\n```\n\n\n\n\n\n\n\n\n\nWe have something, but it appears the top is cut off the graph (this is beacuse we are adding sample 2 onto sample 1 and sample 2 has a larger range). We can change the y axis limits.\n\n\nCode\n```{r}\n###| Line plot with multiple lines with limits\nplot(sample1, type = \"l\", ylim = c(-4,4))\nlines(sample2)\n```\n\n\n\n\n\n\n\n\n\nWe should also change the colours for readability.\n\n\nCode\n```{r}\n###| Line plot with multiple lines with limits\nplot(sample1, type = \"l\", ylim = c(-4,4), col = \"blue\")\nlines(sample2)\n```\n\n\n\n\n\n\n\n\n\nWe can have different types of lines in the same graph as well.\n\n\nCode\n```{r}\n###| Line plot with multiple line types\nplot(sample1, type = \"l\", ylim = c(-4,4), col = \"blue\")\nlines(sample2, lty = 4, type = \"b\")\n```"
  },
  {
    "objectID": "figures.html#histograms",
    "href": "figures.html#histograms",
    "title": "Figures",
    "section": "",
    "text": "Suppose instead we want to look at the distribution of the sample, and test if it aligns with the distribution we expect. To do this, we will up the number of samples (200) and will look at the histogram graph.\n\n\nCode\n```{r}\n###| Sample\nsample &lt;- rnorm(n=200, mean = 0, sd =1)\n\n###| Histogram\nhist(sample)\n```\n\n\n\n\n\n\n\n\n\nIf we want to have the probability on the y axis instead, we need to change the freq argument to FALSE or we change the prob argument to TRUE.\n\n\nCode\n```{r}\n###| Density graph\nhist(sample, freq = FALSE)\nhist(sample, prob = TRUE)\n```\n\n\n\n\n\n\n\n\n\nThe widths of the boxes are quite large. We can change this with the breaks argument.\n\n\nCode\n```{r}\n###| Set number of breaks\nhist(sample, breaks = 10) # 10 boxes\nhist(sample, breaks = 20) # 20 boxes\n\n###| Different size boxes\nhist(sample, breaks = c(min(sample),-1.5,0,0.5,1,max(sample))) \n      # need min and max to ensure range works\n```\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe can also change the labels and add a title.\n\n\nCode\n```{r}\n###| Labels and title\nhist(sample, breaks = 20, xlab = \"Sample\", main = \"Title\")  \n```\n\n\n\n\n\n\n\n\n\nNow, lets compare this to the normal distribution. First, we can add the density curve of the sample.\n\n\nCode\n```{r}\nsample &lt;- rnorm(n = 1000, mean = 0, sd = 1) # Increasing sample count\n\n###| Density curve\nhist(sample, prob = TRUE)\nlines(density(sample))\n```\n\n\n\n\n\n\n\n\n\nWe can then add the normal distribution curve on top to allow comparison.\n\n\nCode\n```{r}\n###| Normal\nseq &lt;- seq(from = -3, to = 3, length = 1000)\nnorm_seq &lt;- dnorm(seq(from = -3, to = 3, length = 1000), mean = 0, sd = 1)\n\n###| Density curve\nhist(sample, prob = TRUE, ylim = c(0,max(norm_seq)))\nlines(density(sample))\nlines(seq,norm_seq, col = \"red\",lwd = 2)\n```\n\n\n\n\n\n\n\n\n\nThe sample distribution is very similar to the normal distribution curve (although the sample has 2 peaks rather than 1). However, it is confusing to have 2 lines without any labels. So, let us add a legend. Additional details appear here.\n\n\nCode\n```{r}\n###| Normal\nseq &lt;- seq(from = -3, to = 3, length = 1000)\nnorm_seq &lt;- dnorm(seq(from = -3, to = 3, length = 1000), mean = 0, sd = 1)\n\n###| Density curve\nhist(sample, prob = TRUE, ylim = c(0,max(norm_seq)))\nlines(density(sample))\nlines(seq,norm_seq, col = \"red\",lwd = 2)\nlegend(x = \"topright\", # position\n       legend = c(\"Sample curve\",\"Normal curve\"),\n       col = c(\"black\",\"red\"),\n       lwd = c(1,2))\n```"
  },
  {
    "objectID": "figures.html#box-plots",
    "href": "figures.html#box-plots",
    "title": "Figures",
    "section": "",
    "text": "Finally, we will consider box plots. We can plot the box plot of a single sample.\n\n\nCode\n```{r}\n###| Generating a sample\nsample &lt;- rnorm(n = 100, mean = 5, sd = 2)\n\n###| Boxplot\nboxplot(sample)\n```\n\n\n\n\n\n\n\n\n\nFor multiple boxplots, we can construct a data frame and plot accordingly.\n\n\nCode\n```{r}\n###| Data frame\ndf &lt;- data.frame(\"A\" = rnorm(n = 10, mean = 0, sd = 1),\n                 \"B\" = rnorm(n = 10, mean = 0, sd = 1),\n                 \"C\" = rnorm(n = 10, mean = 0, sd = 1))\n\n###| Box plot\nboxplot(df)\n```\n\n\n\n\n\n\n\n\n\nWe can add labels and titles.\n\n\nCode\n```{r}\n###| Box plot with labels\nboxplot(df, main = \"Title\", ylab = \"Sample values\", xlab = \"Categories\")\n```"
  },
  {
    "objectID": "figures.html#check-your-understanding",
    "href": "figures.html#check-your-understanding",
    "title": "Figures",
    "section": "",
    "text": "Generate scatterplots, line graphs, histograms and box plots with samples from Poisson and Binomial distributions. Add legends and appropriate titles to each graph."
  },
  {
    "objectID": "Introduction to R/Random numbers.html",
    "href": "Introduction to R/Random numbers.html",
    "title": "Random numbers",
    "section": "",
    "text": "Inbuilt into R, there are many functions focused on statistical distributions. These are all stored in the ‘stats’ package, which is loaded in by default in R. However, for practise, (and to ensure everything will work), we will load in the package directly.\n\n\nCode\n```{r}\n###| Loading in stats package\nlibrary(stats)\n```\n\n\nWe will begin by looking at generating a uniform number before doing on to look at continuous and discrete random variables.\n\nRandom uniform numbers\nTo generate a random number, we are going to use the uniform distribution. Let \\(X\\sim \\text{Uniform}[a,b]\\). Then, the probability mass function of X is\n\\[\nf(x) = \\begin{cases}\n\\frac{1}{b-a} & \\text{for } a\\leq x\\leq b, \\\\\n0 & \\text{for } x&lt;a \\text{ or } x&gt;b\n\\end{cases}\n\\]\nWe are going to use the inbuilt R functions to generate a random number, x, in the interval \\([a,b]\\) and find the probability we generated x.\nFor simplicity, we will demonstrate this with 2 uniform random variables: \\(X\\sim \\text{Uniform}[0,1]\\) and \\(Y\\sim \\text{Uniform}[1,5]\\).\n\n\nCode\n```{r}\n###| Generate a random number, x\nx &lt;- runif(n = 1, min = 0, max = 1)\nx\n\n###| Probability we generated x\nprob_x &lt;- punif(x, min = 0, max = 1)\nprob_x\n\n###| Generate a random number, y\ny &lt;- runif(n = 1, min = 1, max = 5)\ny\n\n###| Probability we generated y\nprob_y &lt;- punif(y, min = 1, max = 5)\nprob_y\n```\n\n\n[1] 0.9805846\n[1] 0.9805846\n[1] 3.822689\n[1] 0.7056722\n\n\nWe can also find the value, \\(x\\), that corresponds to the probability \\(P(X\\leq x) = a\\).\n\n\nCode\n```{r}\n###| a = 0.5, X ~ Uniform[0,1]\nqunif(0.5, min = 0, max = 1)\n\n###| a = 0.5, X ~ Uniform[0,5]\nqunif(0.5, min = 0, max = 5)\n\n###| a = 0.75, X ~ Uniform[0,5]\nqunif(0.75, min = 0, max = 5)\n```\n\n\n[1] 0.5\n[1] 2.5\n[1] 3.75\n\n\nWe can also find the density of values \\(x\\) and \\(y\\).\n\n\nCode\n```{r}\n###| Density of x, X ~ Uniform[0,1]\nx &lt;- runif(n = 1, min = 0, max = 1)\ndunif(x, min = 0,max = 1)\n\n###| Density of y, Y ~ Uniform[1,5]\ny &lt;- runif(n = 1, min = 1, max = 5)\ndunif(y, min = 1,max = 5)\n```\n\n\n[1] 1\n[1] 0.25\n\n\nUp until now, we have only generated 1 number at a time. However, we can generate several numbers at once by changing the $n = $ argument. However, this only works for the ‘runif()’ function!\n\n\nCode\n```{r}\n###| Multiple values at once\nrunif(n = 5, min = 0, max = 1)\nrunif(n = 3, min = -1, max = 1)\n```\n\n\n[1] 0.3304437 0.5607250 0.5797799 0.9419879 0.6397729\n[1] -0.6708021 -0.1787737 -0.1669490\n\n\n\n\nBinomial distribution\nNow, suppose we want to sample from a binomial distribution, i.e. we want to generate a random number so that the probability \\(X=x\\) is the same as the probability \\(Y=x\\), where \\(Y \\sim \\text{Binomial}(m,p)\\). We do this using ‘rbinom()’, ‘dbinom()’, ‘pbinom()’ and ‘qbinom()’. Note that \\(n\\) refers to the number of samples while size refers to the number of trials!\n\n\nCode\n```{r}\n###| Generate a random value from X ~ Binom(m = 5, p = 0.2)\nx &lt;- rbinom(n=1, size = 5, prob = 0.2)\nx\n\n###| Probability generated x\nprob_x &lt;- pbinom(x, size = 5, prob = 0.2)\nprob_x\n\n###| f(x), density of x\ndensity_x &lt;- dbinom(x, size = 5, prob = 0.2)\ndensity_x\n\n###| Quantile of 0.75\nqbinom(p = 0.75, size = 5, prob = 0.2)\n```\n\n\n[1] 2\n[1] 0.94208\n[1] 0.2048\n[1] 2\n\n\n\n\nCheck your understanding - Normal and Poisson distribution\nIn the above sections, we have gone over how to sample from Uniform and Binomial distribution. To check your understanding, try the following:\n\n\nSample 5 values from a Poisson distribution with rate \\(\\lambda = 5\\) and find the probability and density of each value. Return this as a dataframe.\n\nHint: type ?rpois into the command line or into the help section.\n\nSample 5 values from a Normal distribution with mean 0 and variance 4. Find the density of each value, to 3 significant figures.\n\nHint: type ?rnorm and ?round into the command line or into the help section.\n\n\n\n\n\nCode\n```{r}\n#| code-fold: true\n###| Generate and store 5 values from Poisson\nsample &lt;- rpois(n = 5, lambda = 5)\nsample\n\n###| Find probability, density and quantile\ndf &lt;- data.frame(\"sample\" = sample,\n                 \"prob\" = rep(NA,length(sample)),\n                 \"density\" = rep(NA,length(sample)))\n\n\nfor (i in 1:length(sample)) {\n  df$prob[i] &lt;- ppois(df$sample[i], lambda = 5)\n  df$density[i] &lt;- dpois(df$sample[i], lambda = 5)\n}\n\ndf\n```\n\n\n[1] 10  8  3  2  4\n  sample      prob    density\n1     10 0.9863047 0.01813279\n2      8 0.9319064 0.06527804\n3      3 0.2650259 0.14037390\n4      2 0.1246520 0.08422434\n5      4 0.4404933 0.17546737\n\n\n\n\nCode\n```{r}\n#| code-fold: true\n###| Generate Normal distribution\nnorm &lt;- rnorm(n = 5, mean = 0, sd = 2)\nnorm\n\n###| Find density of each variable\nfor (i in 1:length(norm)){\n  print(paste(round(norm[i],3),\" has density \", round(dnorm(norm[i],mean = 0, sd = 2),3)))\n}\n\n# Alternatively, we can do this in one step without the loop as dnorm() \n# allows vector input\ndnorm(norm, mean=0,sd=2) \n```\n\n\n[1] -0.33344264 -0.08099315 -1.41945430  0.80238623  0.03565988\n[1] \"-0.333  has density  0.197\"\n[1] \"-0.081  has density  0.199\"\n[1] \"-1.419  has density  0.155\"\n[1] \"0.802  has density  0.184\"\n[1] \"0.036  has density  0.199\"\n[1] 0.1967181 0.1993076 0.1550602 0.1840471 0.1994394",
    "crumbs": [
      "Home",
      "Introduction to R",
      "Random numbers"
    ]
  },
  {
    "objectID": "Introduction to R/figures.html",
    "href": "Introduction to R/figures.html",
    "title": "Figures",
    "section": "",
    "text": "In R, it is very easy to create scatter plots, line graphs, histograms and box plots. We will cover how to do all 4 using base R commands.\nOther sections will cover how to do these in other packages (namely ‘ggplot2’) to get more control over formatting.\n\nScatterplots\nWe will start by generating a sample from a \\(\\text{Uniform}[0,1]\\) distribution and plotting a scatter plot.\n\n\nCode\n```{r}\n##| Generating a sample\nsample &lt;- runif(n = 100, min = 0, max = 1)\n\n###| Scatterplot\nplot(sample)\n```\n\n\n\n\n\n\n\n\n\nIf we sort the sample by size, we can create a plot that increases from left to right.\n\n\nCode\n```{r}\n###| Ordered sample scatter plot\nplot(sort(sample))\n```\n\n\n\n\n\n\n\n\n\nThe x and y labs are not clear. We should change these by adding in the xlab and ylab arguments. We should also add a title for clarity!\n\n\nCode\n```{r}\n###| x and y labels and title (called main) \nplot(sort(sample), xlab = \"Ordered index\", ylab = \"Sample\", main = \"Title\")\n```\n\n\n\n\n\n\n\n\n\nWe observe a linear relationship between the ordered samples. Let us test this by adding a line to this graph using ‘abline()’.\n\n\nCode\n```{r}\n###| Using abline\nplot(sort(sample), xlab = \"Ordered index\", ylab = \"Sample\", main = \"Title\")\nabline(a = 0,b=0.01)\n```\n\n\n\n\n\n\n\n\n\nIt is quite hard to see both the points and the line at the same time. We can change the aesthetics (colour, shape and size) to make this easier to see. Additional point shapes are available here.\n\n\nCode\n```{r}\n###| Aesthetics - colour and points\nplot(sort(sample), xlab = \"Ordered index\", ylab = \"Sample\", main = \"Title\", \n     col = \"red\", pch = 3)        # we start a new line for readability :)\nabline(a = 0,b=0.01, col = \"blue\")\n```\n\n\n\n\n\n\n\n\n\nSuppose we wanted to add additional lines, at the Sample = 0.5 and at the 50th index. We can add these using ‘abline()’. We can also distinguish them by changing colour, line thickness and line type. Additional details are available here.\n\n\nCode\n```{r}\n###| Aesthetics - line\nplot(sort(sample), xlab = \"Ordered index\", ylab = \"Sample\", main = \"Title\", \n     col = \"red\", pch = 3)\nabline(a = 0,b=0.01, col = \"blue\") \nabline(h=0.5, col = \"black\", lwd = 1, lty = 3) # Note that h here is a horizontal line at sample = 0.5\nabline(v=50, col = \"black\", lwd = 1, lty = 4)  # v here is a vertical line at index = 50\n```\n\n\n\n\n\n\n\n\n\n\n\nLine graphs\nNow, we move to generating a line graph. We will generate a new sample, this time from a \\(\\text{Normal}(0,1)\\) distribution.\n\n\nCode\n```{r}\n###| Generate sample\nsample &lt;- rnorm(n = 30, mean = 0, sd = 1)\n\n###| Line graph\nplot(sample, type = \"l\")\n```\n\n\n\n\n\n\n\n\n\nSuppose we also want to show the points. We change the type from “l” to “b”.\n\n\nCode\n```{r}\n###| Line graph with points\nplot(sample, type = \"b\")\n```\n\n\n\n\n\n\n\n\n\nAgain, we can play with the aesthetics of these graphs.\n\n\nCode\n```{r}\n###| Line graph aesthetics\nplot(sample, type = \"l\", lwd = 2, lty = 3)\nplot(sample, type = \"b\", lwd = 1, lty = 5, pch = 17, col = 3)\n```\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSuppose we have another sample generated from a \\(\\text{Normal}(0,2)\\). We can show both lines on the same graph.\n\n\nCode\n```{r}\n###| For reproducibility\nset.seed(68)\n\n###| Generate 2 samples\nsample1 &lt;- rnorm(n=30, mean = 0, sd = 1)\nsample2 &lt;- rnorm(n=30, mean = 0, sd = 2)\n\n###| Line plot with multiple lines\nplot(sample1, type = \"l\")\nlines(sample2)\n```\n\n\n\n\n\n\n\n\n\nWe have something, but it appears the top is cut off the graph (this is beacuse we are adding sample 2 onto sample 1 and sample 2 has a larger range). We can change the y axis limits.\n\n\nCode\n```{r}\n###| Line plot with multiple lines with limits\nplot(sample1, type = \"l\", ylim = c(-4,4))\nlines(sample2)\n```\n\n\n\n\n\n\n\n\n\nWe should also change the colours for readability.\n\n\nCode\n```{r}\n###| Line plot with multiple lines with limits\nplot(sample1, type = \"l\", ylim = c(-4,4), col = \"blue\")\nlines(sample2)\n```\n\n\n\n\n\n\n\n\n\nWe can have different types of lines in the same graph as well.\n\n\nCode\n```{r}\n###| Line plot with multiple line types\nplot(sample1, type = \"l\", ylim = c(-4,4), col = \"blue\")\nlines(sample2, lty = 4, type = \"b\")\n```\n\n\n\n\n\n\n\n\n\n\n\nHistograms\nSuppose instead we want to look at the distribution of the sample, and test if it aligns with the distribution we expect. To do this, we will up the number of samples (200) and will look at the histogram graph.\n\n\nCode\n```{r}\n###| Sample\nsample &lt;- rnorm(n=200, mean = 0, sd =1)\n\n###| Histogram\nhist(sample)\n```\n\n\n\n\n\n\n\n\n\nIf we want to have the probability on the y axis instead, we need to change the freq argument to FALSE or we change the prob argument to TRUE.\n\n\nCode\n```{r}\n###| Density graph\nhist(sample, freq = FALSE)\nhist(sample, prob = TRUE)\n```\n\n\n\n\n\n\n\n\n\nThe widths of the boxes are quite large. We can change this with the breaks argument.\n\n\nCode\n```{r}\n###| Set number of breaks\nhist(sample, breaks = 10) # 10 boxes\nhist(sample, breaks = 20) # 20 boxes\n\n###| Different size boxes\nhist(sample, breaks = c(min(sample),-1.5,0,0.5,1,max(sample))) \n      # need min and max to ensure range works\n```\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe can also change the labels and add a title.\n\n\nCode\n```{r}\n###| Labels and title\nhist(sample, breaks = 20, xlab = \"Sample\", main = \"Title\")  \n```\n\n\n\n\n\n\n\n\n\nNow, lets compare this to the normal distribution. First, we can add the density curve of the sample.\n\n\nCode\n```{r}\nsample &lt;- rnorm(n = 1000, mean = 0, sd = 1) # Increasing sample count\n\n###| Density curve\nhist(sample, prob = TRUE)\nlines(density(sample))\n```\n\n\n\n\n\n\n\n\n\nWe can then add the normal distribution curve on top to allow comparison.\n\n\nCode\n```{r}\n###| Normal\nseq &lt;- seq(from = -3, to = 3, length = 1000)\nnorm_seq &lt;- dnorm(seq(from = -3, to = 3, length = 1000), mean = 0, sd = 1)\n\n###| Density curve\nhist(sample, prob = TRUE, ylim = c(0,max(norm_seq)))\nlines(density(sample))\nlines(seq,norm_seq, col = \"red\",lwd = 2)\n```\n\n\n\n\n\n\n\n\n\nThe sample distribution is very similar to the normal distribution curve (although the sample has 2 peaks rather than 1). However, it is confusing to have 2 lines without any labels. So, let us add a legend. Additional details appear here.\n\n\nCode\n```{r}\n###| Normal\nseq &lt;- seq(from = -3, to = 3, length = 1000)\nnorm_seq &lt;- dnorm(seq(from = -3, to = 3, length = 1000), mean = 0, sd = 1)\n\n###| Density curve\nhist(sample, prob = TRUE, ylim = c(0,max(norm_seq)))\nlines(density(sample))\nlines(seq,norm_seq, col = \"red\",lwd = 2)\nlegend(x = \"topright\", # position\n       legend = c(\"Sample curve\",\"Normal curve\"),\n       col = c(\"black\",\"red\"),\n       lwd = c(1,2))\n```\n\n\n\n\n\n\n\n\n\n\n\nBox plots\nFinally, we will consider box plots. We can plot the box plot of a single sample.\n\n\nCode\n```{r}\n###| Generating a sample\nsample &lt;- rnorm(n = 100, mean = 5, sd = 2)\n\n###| Boxplot\nboxplot(sample)\n```\n\n\n\n\n\n\n\n\n\nFor multiple boxplots, we can construct a data frame and plot accordingly.\n\n\nCode\n```{r}\n###| Data frame\ndf &lt;- data.frame(\"A\" = rnorm(n = 10, mean = 0, sd = 1),\n                 \"B\" = rnorm(n = 10, mean = 0, sd = 1),\n                 \"C\" = rnorm(n = 10, mean = 0, sd = 1))\n\n###| Box plot\nboxplot(df)\n```\n\n\n\n\n\n\n\n\n\nWe can add labels and titles.\n\n\nCode\n```{r}\n###| Box plot with labels\nboxplot(df, main = \"Title\", ylab = \"Sample values\", xlab = \"Categories\")\n```\n\n\n\n\n\n\n\n\n\n\n\nCheck your understanding\nGenerate scatterplots, line graphs, histograms and box plots with samples from Poisson and Binomial distributions. Add legends and appropriate titles to each graph.",
    "crumbs": [
      "Home",
      "Introduction to R",
      "Figures"
    ]
  },
  {
    "objectID": "Introduction to R/figures.html#scatterplots",
    "href": "Introduction to R/figures.html#scatterplots",
    "title": "Figures",
    "section": "Scatterplots",
    "text": "Scatterplots\nWe will start by generating a sample from a \\(\\text{Uniform}[0,1]\\) distribution and plotting a scatter plot.\n\n\nCode\n```{r}\n##| Generating a sample\nsample &lt;- runif(n = 100, min = 0, max = 1)\n\n###| Scatterplot\nplot(sample)\n```\n\n\n\n\n\n\n\n\n\nIf we sort the sample by size, we can create a plot that increases from left to right.\n\n\nCode\n```{r}\n###| Ordered sample scatter plot\nplot(sort(sample))\n```\n\n\n\n\n\n\n\n\n\nThe x and y labs are not clear. We should change these by adding in the xlab and ylab arguments. We should also add a title for clarity!\n\n\nCode\n```{r}\n###| x and y labels and title (called main) \nplot(sort(sample), xlab = \"Ordered index\", ylab = \"Sample\", main = \"Title\")\n```\n\n\n\n\n\n\n\n\n\nWe observe a linear relationship between the ordered samples. Let us test this by adding a line to this graph using ‘abline()’.\n\n\nCode\n```{r}\n###| Using abline\nplot(sort(sample), xlab = \"Ordered index\", ylab = \"Sample\", main = \"Title\")\nabline(a = 0,b=0.01)\n```\n\n\n\n\n\n\n\n\n\nIt is quite hard to see both the points and the line at the same time. We can change the aesthetics (colour, shape and size) to make this easier to see. Additional point shapes are available here.\n\n\nCode\n```{r}\n###| Aesthetics - colour and points\nplot(sort(sample), xlab = \"Ordered index\", ylab = \"Sample\", main = \"Title\", \n     col = \"red\", pch = 3)        # we start a new line for readability :)\nabline(a = 0,b=0.01, col = \"blue\")\n```\n\n\n\n\n\n\n\n\n\nSuppose we wanted to add additional lines, at the Sample = 0.5 and at the 50th index. We can add these using ‘abline()’. We can also distinguish them by changing colour, line thickness and line type. Additional details are available here.\n\n\nCode\n```{r}\n###| Aesthetics - line\nplot(sort(sample), xlab = \"Ordered index\", ylab = \"Sample\", main = \"Title\", \n     col = \"red\", pch = 3)\nabline(a = 0,b=0.01, col = \"blue\") \nabline(h=0.5, col = \"black\", lwd = 1, lty = 3) # Note that h here is a horizontal line at sample = 0.5\nabline(v=50, col = \"black\", lwd = 1, lty = 4)  # v here is a vertical line at index = 50\n```",
    "crumbs": [
      "Home",
      "Introduction to R",
      "Figures"
    ]
  },
  {
    "objectID": "Introduction to R/figures.html#line-graphs",
    "href": "Introduction to R/figures.html#line-graphs",
    "title": "Figures",
    "section": "Line graphs",
    "text": "Line graphs\nNow, we move to generating a line graph. We will generate a new sample, this time from a \\(\\text{Normal}(0,1)\\) distribution.\n\n\nCode\n```{r}\n###| Generate sample\nsample &lt;- rnorm(n = 30, mean = 0, sd = 1)\n\n###| Line graph\nplot(sample, type = \"l\")\n```\n\n\n\n\n\n\n\n\n\nSuppose we also want to show the points. We change the type from “l” to “b”.\n\n\nCode\n```{r}\n###| Line graph with points\nplot(sample, type = \"b\")\n```\n\n\n\n\n\n\n\n\n\nAgain, we can play with the aesthetics of these graphs.\n\n\nCode\n```{r}\n###| Line graph aesthetics\nplot(sample, type = \"l\", lwd = 2, lty = 3)\nplot(sample, type = \"b\", lwd = 1, lty = 5, pch = 17, col = 3)\n```\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSuppose we have another sample generated from a \\(\\text{Normal}(0,2)\\). We can show both lines on the same graph.\n\n\nCode\n```{r}\n###| For reproducibility\nset.seed(68)\n\n###| Generate 2 samples\nsample1 &lt;- rnorm(n=30, mean = 0, sd = 1)\nsample2 &lt;- rnorm(n=30, mean = 0, sd = 2)\n\n###| Line plot with multiple lines\nplot(sample1, type = \"l\")\nlines(sample2)\n```\n\n\n\n\n\n\n\n\n\nWe have something, but it appears the top is cut off the graph (this is beacuse we are adding sample 2 onto sample 1 and sample 2 has a larger range). We can change the y axis limits.\n\n\nCode\n```{r}\n###| Line plot with multiple lines with limits\nplot(sample1, type = \"l\", ylim = c(-4,4))\nlines(sample2)\n```\n\n\n\n\n\n\n\n\n\nWe should also change the colours for readability.\n\n\nCode\n```{r}\n###| Line plot with multiple lines with limits\nplot(sample1, type = \"l\", ylim = c(-4,4), col = \"blue\")\nlines(sample2)\n```\n\n\n\n\n\n\n\n\n\nWe can have different types of lines in the same graph as well.\n\n\nCode\n```{r}\n###| Line plot with multiple line types\nplot(sample1, type = \"l\", ylim = c(-4,4), col = \"blue\")\nlines(sample2, lty = 4, type = \"b\")\n```",
    "crumbs": [
      "Home",
      "Introduction to R",
      "Figures"
    ]
  },
  {
    "objectID": "Introduction to R/figures.html#histograms",
    "href": "Introduction to R/figures.html#histograms",
    "title": "Figures",
    "section": "Histograms",
    "text": "Histograms\nSuppose instead we want to look at the distribution of the sample, and test if it aligns with the distribution we expect. To do this, we will up the number of samples (200) and will look at the histogram graph.\n\n\nCode\n```{r}\n###| Sample\nsample &lt;- rnorm(n=200, mean = 0, sd =1)\n\n###| Histogram\nhist(sample)\n```\n\n\n\n\n\n\n\n\n\nIf we want to have the probability on the y axis instead, we need to change the freq argument to FALSE or we change the prob argument to TRUE.\n\n\nCode\n```{r}\n###| Density graph\nhist(sample, freq = FALSE)\nhist(sample, prob = TRUE)\n```\n\n\n\n\n\n\n\n\n\nThe widths of the boxes are quite large. We can change this with the breaks argument.\n\n\nCode\n```{r}\n###| Set number of breaks\nhist(sample, breaks = 10) # 10 boxes\nhist(sample, breaks = 20) # 20 boxes\n\n###| Different size boxes\nhist(sample, breaks = c(min(sample),-1.5,0,0.5,1,max(sample))) \n      # need min and max to ensure range works\n```\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe can also change the labels and add a title.\n\n\nCode\n```{r}\n###| Labels and title\nhist(sample, breaks = 20, xlab = \"Sample\", main = \"Title\")  \n```\n\n\n\n\n\n\n\n\n\nNow, lets compare this to the normal distribution. First, we can add the density curve of the sample.\n\n\nCode\n```{r}\nsample &lt;- rnorm(n = 1000, mean = 0, sd = 1) # Increasing sample count\n\n###| Density curve\nhist(sample, prob = TRUE)\nlines(density(sample))\n```\n\n\n\n\n\n\n\n\n\nWe can then add the normal distribution curve on top to allow comparison.\n\n\nCode\n```{r}\n###| Normal\nseq &lt;- seq(from = -3, to = 3, length = 1000)\nnorm_seq &lt;- dnorm(seq(from = -3, to = 3, length = 1000), mean = 0, sd = 1)\n\n###| Density curve\nhist(sample, prob = TRUE, ylim = c(0,max(norm_seq)))\nlines(density(sample))\nlines(seq,norm_seq, col = \"red\",lwd = 2)\n```\n\n\n\n\n\n\n\n\n\nThe sample distribution is very similar to the normal distribution curve (although the sample has 2 peaks rather than 1). However, it is confusing to have 2 lines without any labels. So, let us add a legend. Additional details appear here.\n\n\nCode\n```{r}\n###| Normal\nseq &lt;- seq(from = -3, to = 3, length = 1000)\nnorm_seq &lt;- dnorm(seq(from = -3, to = 3, length = 1000), mean = 0, sd = 1)\n\n###| Density curve\nhist(sample, prob = TRUE, ylim = c(0,max(norm_seq)))\nlines(density(sample))\nlines(seq,norm_seq, col = \"red\",lwd = 2)\nlegend(x = \"topright\", # position\n       legend = c(\"Sample curve\",\"Normal curve\"),\n       col = c(\"black\",\"red\"),\n       lwd = c(1,2))\n```",
    "crumbs": [
      "Home",
      "Introduction to R",
      "Figures"
    ]
  },
  {
    "objectID": "Introduction to R/figures.html#box-plots",
    "href": "Introduction to R/figures.html#box-plots",
    "title": "Figures",
    "section": "Box plots",
    "text": "Box plots\nFinally, we will consider box plots. We can plot the box plot of a single sample.\n\n\nCode\n```{r}\n###| Generating a sample\nsample &lt;- rnorm(n = 100, mean = 5, sd = 2)\n\n###| Boxplot\nboxplot(sample)\n```\n\n\n\n\n\n\n\n\n\nFor multiple boxplots, we can construct a data frame and plot accordingly.\n\n\nCode\n```{r}\n###| Data frame\ndf &lt;- data.frame(\"A\" = rnorm(n = 10, mean = 0, sd = 1),\n                 \"B\" = rnorm(n = 10, mean = 0, sd = 1),\n                 \"C\" = rnorm(n = 10, mean = 0, sd = 1))\n\n###| Box plot\nboxplot(df)\n```\n\n\n\n\n\n\n\n\n\nWe can add labels and titles.\n\n\nCode\n```{r}\n###| Box plot with labels\nboxplot(df, main = \"Title\", ylab = \"Sample values\", xlab = \"Categories\")\n```",
    "crumbs": [
      "Home",
      "Introduction to R",
      "Figures"
    ]
  },
  {
    "objectID": "Introduction to R/figures.html#check-your-understanding",
    "href": "Introduction to R/figures.html#check-your-understanding",
    "title": "Figures",
    "section": "Check your understanding",
    "text": "Check your understanding\nGenerate scatterplots, line graphs, histograms and box plots with samples from Poisson and Binomial distributions. Add legends and appropriate titles to each graph.",
    "crumbs": [
      "Home",
      "Introduction to R",
      "Figures"
    ]
  },
  {
    "objectID": "Introduction to R/data types.html",
    "href": "Introduction to R/data types.html",
    "title": "Data types",
    "section": "",
    "text": "Before we start coding in R, we need to be familiar with how R stores data - i.e. we need to review the data types in R. The following table states the 6 data types and what they store.\n\nData types\n\n\n\n\n\n\nData type name\nStores\n\n\n\n\nLogical or Boolean\nTRUE or FALSE\n\n\nNumeric\na real number, including decimal values\n\n\nInteger\nan integer number (i.e. no decimal values)\n\n\nComplex\nan imaginary value\n\n\nCharacter\ncharacter or string values, for example a letter ‘A’, typically surrounded by '' or \"\"\n\n\nRaw\nraw bytes (0 or 1s)\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nNumeric and integer are different data types! When inputting data, any integer value will be stored as a numeric data type unless we add an L to the end. For example, 5 will be stored as a numeric data type but 5L will be stored as a integer.\n\n\n\nWhat data type is this variable?\nWe can check what data type a variable is using class(). Alternatively, we can confirm if a variable is an integer, logical or a character using is.integer(), is.logical() and is.character() respectively.\n\n\nCode\n```{r}\n###| Character\ncharacter &lt;- \"a banana\"\n\nclass(character)\nis.character(character)\n\n###| Numeric v integer\nnumber &lt;- 5\ninteger &lt;- as.integer(5)\n\nclass(number)\nis.integer(number)\n\nclass(integer)\nis.integer(integer)\n\n###| Decimal value\ndecimal &lt;- 0.5\n\nclass(decimal)\nis.integer(decimal)\n\n###| Logical value\nis.logical(TRUE)\nis.logical(FALSE)\n```\n\n\n[1] \"character\"\n[1] TRUE\n[1] \"numeric\"\n[1] FALSE\n[1] \"integer\"\n[1] TRUE\n[1] \"numeric\"\n[1] FALSE\n[1] TRUE\n[1] TRUE\n\n\n\n\nCoercion (changing data type)\nWe can force a variable to switch data type using as.numeric(), as.logical(), as.character() and as.integer().\n\n\nCode\n```{r}\n###| Coercing a boolean variable\nas.numeric(TRUE)\nas.numeric(FALSE)\nas.character(TRUE)\nas.character(FALSE)\n```\n\n\n[1] 1\n[1] 0\n[1] \"TRUE\"\n[1] \"FALSE\"\n\n\n\n\nCode\n```{r}\n###| Coercing a character variable\nas.numeric(\"a\") # this will produce an error!\n```\n\n\nWarning: NAs introduced by coercion\n\n\n[1] NA\n\n\n\n\nCode\n```{r}\n###| Coercing a character variable\nas.character(\"a\")\n\n###| Coercing a numeric variable\nas.numeric(2) \nas.character(2)\n\n###| Coercing to a logic variable\nas.logical(1)\nas.logical(0)\n\nas.logical(\"TRUE\")\nas.logical(\"FALSE\")\n```\n\n\n[1] \"a\"\n[1] 2\n[1] \"2\"\n[1] TRUE\n[1] FALSE\n[1] TRUE\n[1] FALSE\n\n\n\n\nCheck your understanding\nIdentify the following variable’s data type with and without using R:\n\n\na = 2025\nb = “3.14”\nc = pi\nd = TRUE\ne = c(1,0)\nf = 2022L\n\n\n\n\nCode\n```{r}\n#| code-fold: true\n\n###| Answers\nclass(2025)\nclass(\"3.14\")\nclass(pi)\nclass(TRUE)\nclass(c(1,0))\nclass(2022L)\n```\n\n\n[1] \"numeric\"\n[1] \"character\"\n[1] \"numeric\"\n[1] \"logical\"\n[1] \"numeric\"\n[1] \"integer\"",
    "crumbs": [
      "Home",
      "Introduction to R",
      "Data types"
    ]
  },
  {
    "objectID": "Introduction to R/control structures.html",
    "href": "Introduction to R/control structures.html",
    "title": "Control structures",
    "section": "",
    "text": "Control structures allow us to influence the order in which lines of code are executed. It allows for repetition and conditional arguments and more.\nThe main 2 are:\n\n\nConditional:\n\nif()\nif() else()\n\nRepeat:\n\nfor()\nwhile()\n\n\n\nThese are not always efficient as they can take a relatively long processing time compared to other code. However, for now, do not worry about computation time.\n\nIf statements\nThe code of code after an if statement is only executed if the condition within the if statement is met.\n\n\n\n\n\nflowchart LR\n  A{statement A} --&gt; B[Do this if true.]\n  A --&gt; C[Do nothing.]\n\n\n\n\n\n\nFor example, we can check ‘if 5 \\(&lt;\\) 7’ and ask the computer to output “Hello world.” if it is true.\n\n\nCode\n```{r}\n###| Example of if()\nif (5&lt;7) {\n  print(\"Hello world.\")\n}\n```\n\n\n[1] \"Hello world.\"\n\n\nMoreover, we can add an additional condition. If ‘if 5 \\(&lt;\\) 7’ is false, we can specify what we would like the computer to do instead using an else() command. (In this case, we output “It.”. )\n\n\nCode\n```{r}\n###| Example of if() and else()\nif (5 &gt; 7) {\n  print(\"Not it.\")\n} else {\n    print(\"It.\")\n}\n```\n\n\n[1] \"It.\"\n\n\nNow, our flow diagram looks like this.\n\n\n\n\n\nflowchart LR\n  A{statement A} --&gt; B[Do X if true.]\n  A --&gt; C[Do Y if false]\n\n\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nWe can nest if statements inside of each other.\n\n\nOne such example is the following function that checks if a number is a multiple of \\(2\\), \\(3\\), \\(5\\) or \\(7\\).\n\n\nCode\n```{r}\n###| Nested if statement example\n\n# Function to check divisibility by 2, 3, 5, or 7\ncheck_divisibility &lt;- function(num) {\n  # Ensure the input is numeric\n  if (!is.numeric(num)) {\n    return(\"Please provide a numeric input.\")\n  }\n  \n  # Check divisibility by 2\n  if (num %% 2 == 0) {\n    return(\"The number is divisible by 2.\")\n  } else if (num %% 3 == 0) { # Check divisibility by 3\n    return(\"The number is divisible by 3.\")\n  } else if (num %% 5 == 0) { # Check divisibility by 5\n    return(\"The number is divisible by 5.\")\n  } else if (num %% 7 == 0) { # Check divisibility by 7\n    return(\"The number is divisible by 7.\")\n  } else { # If none of the above conditions are true\n    return(\"The number is not divisible by 2, 3, 5, or 7.\")\n  }\n}\n\n# Example usage:\ncheck_divisibility(14) # Output: \"The number is divisible by 2.\"\ncheck_divisibility(21) # Output: \"The number is divisible by 3.\"\ncheck_divisibility(25) # Output: \"The number is divisible by 5.\"\ncheck_divisibility(49) # Output: \"The number is divisible by 7.\"\ncheck_divisibility(11) # Output: \"The number is not divisible by 2, 3, 5, or 7.\"\n```\n\n\n[1] \"The number is divisible by 2.\"\n[1] \"The number is divisible by 3.\"\n[1] \"The number is divisible by 5.\"\n[1] \"The number is divisible by 7.\"\n[1] \"The number is not divisible by 2, 3, 5, or 7.\"\n\n\nThe following illustrates this as a flow diagram:\n\n\n\n\n\ngraph TD\n    A[Start] --&gt; B{Is input numeric?}\n    B -- No --&gt; C[\"Please provide a numeric input.\"]\n    B -- Yes --&gt; D{Is the number divisible by 2?}\n    D -- Yes --&gt; E[\"The number is divisible by 2.\"]\n    D -- No --&gt; F{Is the number divisible by 3?}\n    F -- Yes --&gt; G[\"The number is divisible by 3.\"]\n    F -- No --&gt; H{Is the number divisible by 5?}\n    H -- Yes --&gt; I[\"The number is divisible by 5.\"]\n    H -- No --&gt; J{Is the number divisible by 7?}\n    J -- Yes --&gt; K[\"The number is divisible by 7.\"]\n    J -- No --&gt; L[\"The number is not divisible by 2, 3, 5, or 7.\"]\n\n\n\n\n\n\nIn this instance, we can stop when we find the smallest number that is a factor of the input. However, we may want to check every case.\n\n\nFor loops\nThe for loop allows code to be executed repeatedly until a given iteration.\n\n\n\n\n\ngraph TD\n    A[Start] --&gt; B[Initialize loop variable]\n    B --&gt; C{Condition met?}\n    C -- No --&gt; D[Exit loop]\n    C -- Yes --&gt; E[Execute loop body]\n    E --&gt; F[Update loop variable]\n    F --&gt; C\n    D --&gt; G[End]\n\n\n\n\n\n\nSuppose we want to print the numbers 1, 2, 3 and 4. We can use a for loop for this:\n\n\nCode\n```{r}\n###| For loop example\nfor (x in c(1:4)) {\n  print(x)\n}\n```\n\n\n[1] 1\n[1] 2\n[1] 3\n[1] 4\n\n\n\n\n\n\n\n\nImportant\n\n\n\nR will automatically increase the counter. We do not need to include x&lt;-x+1 as we do in Python.\n\n\nAlternatively, suppose we wanted to print the number 1, then the numbers 1 to 3, then the number 2, then 1 to 3 again, then 3 … . We can use nested for loops for this:\n\n\nCode\n```{r}\n###| Nested loop\nfor (x in c(1:4)) {\n  print(x)\n  for (y in c(1:3)) {\n    print(y)\n  }\n}\n```\n\n\n[1] 1\n[1] 1\n[1] 2\n[1] 3\n[1] 2\n[1] 1\n[1] 2\n[1] 3\n[1] 3\n[1] 1\n[1] 2\n[1] 3\n[1] 4\n[1] 1\n[1] 2\n[1] 3\n\n\n\n\nWhile loops\nWhile loop tests if a condition is true and will continue running the code until the condition is false.\n\n\n\n\n\ngraph TD\n    A[Start] --&gt; B{Condition met?}\n    B -- No --&gt; C[Exit loop]\n    B -- Yes --&gt; D[Execute loop body]\n    D --&gt; B\n    C --&gt; E[End]\n\n\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nIt is very important to avoid infinite loops!!\n\n\n\n\nCode\n```{r}\n###| While loop example\ni &lt;- 1\nwhile (i &lt;= 5){\n  print(i)\n  i &lt;- i + 1\n}\n```\n\n\n[1] 1\n[1] 2\n[1] 3\n[1] 4\n[1] 5\n\n\n\n\nExample combining if, for and while loops\n\n\nCode\n```{r}\n# Initialize variables\nx &lt;- 1    # Start value for while loop\nresults &lt;- c()  # Empty vector to store results\n\n# While loop: Run while x is less than or equal to 10\nwhile (x &lt;= 10) {\n  # For loop: Iterate through numbers 1 to 5\n  for (y in 1:5) {\n    # If statement: Check if the product of x and y is even\n    if ((x * y) %% 2 == 0) {\n      # Add the product to the results vector if even\n      results &lt;- c(results, x * y)\n    }\n  }\n  # Increment x to avoid infinite loop\n  x &lt;- x + 1\n}\n\n# Print the results\nprint(\"Results of even products:\")\nprint(results)\n```\n\n\n[1] \"Results of even products:\"\n [1]  2  4  2  4  6  8 10  6 12  4  8 12 16 20 10 20  6 12 18 24 30 14 28  8 16\n[26] 24 32 40 18 36 10 20 30 40 50\n\n\n\n\nCheck your understanding\nAnswer the following questions using if(), for() and while() loops.\n\n\nGiven a number, print “Positive” or “Negative” depending on if the number is positive or negative. If the number is 0, print both.\nGiven a vector, find the maximum and minimum value. Thus find out the range.\n\n\n\n\nCode\n```{r}\n#| code-fold: true\n###| Answers\nx=-1\nif (x &gt; 0) {\n  print(\"positive\")\n} else if (x &lt; 0) {\n  print(\"negative\")\n} else {print(\"both\")}\n```\n\n\n[1] \"negative\"\n\n\n\n\nCode\n```{r}\n#| code-fold: true\n###| Answers\nx &lt;- c(0,1,2,7,-5)\nn &lt;- length(x)\nmin &lt;- x[1]\nmax &lt;- x[1]\n\nfor(i in 1:n){\n  if (x[i] &lt; min) {\n    min &lt;- x[i]\n  }\n  if (x[i] &gt; max) {\n    max &lt;- x[i]\n  }\n}\n\nprint(paste(\"Range is\",max-min))\n```\n\n\n[1] \"Range is 12\"",
    "crumbs": [
      "Home",
      "Introduction to R",
      "Control structures"
    ]
  },
  {
    "objectID": "Introduction to R/operators.html",
    "href": "Introduction to R/operators.html",
    "title": "Operations",
    "section": "",
    "text": "We will begin by familiarising ourselves with the operations in R, where\n\n“an operator is a character, or characters, that determine what action is to be performed or considered”,\n\naccording to the BBC Bitesize website. These will form the base building blocks of everything we will do in the future.\nWe will start with arithmetic operators (\\(+\\),\\(-\\),\\(\\times\\),\\(\\div\\)), then go to comparison operators (\\(=\\),\\(\\ne\\),\\(\\geq\\),\\(\\leq\\)) and finally logical operators (and, or).\n\nArithmetic operators\nThe 4 base arithmetic operators are addition (+), subtraction (-), multiplication (*) and division (/). The following are some base examples of how these can be used.\n\n\nCode\n```{r}\n###| Addition\n3+10\n\n###| Subtraction\n6-2\n\n###| Multiplication\n5*15\n\n###| Division\n23/7\n```\n\n\n[1] 13\n[1] 4\n[1] 75\n[1] 3.285714\n\n\n\n\n\n\n\n\nNote\n\n\n\nIt is important to note that R follows the traditional BODMASS order of operations. As such, we can use brackets to control the order in which operations are performed.\n\n\n\n\nCode\n```{r}\n###| BODMASS\n(1+7)/2\n1 + 7/2\n3*5+2/3\n3*(5+2)/3\n```\n\n\n[1] 4\n[1] 4.5\n[1] 15.66667\n[1] 7\n\n\nWe can also do exponents (to the power of) using ^ or **, and we can find the modulo using %% and %/%\n\n\nCode\n```{r}\n###| Exponents \n5^2\n5**2\n\n4^(1/2)\n4**0.5\n```\n\n\n[1] 25\n[1] 25\n[1] 2\n[1] 2\n\n\n\n\nCode\n```{r}\n###| Modulo\n10 %% 2 # remainder of 10 divided by 2\n10 %% 4\n\n10 %/% 2 # how many times 2 goes into 10\n10 %/% 4\n```\n\n\n[1] 0\n[1] 2\n[1] 5\n[1] 2\n\n\n\n\nComparison operators\nComparison operators compare 2 values to one another and will return TRUE or FALSE.\nThe 2 operators that can be used for any data type are equal to == and not equal to !=.\nWe can also compare two numbers using less than &lt;, less than or equal to &lt;=, greater than &gt;, and greater than or equal to &gt;=.\n\n\nCode\n```{r}\n###| Equal to\n\"a banana\" == \"a banana\"\n\"a banana\" == \"a fruit\"\n\n7 == 5\n5 == 5\n\n###| Not wqual to\n\"a banana\" != \"a banana\"\n\"a banana\" != \"a fruit\"\n\n7 != 5\n5 != 5\n```\n\n\n[1] TRUE\n[1] FALSE\n[1] FALSE\n[1] TRUE\n[1] FALSE\n[1] TRUE\n[1] TRUE\n[1] FALSE\n\n\n\n\nCode\n```{r}\n###| Less than\n5 &lt; 7 \n7 &lt; 5\n5 &lt; 5 # note that this will return FALSE!\n\n###| Greater than\n5 &gt; 7 \n7 &gt; 5\n5 &gt; 5 # note that this will return FALSE!\n\n###| Less than or equal to\n5 &lt;= 7 \n7 &lt;= 5\n5 &lt;= 5 # note that this will return TRUE!\n\n###| Greater than or equal to\n5 &gt;= 7 \n7 &gt;= 5\n5 &gt;= 5 # note that this will return TRUE!\n```\n\n\n[1] TRUE\n[1] FALSE\n[1] FALSE\n[1] FALSE\n[1] TRUE\n[1] FALSE\n[1] TRUE\n[1] FALSE\n[1] TRUE\n[1] FALSE\n[1] TRUE\n[1] TRUE\n\n\n\n\nLogical operators\nLogical operators allow us to combine things or negate something.\nIf we want to find the negative, we use the ! operator. For example, we may want to say something is not true. we do this with !TRUE. Or we may want to check if 5 is not less than 7, !(5&lt;7).\n\n\nCode\n```{r}\n###| Negation of TRUE FALSE\nTRUE\n!(TRUE)\n\nFALSE\n!(TRUE)\n```\n\n\n[1] TRUE\n[1] FALSE\n[1] FALSE\n[1] FALSE\n\n\n\n\nCode\n```{r}\n###| Example of negation on relational operators\n5&lt;7\n!(5&lt;7)\n\n5==7\n!(5==7)\n```\n\n\n[1] TRUE\n[1] FALSE\n[1] FALSE\n[1] TRUE\n\n\nWe can also combine operators using AND, &. For example, we may want to check that 5&lt;7 and 10&lt;12. Alternatively, we may want to allow A or B to be true. We do this with |.\n\n\nCode\n```{r}\n###| And on TRUE FALSE\nTRUE & TRUE\nFALSE & FALSE\nTRUE & FALSE\n\n###| And on relational operators example\n(7&gt;5) & (10&lt;12)\n(7&lt;5) & (10&gt;12)\n(7&lt;5) & (10&lt;12)\n```\n\n\n[1] TRUE\n[1] FALSE\n[1] FALSE\n[1] TRUE\n[1] FALSE\n[1] FALSE\n\n\n\n\nCode\n```{r}\n###| OR on TRUE FALSE\nTRUE | TRUE\nFALSE | FALSE\nTRUE | FALSE\n\n###| OR on relational operators example\n(7&gt;5) | (10&lt;12)\n(7&lt;5) | (10&gt;12)\n(7&lt;5) | (10&lt;12)\n```\n\n\n[1] TRUE\n[1] FALSE\n[1] TRUE\n[1] TRUE\n[1] FALSE\n[1] TRUE\n\n\n\n\nCheck your understanding\nThe following are some extercises to test your understanding about operations.\n\n\nUse R to determine the area of a circle with diameter of 20cm.\n\nHint: pi is recognised in R.\n\nCalculate the cube root of 14 \\(\\times\\) 0.51.\n\nHint: think carefully about the order of operations.\n\nTest the following statement in R: Not (4 squared is greater than or equal to 15, or (the sum of 7 and 10 is less than 16)).\n\nHint: the output should be FALSE.\n\n\n\n(The code is hidden to give you a chance to practise. However, if you toggle the &gt;, example code will appear.)\n\n\nCode\n```{r}\n#| code-fold: true\n\n###| Answers\n(10^2)*pi\n(14 * 0.51)^(3)\n!( 4&lt;=15 | 7+10 &lt; 16)\n```\n\n\n[1] 314.1593\n[1] 363.9943\n[1] FALSE",
    "crumbs": [
      "Home",
      "Introduction to R",
      "Operations"
    ]
  },
  {
    "objectID": "Introduction to R/functions.html",
    "href": "Introduction to R/functions.html",
    "title": "Custom functions",
    "section": "",
    "text": "A function is a piece of code written to carry out a specific task. It can take in inputs and may return one or more values.\nThe 3 main components are:\n\n\nThe formals(): the list of arguments/inputs of the function\nThe body(): the code in the function\nThe environment(): the map of the location of the function’s variable\n\n\nA function follows the following general structure:\n\n\nfunction_name &lt;- function(arguments) {function body}\n\n\nCustom functions are used to incorporate sets of instructions that you want to use repeatedly, or that are easier to store so they can be called when needed.\nFunctions are created using function() and are stored as R objects. They can also be passed to other functions as arguments (as input) and can be nested (functions can be inside other functions).\n\n\nCode\n```{r}\n###| Function example 1\nadd &lt;- function(x,y){\n  x + y\n}\n\nadd(2,4)\n\n###| Function example 2\nsquare &lt;- function(x){\n  x^2\n}\n\nsquare(7)\n```\n\n\n[1] 6\n[1] 49\n\n\n\nCheck your understanding\nWrite functions that do the following things:\n\n\nCreate a function which returns integer division of x by y and the remainder\nCreate a function which finds the area and circumference of a circle given a radius r.\nCreate a function that calculates the factorial of some number n.\n\nHint: make sure that n is an integer!\n\n\n\n\n\nCode\n```{r}\n#| code-fold: true\n###| Answer\n\nmodulus &lt;- function(x,y) {\n  remainder &lt;- x %% y\n  multiple &lt;- x %/% y\n  print(paste(\"x modulo y is\", multiple, \"with remainder\", remainder))\n}\n\nmodulus(6,3)\n```\n\n\n[1] \"x modulo y is 2 with remainder 0\"\n\n\n\n\nCode\n```{r}\n#| code-fold: true\n###| Answer\n\ncircle &lt;- function(r){\n  area &lt;- r^2 * pi\n  circumference &lt;- 2*r*pi\n  print(paste(\"Area is\",area, \"and the circumference is\",circumference))\n}\n\ncircle(5)\n```\n\n\n[1] \"Area is 78.5398163397448 and the circumference is 31.4159265358979\"\n\n\n\n\nCode\n```{r}\n#| code-fold: true\n###| Answer\n\nfactorial &lt;- function(x) {\n  \n  if (x%%1 == 0) {\n    \n    factorial &lt;- 1\n    \n    while (x &gt;= 1) {\n      factorial &lt;- factorial * x\n      x &lt;- x - 1\n    }\n    \n    print(factorial)\n  } else {\n    print(paste(x,\" is not a positive integer\"))\n  }\n}\n\nfactorial(2) \n```\n\n\n[1] 2",
    "crumbs": [
      "Home",
      "Introduction to R",
      "Custom functions"
    ]
  },
  {
    "objectID": "Introduction to R/variables.html",
    "href": "Introduction to R/variables.html",
    "title": "Variables",
    "section": "",
    "text": "Thus far, we have covered some very important content. However, it is not in a practical, useable form. Instead of having to rewrite values each time, we want to be able to have the computer remember them (store them) so that we can recall them. We do this using variables.\nWe can assign a value to a named variable using = or -\\&gt;. (Note that we use = for assigning variables and == for check if equal!) We can check what our variable is by outputting it.\n\n\nCode\n```{r}\n###| Assigning a variable\nx &lt;- 5\ny = TRUE\n\n###| Outputting a variable\nx\ny\n```\n\n\n[1] 5\n[1] TRUE\n\n\nWe can use all our previous operators on variables. The following are just some examples of how we can do this.\n\n\nCode\n```{r}\n###| Assigning variables\na = 1\nb = 2\nc = 3\nd = 4\ne = 5\n\n###| Arithmetic operators\nd %% b\nc + d\na * e - d\n\n###| Relational operators\nd &lt; b\nc &gt; d\nc == d\n\n###| Logical operators \n(d &lt; b) & (c &gt; d)\n(d &lt; b) | (c &gt; d)\n!(d &lt; b)\n```\n\n\n[1] 0\n[1] 7\n[1] 1\n[1] FALSE\n[1] FALSE\n[1] FALSE\n[1] FALSE\n[1] FALSE\n[1] TRUE\n\n\n\nCheck your understanding\nThe following are some extercises to test your understanding about variables.\n\n\nDefine variables called velocity, time and acceleration with 5, 10 and 9.8 respectively. Calculate the displacement.\n\nHint: \\(s = ut+0.5at^2\\).\n\nDefine variables height and width of a rectangle with initial values 5 and 10. Calculate the area of the rectangle.\nExtension: given \\(f(x)=\\frac{1}{\\sqrt{2\\pi}}\\exp{(-\\frac{1}{2}x^2)}\\), find \\(f(5)\\).\n\nHint: look at sqrt() and exp().\n\n\n\n\n\nCode\n```{r}\n#| code-fold: true\n\n###| Answers\nvecolity &lt;- 5\ntime &lt;- 10\nacceleration &lt;- 9.8\ndisplacement &lt;- vecolity * time + 0.5 * acceleration * time^2\ndisplacement\n\nheight &lt;- 5\nwidth &lt;- 10\narea &lt;- height * width\narea\n\n###| Extension question\nx &lt;- 5\nf_x &lt;- 1/sqrt(2*pi)*exp(-0.5*x^2)\nf_x\n```\n\n\n[1] 540\n[1] 50\n[1] 1.48672e-06",
    "crumbs": [
      "Home",
      "Introduction to R",
      "Variables"
    ]
  },
  {
    "objectID": "Introduction to R/data structures.html",
    "href": "Introduction to R/data structures.html",
    "title": "Data structures",
    "section": "",
    "text": "Data structures are the ways in which data is stored. The following table indicates the main 5 ways.",
    "crumbs": [
      "Home",
      "Introduction to R",
      "Data structures"
    ]
  },
  {
    "objectID": "Introduction to R/data structures.html#vectors-arithmetic",
    "href": "Introduction to R/data structures.html#vectors-arithmetic",
    "title": "Data structures",
    "section": "Vectors: Arithmetic",
    "text": "Vectors: Arithmetic\nWe can apply arithmetic to vectors. We can multiple, add and subtract vectors.\n\n\nCode\n```{r}\n###| Vector arithmetic\nx &lt;- c(1,2,3)\n\nx + 3\nx * 3\nx * x\n```\n\n\n[1] 4 5 6\n[1] 3 6 9\n[1] 1 4 9",
    "crumbs": [
      "Home",
      "Introduction to R",
      "Data structures"
    ]
  },
  {
    "objectID": "Introduction to R/data structures.html#vectors-sequences-and-repetition",
    "href": "Introduction to R/data structures.html#vectors-sequences-and-repetition",
    "title": "Data structures",
    "section": "Vectors: Sequences and repetition",
    "text": "Vectors: Sequences and repetition\nWe can generate vectors using seq() and rep() to generate a sequence or repeat a value.\n\n\nCode\n```{r}\n###| Sequence 1\n\n# by will create a vector where each subsequent value is 0.1 larger than the previous\nseq(from = 0, to = 1, by = 0.1) \n\n# length.out will ensure 4 values are stored in the vector\nseq(from = 0, to = 1, length.out = 4) \n```\n\n\n [1] 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0\n[1] 0.0000000 0.3333333 0.6666667 1.0000000\n\n\n\n\nCode\n```{r}\n###| Sequence 2\n\nseq(from = 0, to = 10, by = 2.7) # note that 10 is not in this vector!\n\nseq(from = 0, to = 10, length.out = 4) \n```\n\n\n[1] 0.0 2.7 5.4 8.1\n[1]  0.000000  3.333333  6.666667 10.000000\n\n\n\n\nCode\n```{r}\n###| Repeat\nrep(1,6)\n\nrep(1:3,each = 2) # will repeat each value twice\n\nrep(1:3,2) # will repeat the entire 1:3 twice\n\nrep(1:3,length.out=6) # will repeat 1:3 until it reaches the length.out\n\nrep(1:3,length.out=5) # note that this is only 5 long and so only has one 3!\n```\n\n\n[1] 1 1 1 1 1 1\n[1] 1 1 2 2 3 3\n[1] 1 2 3 1 2 3\n[1] 1 2 3 1 2 3\n[1] 1 2 3 1 2",
    "crumbs": [
      "Home",
      "Introduction to R",
      "Data structures"
    ]
  },
  {
    "objectID": "Introduction to R/data structures.html#vectors-indexing",
    "href": "Introduction to R/data structures.html#vectors-indexing",
    "title": "Data structures",
    "section": "Vectors: Indexing",
    "text": "Vectors: Indexing\nYou can extract data from a vector if you know it’s index (for example, you can extract the 5th value of a vector) using [].\nWe can extract 1 element at a time (see the first example) or we can extract multiple elements at once using vectors (see the second and third examples). We can also extract using a variable (fourth example).\n\n\nCode\n```{r}\n###| Indexing\nx &lt;- c(1,2,3,4,5)\n\nx[3] # extracts the 3rd element\nx[1:3] # extracts elements 1, 2 and 3\nx[c(1,3,5)] # extracts elements 1, 3 and 5\n\n###| Indexing with a named vector\ny &lt;- c(2,4)\nx[y] # extracts elements 2 and 4\n```\n\n\n[1] 3\n[1] 1 2 3\n[1] 1 3 5\n[1] 2 4\n\n\nYou can change the values of a vector using indexes as well.\n\n\nCode\n```{r}\n###| Changing an element\nx &lt;- c(1,2,3,4,5)\n\nx[1] &lt;- 7\nx\n```\n\n\n[1] 7 2 3 4 5\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe number of replacing values must match the number of replaced values, otherwise there is an error (see next example)!\n\n\n\n\nCode\n```{r}\n###| Mismatch in replacement length\nx[2] &lt;- c(1,3)\n```\n\n\nWarning in x[2] &lt;- c(1, 3): number of items to replace is not a multiple of\nreplacement length\n\n\nCode\n```{r}\nx # only the 1st element is used to replace the 2nd value\n```\n\n\n[1] 7 1 3 4 5\n\n\nYou can also remove an element from a vector using [- ].\n\n\nCode\n```{r}\n###| Changing an element\nx &lt;- c(1,2,3,4,5)\nx[-1] \n```\n\n\n[1] 2 3 4 5",
    "crumbs": [
      "Home",
      "Introduction to R",
      "Data structures"
    ]
  },
  {
    "objectID": "Introduction to R/data structures.html#vectors-check-your-understanding",
    "href": "Introduction to R/data structures.html#vectors-check-your-understanding",
    "title": "Data structures",
    "section": "Vectors: Check your understanding",
    "text": "Vectors: Check your understanding\nTo practise sequences and repetition, do the following exercises.\n\n\nCreate a vector from 0 to 100.\nCreate a vector from 100 to 0.\nCreate a vector containing all strictly positive even numbers up to and including 100.\nCreate a vector containing 1 once, 2 twice and 3 thrice, in that order.\n\n\n\n\nCode\n```{r}\n#| code-fold: true\n\n###| Answers\nseq(from = 0, to = 100)\nseq(from = 100, to = 0)\nseq(from = 0, to = 100, by = 2)\n\nrep(1:3,1:3)\n```\n\n\n  [1]   0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n [19]  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n [37]  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n [55]  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n [73]  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n [91]  90  91  92  93  94  95  96  97  98  99 100\n  [1] 100  99  98  97  96  95  94  93  92  91  90  89  88  87  86  85  84  83\n [19]  82  81  80  79  78  77  76  75  74  73  72  71  70  69  68  67  66  65\n [37]  64  63  62  61  60  59  58  57  56  55  54  53  52  51  50  49  48  47\n [55]  46  45  44  43  42  41  40  39  38  37  36  35  34  33  32  31  30  29\n [73]  28  27  26  25  24  23  22  21  20  19  18  17  16  15  14  13  12  11\n [91]  10   9   8   7   6   5   4   3   2   1   0\n [1]   0   2   4   6   8  10  12  14  16  18  20  22  24  26  28  30  32  34  36\n[20]  38  40  42  44  46  48  50  52  54  56  58  60  62  64  66  68  70  72  74\n[39]  76  78  80  82  84  86  88  90  92  94  96  98 100\n[1] 1 2 2 3 3 3",
    "crumbs": [
      "Home",
      "Introduction to R",
      "Data structures"
    ]
  },
  {
    "objectID": "Introduction to R/introduction to r.html",
    "href": "Introduction to R/introduction to r.html",
    "title": "Introduction",
    "section": "",
    "text": "These pages will cover will introduce some key theory about how R operates and the basic building blocks of coding. It ends with generating plots using inbuilt R commands.\nThis section covers:\n\n\nhow R stores data/values (data types, data structures and variables),\nhow to perform operations (arithmetic, comparison and logical),\nhow to control the structure of your code (if, else, for and while),\nhow to write your own functions,\nrandom numbers, and\nplotting graphs.",
    "crumbs": [
      "Home",
      "Introduction to R",
      "Introduction"
    ]
  },
  {
    "objectID": "cheatsheets.html",
    "href": "cheatsheets.html",
    "title": "Cheatsheets",
    "section": "",
    "text": "There is a lot to learn to create beautiful and informative reports using R. In this section, there are several cheatsheets that will hopefully make this learning curve a little easier.\n(If the files are not loading, there also available on the GitHub under the Cheatsheets folder link.)\n\nLatex\nLatex is a language that allows for additional control over figures, tables and maths. The following is a cheatsheet created by Winston Chang, with the original version available here.\n\n\n\nggplot2\nA very popular package for figures is the ggplot2 package. It can be installed and loaded with the following code (although it is included in the tidyverse package).\n\n\nCode\n```{r}\n###| ggplot2 package\n\n#install.packages(\"ggplot2\")\nlibrary(ggplot2)\n```\n\n\nWarning: package 'ggplot2' was built under R version 4.4.3"
  },
  {
    "objectID": "Modelling/What is a linear model.html",
    "href": "Modelling/What is a linear model.html",
    "title": "What is a linear model?",
    "section": "",
    "text": "Important\n\n\n\nA linear model aims predict or explain the relationship between a single outcome variable and one (or more) explanatory variables. It is the simplest form of a regression model.\n\n\nIn this case, a variable is a quantifiable quantity. The observed data is a realisation of the variable, obtained by conducting tests (observations). Variables can be numerical (continuous or discrete) or categorical.\nThe most basic linear model has a single response and explanatory variable. It is of the form:\n\\[y_i = \\alpha + \\beta x_i + \\epsilon_i,\\]\nwhere \\(y_i\\) is the ith observation of the response variable, \\(x_i\\) is the ith observation of the explanatory variable, \\(\\alpha\\) is the intercept, \\(\\beta\\) is the gradient and \\(\\epsilon_i\\) is the error.\n\n\n\n\n\n\nImportant\n\n\n\nRegardless of whether we are fitting a model to predict or explain, our aim is to estimate the parameters.\n\n\n\nDeterministic with error\nIt is important to note that the relationship between explanatory and outcome variables is not deterministic - that is to say, knowing the values of the explanatory variables does not allow you to predict the outcome variable exactly. We can decompose the relationship into the deterministic/systemic component (\\(X\\beta\\)) and random error (\\(\\epsilon\\)):\n\\[\nY = X \\beta + \\epsilon,\n\\] where \\(Y\\in \\mathbb{R}^{n\\times 1}\\) is the outcome/response variable, \\(X \\in \\mathbb{R}^{n\\times p+1}\\) is the design matrix, \\(\\beta \\in \\mathbb{R}^{p+1 \\times 1}\\) is the parameter vector and \\(\\epsilon \\in \\mathbb{R}^{n\\times 1}\\) is the vector of errors.\nHere, we assume we have \\(n\\) data points and \\(p\\) explanatory variables. We have \\(p+1\\) in the dimensions to account for the intercept term.\n\n\nAssumptions\nTo use a linear model, we need to make 4 key assumptions. We will see in later sections how we can relax some of these assumptions to fit a generalised linear model. However, for now, we must make sure our model meets these assumptions:\n\n\nLinearity - the systemic component is linear in parameters, that is, \\[\\mathbb{E}[Y] = \\mathbb{E}[X\\beta].\\] Note that the explanatory variables do not have to be linear. They can be polynomials, log and more!\nHomoscedasticity - the errors must have constant variance, i.e. \\[Var(\\epsilon_1) = Var(\\epsilon_2) = \\; ... \\; = Var(\\epsilon_{n+1}) = \\sigma^2.\\]\nThe errors are independent of each other.\nThe errors are normally distributed, \\[\\epsilon_i \\sim \\text{Normal}(0,\\sigma^2).\\]\n\n\nThere are several things we should note about the response variable as a consequence of these assumptions.\n\n\nIt is univariate.\nIt is continuous.\nIt is stochastic (i.e. has a random element).\nIt has equal variance.\nResponses from different observations are assumed to be uncorrelated. (We will revisit this for time series later.)\n\n\n\n\nLinearity assumption - can we have \\(x^2\\)?\nIt is very important to be careful with the linearity assumption.\nSuppose we are given a dataset. Let \\(y_i\\) denote the ith observation of the response variable. Let \\(x_{i1}\\) denote the ith observation of the first explanatory variable and \\(x_{i2}\\) denote the ith observation of the second explanatory variable.Let \\(\\beta = (a,b,c)^{T}\\).\nThen, which of the following are linear models - i.e. when does \\(\\mathbb{E}[y_i] = \\mathbb{E}[X_i\\beta]\\)?\n\n\n\\(y_i = b x_{i1} + \\epsilon_i\\)\n\\(y_i = a + b x_{i1} + \\epsilon_i\\)\n\\(y_i = a + b^3 x_{i1} + c x_{i2} + \\epsilon_i\\)\n\\(y_i = a + b (x_{i1}-x_{i2})^2 + \\epsilon_i\\)\n\\(y_i = a + b x_{i1} + c \\log(x_{i2}) + \\epsilon_i\\)\n\n\nIn this case, all are linear models except for 3. This is because the parameters are not linear in point 3 as we have \\(b^3\\)!\n\n\nPrinciple of parsimony - simplest is best\nAfter we have checked that our model meets the 4 key assumptions, we must decide what variables to include in our model. We need to balance accuracy and complexity.\nFor example, a model with loads of explanatory variables may give more accurate predictions. However, the more parameters (explanatory variables) we have in a model, the higher the computational cost to fit a linear model.\nThe principle of parsimony states that “given 2 models that behave similarly, we should pick the simpler model”.\nThe exact boundaries of ‘similarly’ are difficult to quantify. Model creation and selection is an art form, and something that requires practise to learn.\n\n\n\n\n\n\nImportant\n\n\n\nImportant exceptions to the ‘pick the simpler model’ principle are the following:\n\n\nIf \\(x^2\\) appears in the model, \\(x\\) must also appear. Similarly, if \\(x^3\\) appears, \\(x\\) and \\(x^2\\) must also appear.\nIf there is an interaction term between explanatory variables \\(x_1\\) and \\(x_2\\), then \\(x_1\\) and \\(x_2\\) must also appear. (We will revisit this when we cover categorical data.)\n\n\n\n\nMore information about this principle can be found here.",
    "crumbs": [
      "Home",
      "Linear modelling",
      "What is a linear model?"
    ]
  },
  {
    "objectID": "Modelling/What is a linear model.html#what-is-a-linear-model",
    "href": "Modelling/What is a linear model.html#what-is-a-linear-model",
    "title": "What is a linear model?",
    "section": "",
    "text": "A linear model aims predict or explain the relationship between a single outcome variable and one (or more) explanatory variables. It is the simplest form of a regression model.\nIn this case, a variable is a quantifiable quantity. The observed data is a realisation of the variable, obtained by conducting tests (observations). Variables can be numerical (continuous or discrete) or categorical.\nThe most basic linear model has a single response and explanatory variable. It is of the form:\n\\[y_i = \\alpha + \\beta x_i + \\epsilon_i,\\]\nwhere \\(y_i\\) is the ith observation of the response variable, \\(x_i\\) is the ith observation of the explanatory variable, \\(\\alpha\\) is the intercept, \\(\\beta\\) is the gradient and \\(\\epsilon_i\\) is the error.\nRegardless of whether we are fitting a model to predict or explain, our aim is to estimate the parameters.\n\n\nIt is important to note that the relationship between explanatory and outcome variables is not deterministic - that is to say, knowing the values of the explanatory variables does not allow you to predict the outcome variable exactly. We can decompose the relationsihp into the deterministic/systemic component and random error:\n\\[\nY = X \\beta + \\epsilon,\n\\] where \\(Y\\in \\mathbb{R}^{n\\times 1}\\) is the outcome/response variable, \\(X \\in \\mathbb{R}^{n\\times p+1}\\) is the design matrix, \\(\\beta \\in \\mathbb{R}^{p+1 \\times 1}\\) is the parameter vector and \\(\\epsilon \\in \\mathbb{R}^{n\\times 1}\\) is the vector of errors. Here, we assume we have \\(n\\) data points and \\(p\\) explanatory variables. We have \\(p+1\\) in the dimensions to account for the intercept term.\n\n\n\nTo use a linear model, we need to make 4 key assumptions. We will see in later pages how we can relax some of these assumptions to fit a generalised linear model. However, for now, we must make sure our model meets these assumptions:\n\n\nLinearity - the systemic component is linear in parameters, that is, \\[\\mathbb{E}[Y] = \\mathbb{E}[X\\beta].\\] Note that the explanatory variables do not have to be linear. They can be polynomials, log and more!\nHomoscedasticity - the errors must have constant variance, i.e. \\[Var(\\epsilon_1) = Var(\\epsilon_2) = \\; ... \\; = Var(\\epsilon_{n+1}) = \\sigma^2.\\]\nThe errors are independent of each other.\nThe errors are normally distributed, \\[\\epsilon \\sim \\text{Normal}(0,\\sigma^2 I_n).\\]\n\n\nThere are several things we should note about the response variable as a consequence of these assumptions.\n\n\nIt is univariate.\nIt is continuous.\nIt is stochastic (i.e. has a random element).\nIt has equal variance.\nResponses from different observations are assumed to be uncorrelated. (We will revisit this for time series later.)\n\n\n\n\n\nIt is very important to be careful with the linearity assumption.\nSuppose we are given a dataset. Let \\(y_i\\) denote the ith observation of the response variable. Let \\(x_{i1}\\) denote the ith observation of the first explanatory variable and \\(x_{i2}\\) denote the ith observation of the second explanatory variable.Let \\(\\beta = (a,b,c)^{T}\\).\nThen, which of the following are linear models - i.e. when does \\(\\mathbb{E}[y_i] = \\mathbb{E}[X_i\\beta]\\)?\n\n\n\\(y_i = b x_{i1} + \\epsilon_i\\)\n\\(y_i = a + b x_{i1} + \\epsilon_i\\)\n\\(y_i = a + b^3 x_{i1} + c x_{i2} + \\epsilon_i\\)\n\\(y_i = a + b (x_{i1}-x_{i2})^2 + \\epsilon_i\\)\n\\(y_i = a + b x_{i1} + c \\log(x_{i2}) + \\epsilon_i\\)\n\n\nIn this case, all are linear models except for 3. This is because the parameters are not linear in 3 (\\(b^3\\))!\n\n\n\nAfter we have checked that our model meets the 4 key assumptions, we must decide what explanatory variables to include in our model. We need to balance accuracy and complexity.\nFor example, a model with loads of explanatory variables may give more accurate predictions. However, the more parameters (explanatory variables) we have in a model, the higher the computational cost to fit a linear model.\nThe principle of parsimony states that “given 2 models that behave similarly, we should pick the simpler model”.\nThe exact boundaries of ‘similarly’ are difficult to quantify. Model creation and selection is an art form, and something that requires practise to learn.\nImportant exceptions to the ‘pick the simpler model’ principle are the following:\n\n\nIf \\(x^2\\) appears in the model, \\(x\\) must also appear. Similarly, if \\(x^3\\) appears, \\(x\\) and \\(x^2\\) must also appear.\nIf there is an interaction term between explanatory variables \\(x_1\\) and \\(x_2\\), then \\(x_1\\) and \\(x_2\\) must also appear. (We will revisit this when we cover categorical data.)"
  },
  {
    "objectID": "Data/Raw data.html",
    "href": "Data/Raw data.html",
    "title": "Data",
    "section": "",
    "text": "To begin, download the data and save it to a folder in your documents. Then, you can use the following commands to call in the data:"
  },
  {
    "objectID": "Data/Raw data.html#leaf-data",
    "href": "Data/Raw data.html#leaf-data",
    "title": "Data",
    "section": "Leaf data",
    "text": "Leaf data\n\n\nCode\n```{r}\n###| Leaf data \n\nleaf &lt;- data.frame(\"Nitrogen\" = c(3.05,4.22,3.34,3.77,3.52,3.54,3.74, 3.78, 2.92, 3.10, 2.86, 2.78, 2.22, 2.67, 3.12, 3.03, 2.45, 4.12, 4.61, 3.94, 4.12, 2.93, 2.66, 3.17, 2.79, 2.61, 3.74, 3.13, 3.49, 2.94),\n                   \"Chlorine\" = c(1.45, 1.35, 0.26, 0.23, 1.10, 0.76, 1.59, 0.39, 0.39, 0.64, 0.82, 0.64, 0.85, 0.90, 0.92, 0.97, 0.18, 0.62, 0.51, 0.45, 1.79, 0.25, 0.31, 0.20, 0.24, 0.20, 2.27, 1.48, 0.25, 2.22),\n                   \"Potassium\" = c(5.67, 4.86, 4.19, 4.42, 3.17, 2.76, 3.81, 3.23, 5.44, 6.16, 5.48, 4.62, 4.49, 5.59, 5.86, 6.60, 4.51, 5.31, 5.16, 4.45, 6.17, 3.38, 3.51, 3.08, 3.98, 3.64, 6.50, 4.28, 4.71, 4.58),\n                   \"lburn\" = c(0.34, 0.11, 0.38, 0.68, 0.18, 0.00, 0.08, 0.11, 1.53, 0.77, 1.17, 1.01, 0.89, 1.40, 1.05, 1.15, 1.49, 0.51, 0.18, 0.34, 0.36, 0.89, 0.91, 0.92, 1.35, 1.33, 0.23, 0.26, 0.73, 0.23))\n```"
  },
  {
    "objectID": "Modelling/Continuous data.html",
    "href": "Modelling/Continuous data.html",
    "title": "Fitting a model with continuous data",
    "section": "",
    "text": "Suppose we are contacted by a group of scientists who are conducting experiments on leaf burn times. They have provided us with the leaf dataset and want to know what the relationship between the elements in the soil and burn time.\nThey tell us that the ‘lburn’ variable is the log of the leaf burn time. They also tell us that the ‘Nitrogen’, ‘Chlorine’ and ‘Potassium’ variables are the percentage of prevalant in soil.\nTo answer their question, and find the relationship between the elements and burn time, we are going to fit a linear model on the leaf dataset. However, before we fit the model, it is important to review the dataset carefully.\n\nA quick look at the data\nWe can load in the data and inspect the first 6 rows as follows.\n\n\n\n\n\n\nNote\n\n\n\nThe data can be found on the associated github here. Please download this to your computer and save it to your documents.\nYou will need to change the location of the file path. You can find this by clicking the file and reading the pop up window.\n\n\n(If you cannot load in the data, a version appears in the Data tab at the top of the website. You should be able to copy and paste that version into your R script and run it directly.)\n\n\nCode\n```{r}\n###| Loading in data\nleaf &lt;- read.csv(\"~/Documents/GitHub/Warwick Statistics Society R Course 2024-2025/Data/leaf.csv\")\n\n###| First 6 rows\nhead(leaf)\n```\n\n\n  Nitrogen Chlorine Potassium lburn\n1     3.05     1.45      5.67  0.34\n2     4.22     1.35      4.86  0.11\n3     3.34     0.26      4.19  0.38\n4     3.77     0.23      4.42  0.68\n5     3.52     1.10      3.17  0.18\n6     3.54     0.76      2.76  0.00\n\n\n\n\nSet up\nFrom the previous section, we observe 4 variables: Nitrogen, Chlorine, Potassium and lburn. We note that all 4 are continuous (as we would expect given what we have been told).\nNow, we want to fit a linear model of the form: \\[\\text{lburn} = \\alpha + \\beta \\times \\text{Nitrogen}+ \\gamma \\times \\text{Chlorine} + \\delta \\times \\text{Potassium} + \\epsilon.\\] Expressing this as a matrix, by reading off the first 2 rows of the dataframe,\n\\[\n\\begin{pmatrix} 0.34 \\\\ 0.11 \\\\ ... \\end{pmatrix} = \\begin{pmatrix} 1 & 3.05 & 1.45 & 5.67 \\\\ 1 & 4.22 & 1.35 & 4.86 \\\\ ... & ... & ... & ... \\end{pmatrix} \\times \\begin{pmatrix} \\alpha \\\\ \\beta \\\\ \\gamma \\\\ \\delta \\end{pmatrix} + \\epsilon.\n\\]\nThus, our goal is to estimate the \\(\\alpha\\),\\(\\beta\\),\\(\\gamma\\) and \\(\\delta\\) that best captures the relationship between the response variable (lburn) and the explanatory variables (Nitrogen, Chlorine and Potassium).\n\n\nUsing ‘lm()’\nIn R, the command ‘lm()’ will fit a linear model for you. We will begin by fitting a model where we only use the Nitrogen soil percentage to predict the burn time. That is, we fit the following model:\n\\[\ny_i = \\alpha + \\beta x_{i,\\text{Nitrogen}} + \\epsilon_i,\n\\]\nwhere \\(x_{i,\\text{Nitrogen}}\\) represents the Nitrogen percentage of the ith observation. We fit this using the lm() command with lburn ~ Nitrogen formula and setting the data=leaf.\n\n\nCode\n```{r}\n###| lburn ~ nitrogen model\nm1 &lt;- lm(lburn ~ Nitrogen, data = leaf) \n\n###| output\nm1\n```\n\n\n\nCall:\nlm(formula = lburn ~ Nitrogen, data = leaf)\n\nCoefficients:\n(Intercept)     Nitrogen  \n     2.6257      -0.5916  \n\n\nFrom the output, we obtain an estimate for \\(\\alpha = 2.6257\\) and an estimate for \\(\\beta = -0.5916\\). We interpret this as follows:\n\n\nIf there is no Nitrogen in the soil, the expected log leaf burn time is 2.6.\nFor every increase of 1% of Nitrogren in the soil, we expect a 0.6 decrease in the log leaf burn time.\n\n(Alternatively, we expect the leaf burn time to decrease by $(0.6).)\n\n\n\nHowever, if we want to get more information about the model, we can use the summary() command on a model, rather than looking at the raw output.\n\n\nCode\n```{r}\n###| Summary output of a model\nsummary(m1)\n```\n\n\n\nCall:\nlm(formula = lburn ~ Nitrogen, data = leaf)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.65636 -0.27698  0.03712  0.27876  0.63181 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   2.6257     0.3610   7.273 6.44e-08 ***\nNitrogen     -0.5916     0.1085  -5.454 8.03e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.3404 on 28 degrees of freedom\nMultiple R-squared:  0.5151,    Adjusted R-squared:  0.4978 \nF-statistic: 29.75 on 1 and 28 DF,  p-value: 8.025e-06\n\n\nNow, the estimates of \\(\\alpha\\) and \\(\\beta\\) are reported in the Estimate column. The rest of the output consists of useful information about the performance of the model. A detailed blogpost of information was created by Felipe Rego and is available here. I have pulled out 2 key values that you need to be very comfortable with calculating and using:\n\n\nPr(&gt;|t|) is the p-value after performing a hypothesis test.\n\nThe asterics (*) indicate the significance. Depending on the context, different significance levels are suitable. In most cases \\(0.05\\) is a ‘good’ level.\n\nThe \\(R^2\\) and adjusted \\(R^2\\) describe how much variance is accounted for by the model (the closer to 1 the better)\n\n\nWe can also get information using ‘anova()’.\n\n\nCode\n```{r}\n###| Anova output\nanova(m1)\n```\n\n\nAnalysis of Variance Table\n\nResponse: lburn\n          Df Sum Sq Mean Sq F value    Pr(&gt;F)    \nNitrogen   1 3.4460  3.4460  29.748 8.025e-06 ***\nResiduals 28 3.2435  0.1158                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nThis no longer gives the \\(R^2\\) values. However, it will perform consecutive hypothesis tests.\n\n\nUsing ‘anova()’\nTo explore anova further, let us fit a different linear model: \\[\ny_i = \\alpha + \\beta x_{i,\\text{Nitrogen}} + \\gamma x_{i,\\text{Chlorine}}+ \\epsilon_i.\\]\n\n\nCode\n```{r}\n###| lburn ~ Nitrogen + Chlorine\nm2 &lt;- lm(lburn ~ Nitrogen + Chlorine, data = leaf)\n\n###| anova on larger model\nanova(m2)\n```\n\n\nAnalysis of Variance Table\n\nResponse: lburn\n          Df Sum Sq Mean Sq F value    Pr(&gt;F)    \nNitrogen   1 3.4460  3.4460 38.9352 1.127e-06 ***\nChlorine   1 0.8538  0.8538  9.6473  0.004424 ** \nResiduals 27 2.3897  0.0885                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nThe first row of the anova output is: \\[ Nitrogen \\quad  1 \\quad 3.4460 \\quad 3.4460 \\quad 38.9352 \\quad 1.127e-06 \\text{***}.\\]\nThe p-value \\(1.127e-06\\) comes from a hypothesis test with null hypothsis \\(\\beta = 0\\). That is to say, we compare the following 2 models, one where \\(\\beta =0\\) and one where \\(\\beta \\neq 0\\):\n\n\n\\(y_i = \\alpha + \\epsilon_i\\)\n\\(y_i = \\alpha + \\beta x_{i,\\text{Nitrogen}} + \\epsilon_i\\)\n\n\nAs the p-value is \\(&lt;0.05\\), we say that there is sufficient evidence to reject the null hypothesis.\nThe second row of the anova output is: \\[Chlorine \\quad  1 \\quad 0.8538 \\quad 0.8538 \\quad 9.6473 \\quad 0.004424 \\text{**}.\\]\nThe p-value \\(0.004424\\) comes from a hypothesis test with null hypothesis \\(\\gamma = 0\\). That is to say, we compare the following 2 models, one where \\(\\beta =0\\) and one where \\(\\beta \\neq 0\\):\n\n\n\\(y_i = \\alpha + \\beta x_{i,\\text{Nitrogen}} + \\epsilon_i\\)\n\\(y_i = \\alpha + \\beta x_{i,\\text{Nitrogen}} + \\gamma x_{i,\\text{Chlorine}} + \\epsilon_i\\)\n\n\nAs the p-value is \\(&lt;0.05\\), we say that there is sufficient evidence to reject the null hypothesis.\nMore information about interpreting anova can be found here.\n\n\nFitting a model with all 3 explanatory variables\nNow that we have some familiarity with the outputs, let us fit the model with all possible terms (i.e. the fully saturated model). That is, we fit\n\\[\ny_i = \\alpha + \\beta x_{i,\\text{Nitrogen}} + \\gamma x_{i,\\text{Chlorine}} + \\delta x_{i,\\text{Potassium}} + \\epsilon_i.\n\\]\n\n\nCode\n```{r}\n###| Saturated model\nm3 &lt;- lm(lburn ~ Nitrogen + Chlorine + Potassium, data = leaf)\n\n###| Output\nm3\n```\n\n\n\nCall:\nlm(formula = lburn ~ Nitrogen + Chlorine + Potassium, data = leaf)\n\nCoefficients:\n(Intercept)     Nitrogen     Chlorine    Potassium  \n     1.8110      -0.5315      -0.4396       0.2090  \n\n\nFrom fitting this model, we obtain estimates for \\(\\alpha\\),\\(\\beta\\),\\(\\gamma\\) and \\(\\delta\\). We interpret these as follows:\n\nFor a leaf with no Nitrogen, Chlorine and Potassium in the soil, we expect the log burning time to be \\(1.8\\). Thus, the burning time is \\(\\exp(1.8)\\approx 6\\).\nHolding all other element concentrations, an increase of \\(1\\%\\) in Nitrogen concentration corresponds to a decrease of 0.5 in the log burning time.\nHolding all other element concentrations, an increase of \\(1\\%\\) in Chlorine concentration corresponds to a decrease of 0.4 in the log burning time.\nHolding all other element concentrations, an increase of \\(1\\%\\) in Potassium concentration corresponds to an increase of 0.2 in the log burning time.\n\n\n\n\n\n\n\nImportant\n\n\n\nIt is very important that we state that the other explanatory variables are held constant when interpreting the estimates! The estimate only explains the relationship when that specific explanatory variable is altered.\n\n\nNow, we can consider if we need all of these variables in our model. We do this by using ‘anova()’.\n\n\nCode\n```{r}\n###| Saturated model anova\nanova(m3)\n```\n\n\nAnalysis of Variance Table\n\nResponse: lburn\n          Df Sum Sq Mean Sq F value    Pr(&gt;F)    \nNitrogen   1 3.4460  3.4460  75.622 3.573e-09 ***\nChlorine   1 0.8538  0.8538  18.738 0.0001976 ***\nPotassium  1 1.2049  1.2049  26.441 2.311e-05 ***\nResiduals 26 1.1848  0.0456                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nIn all 3 consecutive tests (\\(\\beta=0\\),\\(\\gamma=0\\) and \\(\\delta=0\\)), we observe evidence to reject the null hypothesis. Thus, we keep all 3 variables and propose the following linear model to the scientists:\n\\[\ny_i = 1.8 -0.5 \\; x_{i,\\text{Nitrogen}} -0.4 \\; x_{i,\\text{Chlorine}} + 0.2 \\; x_{i,\\text{Potassium}} + \\epsilon_i.\n\\]",
    "crumbs": [
      "Home",
      "Linear modelling",
      "Fitting a model with continuous data"
    ]
  },
  {
    "objectID": "Modelling/Loading in data.html",
    "href": "Modelling/Loading in data.html",
    "title": "Loading in data",
    "section": "",
    "text": "NEED TO WRITE UP HOW TO DO THIS."
  },
  {
    "objectID": "Modelling/Categorical data.html",
    "href": "Modelling/Categorical data.html",
    "title": "Fitting a model with categorical data",
    "section": "",
    "text": "Thus far, we have fit models with continuous data. However, we will often encounter variables that have a finite number of categories (i.e. categorical variables). We can either assign a reference category (treatment coding) or have no intercept term.\n\nSet up\nTo explore categorical data, let us look at the agriculture dataset.\n\n\nCode\n```{r}\n###| Load in the data\nagriculture &lt;- read.csv(\"~/Documents/GitHub/Warwick Statistics Society R Course 2024-2025/Data/agriculture.csv\")\n\n###| First 6 rows\nhead(agriculture)\n```\n\n\n  Variety Block SIZE YIELD\n1       A     1   28    28\n2       B     1   23    23\n3       C     1   27    27\n4       D     1   24    24\n5       E     1   30    30\n6       F     1   30    30\n\n\nIn this dataset, there are 4 variables: Variety, Block, SIZE and YIELD. From the first 6 rows, we see that Variety is a categorical variable with categories at least A-F. However, as we can only see 1 for Block, it is unclear what type of variable it is. Instead, let us look at the summary of the dataset, using the summary() function.\n\n\nCode\n```{r}\n###| Dataset summary\nsummary(agriculture)\n```\n\n\n   Variety              Block           SIZE           YIELD      \n Length:48          Min.   :1.00   Min.   : 19.0   Min.   : 19.0  \n Class :character   1st Qu.:2.75   1st Qu.: 27.0   1st Qu.: 27.0  \n Mode  :character   Median :4.50   Median : 82.0   Median : 82.0  \n                    Mean   :4.50   Mean   :113.0   Mean   :113.0  \n                    3rd Qu.:6.25   3rd Qu.:201.2   3rd Qu.:201.2  \n                    Max.   :8.00   Max.   :261.0   Max.   :261.0  \n\n\nFrom this, we see that SIZE is a continuous variable from 19 to 261 and YIELD is a continuous variable from 19 to 261. (Exploring this further, we note that the size and yield observations are the same for every entry.) We also see that Block takes values from 1 to 8 and Variety is always a character. However, we do not know what values Variety takes.\nTo fix this, we will alter the data using the factor() command.\n\n\nCode\n```{r}\n###| Factor command\nagriculture$Variety &lt;- factor(agriculture$Variety)\n\n###| First 6 rows\nhead(agriculture)\n\n###| Summary\nsummary(agriculture)\n```\n\n\n  Variety Block SIZE YIELD\n1       A     1   28    28\n2       B     1   23    23\n3       C     1   27    27\n4       D     1   24    24\n5       E     1   30    30\n6       F     1   30    30\n Variety     Block           SIZE           YIELD      \n A:8     Min.   :1.00   Min.   : 19.0   Min.   : 19.0  \n B:8     1st Qu.:2.75   1st Qu.: 27.0   1st Qu.: 27.0  \n C:8     Median :4.50   Median : 82.0   Median : 82.0  \n D:8     Mean   :4.50   Mean   :113.0   Mean   :113.0  \n E:8     3rd Qu.:6.25   3rd Qu.:201.2   3rd Qu.:201.2  \n F:8     Max.   :8.00   Max.   :261.0   Max.   :261.0  \n\n\nNow, the Variety column is treated as a categorical variable, rather than as characters/strings. If we look at the new summary of the data, we observe that there are 6 categories (A-F) and each category has 8 observations.\n\n\nFitting a model\nNow, let’s fit a model that uses Variety and Block to predict SIZE. That is, we fit a model of the following from:\n\\[\\begin{align}\nSIZE_i = & \\alpha \\times \\mathbb{I}{(\\text{oberservation i has Variety A})} + \\beta \\times \\mathbb{I}{(\\text{oberservation i has Variety B})} \\\\ & + \\gamma \\times \\mathbb{I}{(\\text{oberservation i has Variety C})} + \\delta \\times \\mathbb{I}{(\\text{oberservation i has Variety D})} \\\\ & + \\epsilon \\times \\mathbb{I}{(\\text{oberservation i has Variety E})} + \\zeta \\times \\mathbb{I}{(\\text{oberservation i has Variety F})} \\\\ & + \\eta \\times Block_i + \\hat{\\epsilon}_i,\n\\end{align}\\]\nwhere \\(\\hat{\\epsilon}_i\\) is the error of the ith observation.\n\n\nCode\n```{r}\n###| SIZE ~ Variety + Block\nm1 &lt;- lm(SIZE ~ 0 + Variety + Block, data = agriculture) # Set intercept to 0\n\n###| Output\nm1\n```\n\n\n\nCall:\nlm(formula = SIZE ~ 0 + Variety + Block, data = agriculture)\n\nCoefficients:\nVarietyA  VarietyB  VarietyC  VarietyD  VarietyE  VarietyF     Block  \n  57.625    62.875    69.625    89.500    73.500    79.875     9.083  \n\n\nReading off of the output, we obtain the following model:\n\\[\\begin{align}\nSIZE_i = &57.6 \\times \\mathbb{I}{(\\text{oberservation i has Variety A})} + 62.9 \\times \\mathbb{I}{(\\text{oberservation i has Variety B})} \\\\ & + 69.6 \\times \\mathbb{I}{(\\text{oberservation i has Variety C})} + 89.5 \\times \\mathbb{I}{(\\text{oberservation i has Variety D})} \\\\ & + 73.5 \\times \\mathbb{I}{(\\text{oberservation i has Variety E})} + 79.9 \\times \\mathbb{I}{(\\text{oberservation i has Variety F})} \\\\ & + 9.1 \\times Block_i + \\hat{\\epsilon}_i.\n\\end{align}\\]\nWe interpret the Block variable as before: holding every other variable constant, a 1 unit increase in the Block is expected to result in a 9.1 unit increase in SIZE.\n\n\n\n\n\n\nImportant\n\n\n\nHowever, we cannot interpret the categorical variable, Variety, in the same way. Instead, we will compare what happens as we change category.\n\n\nFor example,\n\n\nFor a Variety A observation, and holding Block constant, we expect the SIZE to be 5.3 units smaller than if it was Variety B.\nFor a Variety F observation, and holding Block constant, we expect the SIZE to be 22.3 units larger than if it was Variety A.\n\n\n\n\nRefrence categories\nUsing no intercept (by adding the 0 term in the lm() command), we can compare across categories easily. However, suppose we want to compare everything to category A. Instead of finding the estimates and then subtracting them, we can ask R to do this directly by setting up reference categories using relevel().\nNow, our model looks like:\n\\[\\begin{align}\nSIZE_i = & \\tilde{\\alpha} + \\tilde{\\beta} \\times \\mathbb{I}{(\\text{oberservation i has Variety B})} \\\\ & + \\tilde{\\gamma} \\times \\mathbb{I}{(\\text{oberservation i has Variety C})} + \\tilde{\\delta} \\times \\mathbb{I}{(\\text{oberservation i has Variety D})} \\\\ & + \\tilde{\\epsilon} \\times \\mathbb{I}{(\\text{oberservation i has Variety E})} + \\tilde{\\zeta} \\times \\mathbb{I}{(\\text{oberservation i has Variety F})} \\\\ & + \\tilde{\\eta} \\times Block_i + \\hat{\\epsilon}_i,\n\\end{align}\\]\nWe code this up as follows:\n\n\nCode\n```{r}\n###| Setting Category A as the reference category\nagriculture$Variety &lt;- relevel(agriculture$Variety, ref = \"A\")\n\n###| New model\nm2 &lt;- lm(SIZE ~ Variety + Block, data = agriculture) # no specified intercept!\n\n###| Output\nm2\n```\n\n\n\nCall:\nlm(formula = SIZE ~ Variety + Block, data = agriculture)\n\nCoefficients:\n(Intercept)     VarietyB     VarietyC     VarietyD     VarietyE     VarietyF  \n     57.625        5.250       12.000       31.875       15.875       22.250  \n      Block  \n      9.083  \n\n\nNow, our model is: \\[\\begin{align}\nSIZE_i = &57.6 + 5.3 \\times \\mathbb{I}{(\\text{oberservation i has Variety B})} \\\\ & + 12 \\times \\mathbb{I}{(\\text{oberservation i has Variety C})} + 31.9 \\times \\mathbb{I}{(\\text{oberservation i has Variety D})} \\\\ & + 15.7 \\times \\mathbb{I}{(\\text{oberservation i has Variety E})} + 22.3 \\times \\mathbb{I}{(\\text{oberservation i has Variety F})} \\\\ & + 9.1 \\times Block_i + \\hat{\\epsilon}_i.\n\\end{align}\\]\nBoth of these models are equivalent! They are reparametrisations of each other, with \\(\\alpha = \\tilde{\\alpha}\\), \\(\\beta = \\tilde{\\alpha} + \\tilde{\\beta}\\), \\(\\gamma = \\tilde{\\alpha} + \\tilde{\\gamma}\\), …, \\(\\zeta = \\tilde{\\alpha} + \\tilde{\\zeta}\\) and \\(\\eta = \\tilde{\\eta}\\). Based on the context, you should choose to include or not to include the intercept term.\n\n\nInteraction terms\nWhat effect does the Variety category have on the Block estimator? We explore this using interaction terms with a model of the form:\n\\[\\begin{align}\nSIZE_i = & \\alpha + \\beta \\times \\mathbb{I}{(\\text{oberservation i has Variety B})} \\\\ & + ... + \\zeta \\times \\mathbb{I}{(\\text{oberservation i has Variety F})} \\\\ & + \\eta \\times Block_i + \\\\ & \\tilde{\\beta} \\times \\mathbb{I}{(\\text{oberservation i has Variety B})} \\times Block_i \\\\ & + ... + \\tilde{\\zeta} \\times \\mathbb{I}{(\\text{oberservation i has Variety F})} \\times Block_i \\\\ & \\hat{\\epsilon}_i,\n\\end{align}\\] where \\(\\hat{\\epsilon}_i\\) is the error of the ith observation.\n\n\nCode\n```{r}\n###| Model with intercept terms\nm3 &lt;- lm(SIZE ~ Variety + Block + Variety:Block, data = agriculture) \n\n###| Output\nm3\n```\n\n\n\nCall:\nlm(formula = SIZE ~ Variety + Block + Variety:Block, data = agriculture)\n\nCoefficients:\n   (Intercept)        VarietyB        VarietyC        VarietyD        VarietyE  \n        88.000         -29.893         -24.429         -23.679         -20.286  \n      VarietyF           Block  VarietyB:Block  VarietyC:Block  VarietyD:Block  \n         3.286           2.333           7.810           8.095          12.345  \nVarietyE:Block  VarietyF:Block  \n         8.036           4.214  \n\n\nWe interpret the model as follows:\n\n\nIf the observation is Variety B and holding block constant, the SIZE will be 29.9 units smaller than if it was Variety A.\n\nIf the observation is Variety C and holding block constant, the SIZE will be 24.4 units smaller than if it was Variety A.\n\nIf the observation is Variety D and holding block constant, the SIZE will be 23.7 units smaller than if it was Variety A.\n\nIf the observation is Variety E and holding block constant, the SIZE will be 20.3 units smaller than if it was Variety A.\n\nIf the observation is Variety F and holding block constant, the SIZE will be 3.3 units larger than if it was Variety A.\nIf the observation is Variety A, increasing block size by 1 will increase the SIZE by 2.3.\nIf the observation is Variety B, increasing block size by 1 will increase the SIZE by 7.8.\nIf the observation is Variety C, increasing block size by 1 will increase the SIZE by 8.1.\nIf the observation is Variety D, increasing block size by 1 will increase the SIZE by 12.3.\nIf the observation is Variety E, increasing block size by 1 will increase the SIZE by 8.0.\nIf the observation is Variety F, increasing block size by 1 will increase the SIZE by 2.3.\n\n\n\n\n\n\n\n\nImportant\n\n\n\nWhen using interaction terms, it is important to remember the principle of parsimony. If we decide to model the interaction between variable A and variable B, we must include both variables in the model.",
    "crumbs": [
      "Home",
      "Linear modelling",
      "Fitting a model with categorical data"
    ]
  },
  {
    "objectID": "Modelling/Check your understanding.html",
    "href": "Modelling/Check your understanding.html",
    "title": "Check your understanding",
    "section": "",
    "text": "data.csv task\nDownload and load in the data.csv file. This contains 3 variables: x1, x2 and y.\n\n\nPlot y against x1; plot y against x2. What do you notice about the relationships?\nWhat does the design matrix of the following model look like? \\[y_i = \\beta_0 +\\beta_1 x_{1i} + \\beta_2 x_{2i} + \\epsilon_i.\\]\nFit this model in R, find the estimates of \\(\\beta_0\\),\\(\\beta_1\\) and \\(\\beta_2\\) and interpret them.\nFit a new model, \\[y_i = \\gamma_0 +\\gamma_1 x_{1i} + \\gamma_2 x_{2i}^2 + \\epsilon_i.\\] How do the estimates of \\(\\gamma\\) compare to the estimates of \\(\\beta\\)?\n\n\n\n\ncoursework.csv task\nDownload and load in the coursework.csv` file. This is a dataset of the coursework marks, out of 20, and the exam marks, out of 100.\n\n\nCreate coursework and exam variables in R.\nPlot exam against coursework with exam on the y axis.\nFor a simple linear regression model with exam as the response and coursework as the predictor variable.\nAccording to the model, for each extra coursework mark, how many extra exam marks were obtained?\nUsing the ‘fitted’ command in R, calculate the fitted values of the model.\n\nUse ?fitted to get more information about this command.\nThe ith fitted value is the value predicted by the model based on the ith observation.\n\nAdd the fitted line to the graph of exam against coursework.\n\nHint: use the abline function.\n\nCreate a new variable, coursework_percentage, that contains the coursework mark as a percentage.\nFit a new model with coursework_percentage as the predictor variable.\nWhat effect does the rescaling of the coursework marks have on the fitted values and on the parameters?\nPredict the exam score for a student that scored full marks in their coursework. Is there an issue with this prediction?\n\n\n\n\nAnswers to data.csv tasks\n\n\nCode\n```{r}\n###| Loading in file\ndata &lt;- read.csv(\"~/Documents/GitHub/Warwick Statistics Society R Course 2024-2025/Data/data.csv\")\n\n###| Plot\nplot(data$x1, data$y, xlab = \"x1\", ylab = \"y\", \n     main = \"Scatter plots of x1 against y\")\nplot(data$x2, data$y, xlab = \"x2\", ylab = \"y\", \n     main = \"Scatter plots of x2 against y\")\n```\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFrom the 2 graphs, we observe that y increases as x1 increases but y decreases as x2 increases.\nThe design matrix for this model will be of the form:\n\\[\n\\begin{pmatrix} 1 & 2.37 & 20.41 \\\\ 1 & 8.38 & 4.34 \\\\ ... & ... & ... \\end{pmatrix}.\n\\]\n\n\nCode\n```{r}\n###| Fitting the model\nm1 &lt;- lm(y ~ x1 + x2, data = data)\nm1\n```\n\n\n\nCall:\nlm(formula = y ~ x1 + x2, data = data)\n\nCoefficients:\n(Intercept)           x1           x2  \n   5.594377     0.614462    -0.004929  \n\n\nIf \\(x1 = 0\\) and \\(x2= 0\\), we expect \\(y=5.6\\). Assuming \\(x2\\) remains constant, if \\(x1\\) increases by 1, we expect \\(y\\) to increase by 0.6. Assuming \\(x1\\) remains constant, if \\(x1\\) increases by 1, we expect \\(y\\) to decrease by 0.005.\n\n\nCode\n```{r}\n###| Fitting the second model\nm2 &lt;- lm(y ~ x1 + I(x2^2), data = data) # NOTE THAT WE NEED TO USE I()!\nm2\n```\n\n\n\nCall:\nlm(formula = y ~ x1 + I(x2^2), data = data)\n\nCoefficients:\n(Intercept)           x1      I(x2^2)  \n  5.439e+00    6.307e-01   -2.652e-05  \n\n\nIf \\(x1 = 0\\) and \\(x2= 0\\), we expect \\(y=5.4\\). Assuming \\(x2\\) remains constant, if \\(x1\\) increases by 1, we expect \\(y\\) to increase by 0.6. Assuming \\(x1\\) remains constant, if \\(x1\\) increases by 1, we do not expect \\(y\\) to change (to 4 decimal places).\n\n\nAnswers to coursework.csv\n\n\nCode\n```{r}\n###| Loading in file\ncoursework.df &lt;- read.csv(\"~/Documents/GitHub/Warwick Statistics Society R Course 2024-2025/Data/coursework.csv\")\n\n###| Variable assigning\ncoursework &lt;- coursework.df$cw\nexam &lt;- coursework.df$exam\n\n###| Scatter plot\nplot(coursework,exam, xlab = \"Raw coursework mark\",\n     ylab = \"Exam mark\", main = \"Coursework against exam marks\")\n```\n\n\n\n\n\n\n\n\n\nFrom the scatter plot, we observe that a linear relationship between the raw coursework mark and the exam mark, where students who performed well in coursework also performed well on the exam and students who performed badly in the coursework also performed badly in the exam.\n\n\nCode\n```{r}\n###| Raw coursework model\nm1 &lt;- lm(exam ~ cw, data = coursework.df)\nm1\n```\n\n\n\nCall:\nlm(formula = exam ~ cw, data = coursework.df)\n\nCoefficients:\n(Intercept)           cw  \n     19.377        4.383  \n\n\nFor each extra mark obtained on the coursework, we expect the student to gain an extra \\(4.4\\%\\) in the exam.\n\n\nCode\n```{r}\n###| Fitted values\nfitted &lt;- fitted(m1)\n\n###| Adding fitted values as points\nplot(coursework,exam, xlab = \"Raw coursework mark\",\n     ylab = \"Exam mark\", main = \"Coursework against exam marks\")\npoints(coursework,fitted, col = \"blue\")\n\n###| Adding a line through the fitted points\nplot(coursework,exam, xlab = \"Raw coursework mark\",\n     ylab = \"Exam mark\", main = \"Coursework against exam marks\")\npoints(coursework,fitted, col = \"blue\")\nabline(a = m1$coefficients[1], b = m1$coefficients[2], col = \"blue\")\n```\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n```{r}\n###| Coursework as a percentage\ncoursework.df$coursework_perc &lt;- coursework/20\n\nm2 &lt;- lm(exam ~ coursework_perc, data = coursework.df)\nm2\n\nfitted_perc &lt;- fitted(m2)\nfitted_perc\n```\n\n\n\nCall:\nlm(formula = exam ~ coursework_perc, data = coursework.df)\n\nCoefficients:\n    (Intercept)  coursework_perc  \n          19.38            87.66  \n\n       1        2        3        4        5        6 \n41.29114 41.29114 63.20570 71.97152 80.73734 89.50316 \n\n\nThe fitted values and the intercept estimate are the same! However, the \\(\\beta\\) estimate is now 87.66, \\(20\\times 4.383\\).\nIf a student achieves \\(100\\%\\) in their coursework, we expect them to achive \\(19.38 + 87.66 = 107.04\\%\\) in the exam. This is a big problem as a student cannot achieve \\(&gt;100\\%\\)! It is very important to be careful when extrapolating as it is very easy to end up in unrealistic (or even impossible) situations.",
    "crumbs": [
      "Home",
      "Linear modelling",
      "Check your understanding"
    ]
  },
  {
    "objectID": "Data/Raw data.html#agriculture-data",
    "href": "Data/Raw data.html#agriculture-data",
    "title": "Data",
    "section": "Agriculture data",
    "text": "Agriculture data\n\n\nCode\n```{r}\n###| Agriculture data\nagriculture &lt;- data.frame(\"Variety\" = c(\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"A\", \"B\", \"C\", \"D\", \"E\", \"F\"),\n                          \"Block\" = c(1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8),\n                          \"SIZE\" = c(28, 23,27, 24,30,30,202,145,188,201,202,228,22,26,24,28,26, 25,165,201,185,231,178,221,27,28,27,30,26,27, 191,203,185,238,198,207,19,24,28,30,29,24,134,180,220,261,226,204),\n                          \"YIELD\" = c(28, 23,27, 24,30,30,202,145,188,201,202,228,22,26,24,28,26,25,165,201,185,231,178,221,27,28,27,30,26,27,191,203,185,238,198,207,19,24,28,30,29,24,134,180,220,261,226,204))\n```"
  },
  {
    "objectID": "Modelling/Diagnostics.html",
    "href": "Modelling/Diagnostics.html",
    "title": "Model diagnostics",
    "section": "",
    "text": "In the previous pages, we covered what a linear model is and how to fit a linear model. In this page, we will cover how to check a model fits the 4 key assumptions and what to do if it fails to meet an assumption.\nTo recap, the 4 key assumptions are:",
    "crumbs": [
      "Home",
      "Linear modelling",
      "Model diagnostics"
    ]
  },
  {
    "objectID": "Modelling/Diagnostics.html#generating-data",
    "href": "Modelling/Diagnostics.html#generating-data",
    "title": "Model diagnostics",
    "section": "Generating data",
    "text": "Generating data\nWe are going to create some data to illustrate good and bad model assumptions.\n\n\nCode\n```{r}\n###| For reproducability, we set a seed\nset.seed(419)\n\n###| Generating random numbers\na &lt;- runif(n = 100, min = 0, max = 10)\nb &lt;- rpois(n = 100, lambda = 2)\nc &lt;- runif(n = 100, min = -5, max = 10)\n\n###| Generating the response variables\ny1 &lt;- a + b\ny2 &lt;- a + b^2\ny3 &lt;- log(a)\n\n###| Storing as a dataframe\ndata &lt;- data.frame(\"a\" = a,\n                   \"b\" = b,\n                   \"c\" = c,\n                   \"y1\" = y1,\n                   \"y2\" = y2,\n                   \"y3\" = y3)\n\n###| First 6 rows\nhead(data)\n```\n\n\n         a b         c        y1        y2        y3\n1 9.786378 2 -4.673051 11.786378 13.786378 2.2809914\n2 3.318455 5 -3.948319  8.318455 28.318455 1.1994994\n3 8.329044 0 -4.219525  8.329044  8.329044 2.1197487\n4 2.087712 4 -2.410313  6.087712 18.087712 0.7360689\n5 3.048667 1  8.473026  4.048667  4.048667 1.1147043\n6 4.070241 1  3.784801  5.070241  5.070241 1.4037022"
  },
  {
    "objectID": "Modelling/Diagnostics.html#diagnostic-plots",
    "href": "Modelling/Diagnostics.html#diagnostic-plots",
    "title": "Model diagnostics",
    "section": "Diagnostic plots",
    "text": "Diagnostic plots\nOne way to test model assumptions is to look at the residual plots.\n\n\n\n\n\n\nNote\n\n\n\nA residual (or fitting deviation) is an estimate of the unobsereved statistical error. It is the difference between the observed \\(y_i\\) and the estimated \\(\\hat{y}_i\\), the value predicted by the model residuals.\n\n\nWe want our model’s predictions to be as close to the true observed values as possible, that is, we want to minimise the residuals. We also use the residuals to check if we are meeting the linearity and normality assumptions. We can also identify outliers this way.\n\nA good model\nTo explore what ideal residual plots look like, we are going to exactly fit the model \\[y1_i = a_i + b_i + \\epsilon_i.\\] Based on the way we have defined \\(y1\\), we know that this model should fit the data exactly. We plot several different diagnostic plots using the ‘plot()’ command.\nWe will explore each plot one by one:\n\n\nCode\n```{r}\n###| Fitting the model\nm1 &lt;- lm(y1 ~ a + b, data = data)\n\n###| Residual v fitted plot\nplot(m1, which = 1)\n```\n\n\n\n\n\n\n\n\n\nThe residuals v fitted values plot is a scatter plot of with the residuals on the y-axis and the fitted/predicted values on the x-axis. The red line (called the smoother) is a curve fitted to the residuals. If the structural component of the model is correct (i.e. the explanatory variables and not the errors), the smoother will be horizontal around 0.\nIn this example, we see a very flat smoother, centered at 0, with 3 labelled points that deviate from the general trend.\n\n\nCode\n```{r}\n###| Q-Q plot\nplot(m1, which = 2)\n```\n\n\n\n\n\n\n\n\n\nRecall that a model assumption is that the errors are normally distributed. The Q-Q plot allows us to check this assumption by plotting the absolute values of the standardized residuals on the y-axis and the theoretical quantiles of the standard half-normal distribution on the x-axis. If the errors are normally distributed, the dashed line will go through the origin and have a gradient of 1.\nIn this example, we see that the residuals do appear to be normally distributed, although at the tails, we do see 3 points that deviate from this.\n\n\nCode\n```{r}\n###| Cook's distance plot\nplot(m1, which = 4)\n```\n\n\n\n\n\n\n\n\n\nThis graph plots the Cook’s distance against the observation number, with the largest 3 values labelled. The Cook’s distance can be thought of as a measure of the influence of a particular observation. That is, it summarises how much the model changes, when you do and don’t include the ith data point.\nYou may notice that we have skipped several plots, namely: the location-scale plot and the standardized resivual v leverage plot. More information about diasgnotstic plots can be found here for those interested.\n\n\nA bad model\nNow, let us purposefully fit a bad model to see how the diagnostic plots change.\n\n\nCode\n```{r}\n###| Bad model example\nm2 &lt;- lm(y2 ~ a + b, data=data)\n\n###| Residual v fitted plot\nplot(m2, which = 1)\n\n###| Q-Q plot\nplot(m2, which = 2)\n```\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn the residuals v fitted values plot, we observe that the smoother has a parabolic shape. This indicates that there is a problem in how we have constructed our model - specifically we are failing to meet the linearity assumption. If we look back to how we defined y2 (\\(y2 = a + b^2\\)), this makes sense. We cannot capture the \\(b^2\\) nature of our data if we are only using \\(a+b\\) as our explanatory variables.\nIn the Q-Q plot, we note large deviations from the ideal dashed line at the upper tail. This indicates that our errors are not normally distributed, violating that assumption.\nSo, we conclude that \\(y2_i = a_i + b_i +\\epsilon_i\\) is a bad model as it violates the key model assumptions. But, how do we fix this?\n\n\nTransformations\nOn top of altering which explanatory variables we do and do not include in our model, we can transform our variables to make the model fit better.\nFor example, in the \\(y2\\) case, we can create a new variable \\(b2\\) that is \\(b^2\\) and include this transformed variable into our model. However, by the principle of parsimony, we also need to include \\(b\\) into the model as well.\n\n\nCode\n```{r}\n###| Modeeling y2\nm3 &lt;- lm(y2 ~ a + b + I(b^2), data = data)\n\n###| Residuals v fitted plot\nplot(m3, which = 1)\n\n###| Q-Q plot\nplot(m3, which = 2)\n```\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn the residuals plot, we observe a flat smoother. This indicates we are meeting the linearity assumption!\nIn the Q-Q plot, we see that the data follows the dashed line, baring 3 exceptions at the extreme. Thus, the model appears to meet the normally distributed errors assumption.\n\n\nAnother bad model\nTo further explore diagnostic plots, let us consider one more model: \\[y3_i = a_i + \\epsilon.\\]\n\n\nCode\n```{r}\n###| y3 = a\nm4 &lt;- lm(y3 ~ a, data = data)\n\n###| Residual plot\nplot(m4, which = 1)\n```\n\n\n\n\n\n\n\n\n\nFitting this model, we observe a curve shape in the smoother, indicating that we are violating the linearity assumption. As the shape is not symmetric, it doesn’t seem like this is can be corrected by using \\(a^2\\). Instead, we can try using a logarithm.\n\n\nCode\n```{r}\n###| y3 = log(a)\nm5 &lt;- lm(y3 ~ log(a), data = data)\n\n###| Residual plot\nplot(m5, which = 1)\n```\n\n\n\n\n\n\n\n\n\nNow, we observe the correct behaviour of the smoother."
  },
  {
    "objectID": "Modelling/Diagnostics.html#diagnostic-plots-with-noise",
    "href": "Modelling/Diagnostics.html#diagnostic-plots-with-noise",
    "title": "Model diagnostics",
    "section": "Diagnostic plots with noise",
    "text": "Diagnostic plots with noise\nThus far, we have used formulas to generate our response variables. This has resulted in very clearly defined behaviour from our models and diagnostic plots. However, in a normal scenario, the data we are given will have noise. So, we will add some normally distributed noise to our data and repeat the above.\n\n\nCode\n```{r}\n###| Adding noise\ndata2 &lt;- data\ndata2$y1 &lt;- data2$y1 + rnorm(n = 100, mean = 0, sd = 1)\ndata2$y2 &lt;- data2$y2 + rnorm(n = 100, mean = 0, sd = 1)\ndata2$y3 &lt;- data2$y3 + rnorm(n = 100, mean = 0, sd = 1)\n```\n\n\n\nA good model revisited\nOnce again, we will fit the model \\[y1_i = a_i + b_i + \\epsilon_i.\\] However, now we will use the noisy dataset.\n\n\nCode\n```{r}\n###| y1 model\nM1 &lt;- lm(y1 ~ a + b, data = data2)\nplot(M1,which=1)\nplot(M1, which = 2)\n```\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNow, there is a lot more variation in the residuals. However, we still observe a roughly flat smoother so the model does not appear to be violating the linearity assumption.\nThe Q-Q plot still follows the ideal general trend, athough the tails deviate slightly more.\n\n\nA bad model revisited\nNow, we fit both of the following models: \\[\\begin{align}\ny2_i & = a_i + b_i + \\epsilon_i, \\\\\ny2_i & = a_i + b_i + b_i^2 + \\epsilon_i.\n\\end{align}\\]\n(I have placed the graphs side by side for comparison using the ‘par(mfrow = c(1,2)))’ command. More information about this, and graphics more generally, appears here.)\n\n\nCode\n```{r}\n###| a + b\nM2 &lt;- lm(y2 ~ a + b, data = data2)\n\n###| a + b + b^2\nM3 &lt;- lm(y2 ~ a + b + I(b^2), data = data2)\n\n###| Plotting graphs side by side\npar(mfrow = c(1, 2))\n\nplot(M2,which=1)\nplot(M3,which=1)\n\nplot(M2, which = 2)\nplot(M3, which = 2)\n```\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn the residuals plot, we see the same general trends in behaviour that we saw before. The graph on the left, fitted with \\(a+b\\), displays the problematic parabolic behaviour in the smoother. The graph on the right, fitted with \\(a+b+b^2\\), has a flatter smoother.\nSimilarly, in the Q-Q plots, we observe that the left graph deviates at the tails more than the right graph.\n\n\nAnother bad model revisited\nNow, we fit both of the following models: \\[\\begin{align}\ny2_i & = a_i \\epsilon_i, \\\\\ny2_i & = \\log(a_i) + \\epsilon_i.\n\\end{align}\\]\nAgain, for ease, I have plotted the graphs side by side.\n\n\nCode\n```{r}\n###| a \nM4 &lt;- lm(y3 ~ a, data = data2)\n\n###| log(a)\nM5 &lt;- lm(y3 ~ log(a), data = data2)\n\n###| Plotting graphs side by side\npar(mfrow = c(1, 2))\n\nplot(M4,which=1)\nplot(M5,which=1)\n\nplot(M4, which = 2)\nplot(M5, which = 2)\n```\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThis time, it is much less clear which of these two models is better.\nComparing the Q-Q plots, the left graph appears to deviate more on the lower tail. So, the \\(\\log(a)\\) model appears to better meet the normality assumption.\nHowever, both models have issues with the smoother in the residuals v fitted graphs. For the \\(y3 ~ a\\) model, there is a general curve shape to the smoother and residuals that violates the linearity assumption. While this appears to be fixed somewhat by using \\(\\log(a)\\) instead, now the residuals get further and further away from the smoother and the fitted values get larger. (This shape is known as a megaphone.) This violates the assumption that the errors have constant variance.\nThus, we conclude that it appears neither model is a good fit."
  },
  {
    "objectID": "Modelling/Diagnostics.html#a-good-model",
    "href": "Modelling/Diagnostics.html#a-good-model",
    "title": "Model diagnostics",
    "section": "A good model",
    "text": "A good model\nTo explore what ideal residual plots look like, we are going to exactly fit the model \\[y1_i = a_i + b_i + \\epsilon_i.\\] Based on the way we have defined \\(y1\\) (y1 &lt;- a + b), we know that this model should fit the data almost exactly. (The almost stems from the random noise from \\(\\epsilon\\).) We plot several different diagnostic plots using the ‘plot()’ command.\nWe will explore each plot one by one.\n\n\nCode\n```{r}\n###| Fitting the model\nm1 &lt;- lm(y1 ~ a + b, data = data)\n\n###| Residual v fitted plot\nplot(m1, which = 1)\n```\n\n\n\n\n\n\n\n\n\nThe residuals v fitted values plot is a scatter plot of with the residuals on the y-axis and the fitted/predicted values on the x-axis. The red line (called the smoother) is a curve fitted to the residuals. If the structural component of the model is correct (i.e. the explanatory variables and not the errors), the smoother will be horizontal around 0.\nIn this example, we see a very flat smoother, centered at 0, with 3 labelled points that deviate from the general trend.\n\n\nCode\n```{r}\n###| Q-Q plot\nplot(m1, which = 2)\n```\n\n\n\n\n\n\n\n\n\nRecall that a model assumption is that the errors are normally distributed. The Q-Q plot allows us to check this assumption by plotting the absolute values of the standardized residuals on the y-axis and the theoretical quantiles of the standard half-normal distribution on the x-axis. If the errors are normally distributed, the dashed line will go through the origin and have a gradient of 1.\nIn this example, we see that the residuals do appear to be normally distributed, although at the tails, we do see 3 points that deviate from this.\n\n\nCode\n```{r}\n###| Cook's distance plot\nplot(m1, which = 4)\n```\n\n\n\n\n\n\n\n\n\nThis graph plots the Cook’s distance against the observation number, with the largest 3 values labelled. The Cook’s distance can be thought of as a measure of the influence of a particular observation. That is, it summarises how much the model changes, when you do and don’t include the ith data point.\nYou may notice that we have skipped several plots, namely: the location-scale plot and the standardized resivual v leverage plot. More information about diasgnotstic plots can be found here for those interested.",
    "crumbs": [
      "Home",
      "Linear modelling",
      "Model diagnostics"
    ]
  },
  {
    "objectID": "Modelling/Diagnostics.html#a-bad-model",
    "href": "Modelling/Diagnostics.html#a-bad-model",
    "title": "Model diagnostics",
    "section": "A bad model",
    "text": "A bad model\nNow, let us purposefully fit a bad model to see how the diagnostic plots change.\n\n\nCode\n```{r}\n###| Bad model example\nm2 &lt;- lm(y2 ~ a + b, data=data)\n\n###| Residual v fitted plot\nplot(m2, which = 1)\n```\n\n\n\n\n\n\n\n\n\nIn the residuals v fitted values plot, we observe that the smoother has a parabolic shape. This indicates that there is a problem in how we have constructed our model - specifically we are failing to meet the linearity assumption. If we look back to how we defined y2 (y2 &lt;- a + b^2), this makes sense. We cannot capture the \\(b^2\\) nature of our data if we are only using \\(a+b\\) as our explanatory variables.\n\n\nCode\n```{r}\n###| Q-Q plot\nplot(m2, which = 2)\n```\n\n\n\n\n\n\n\n\n\nIn the Q-Q plot, we note large deviations from the ideal dashed line at the upper tail. This indicates that our errors are not normally distributed, violating that assumption.\nSo, we conclude that \\(y2_i = a_i + b_i +\\epsilon_i\\) is a bad model as it violates the key model assumptions. But, how do we fix this?",
    "crumbs": [
      "Home",
      "Linear modelling",
      "Model diagnostics"
    ]
  },
  {
    "objectID": "Modelling/Diagnostics.html#transformations",
    "href": "Modelling/Diagnostics.html#transformations",
    "title": "Model diagnostics",
    "section": "Transformations",
    "text": "Transformations\nOn top of choosing which variables we include in our model, we can transform our variables to make the model fit better.\nFor example, in the \\(y2\\) case, we can create a new variable \\(b2\\) that is \\(b^2\\) and include this transformed variable into our model. However, by the principle of parsimony, we also need to include \\(b\\) into the model as well.\n\n\nCode\n```{r}\n###| Modeeling y2\nm3 &lt;- lm(y2 ~ a + b + I(b^2), data = data)\n\n###| Residuals v fitted plot\nplot(m3, which = 1)\n```\n\n\n\n\n\n\n\n\n\nIn the residuals plot, we observe a flat smoother. This indicates we are meeting the linearity assumption!\n\n\nCode\n```{r}\n###| Q-Q plot\nplot(m3, which = 2)\n```\n\n\n\n\n\n\n\n\n\nIn the Q-Q plot, we see that the data follows the dashed line, baring 3 exceptions at the extreme. Thus, the model appears to meet the normally distributed errors assumption.",
    "crumbs": [
      "Home",
      "Linear modelling",
      "Model diagnostics"
    ]
  },
  {
    "objectID": "Modelling/Diagnostics.html#another-bad-model",
    "href": "Modelling/Diagnostics.html#another-bad-model",
    "title": "Model diagnostics",
    "section": "Another bad model",
    "text": "Another bad model\nTo further explore diagnostic plots, let us consider one more model: \\[y3_i = a_i + \\epsilon.\\]\n\n\nCode\n```{r}\n###| y3 = a\nm4 &lt;- lm(y3 ~ a, data = data)\n\n###| Residual plot\nplot(m4, which = 1)\n```\n\n\n\n\n\n\n\n\n\nFitting this model, we observe a curve shape in the smoother, indicating that we are violating the linearity assumption. As the shape is not symmetric, it doesn’t seem like this is can be corrected by using \\(a^2\\). Instead, we can try using a logarithm.\n\n\nCode\n```{r}\n###| y3 = log(a)\nm5 &lt;- lm(y3 ~ log(a), data = data)\n\n###| Residual plot\nplot(m5, which = 1)\n```\n\n\n\n\n\n\n\n\n\nNow, we observe the correct behaviour of the smoother.",
    "crumbs": [
      "Home",
      "Linear modelling",
      "Model diagnostics"
    ]
  },
  {
    "objectID": "Modelling/Diagnostics.html#a-good-model-revisited",
    "href": "Modelling/Diagnostics.html#a-good-model-revisited",
    "title": "Model diagnostics",
    "section": "A good model revisited",
    "text": "A good model revisited\nOnce again, we will fit the model \\[y1_i = a_i + b_i + \\epsilon_i.\\] However, we will use the noisy dataset.\n\n\nCode\n```{r}\n###| y1 model\nM1 &lt;- lm(y1 ~ a + b, data = data2)\nplot(M1,which=1)\nplot(M1, which = 2)\n```\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNow, there is a lot more variation in the residuals. However, we still observe a roughly flat smoother so the model does not appear to be violating the linearity assumption.\nThe Q-Q plot still follows the ideal general trend, although the tails deviate slightly more.",
    "crumbs": [
      "Home",
      "Linear modelling",
      "Model diagnostics"
    ]
  },
  {
    "objectID": "Modelling/Diagnostics.html#a-bad-model-revisited",
    "href": "Modelling/Diagnostics.html#a-bad-model-revisited",
    "title": "Model diagnostics",
    "section": "A bad model revisited",
    "text": "A bad model revisited\nNow, we fit both of the following models: \\[\\begin{align}\ny2_i & = a_i + b_i + \\epsilon_i, \\\\\ny2_i & = a_i + b_i + b_i^2 + \\epsilon_i.\n\\end{align}\\]\n\n\n\n\n\n\nNote\n\n\n\nI have placed the graphs side by side for comparison using the par(mfrow = c(1,2))) command. More information about this, and graphics more generally, appears here.\n\n\n\n\nCode\n```{r}\n###| a + b\nM2 &lt;- lm(y2 ~ a + b, data = data2)\n\n###| a + b + b^2\nM3 &lt;- lm(y2 ~ a + b + I(b^2), data = data2)\n\n###| Plotting graphs side by side\npar(mfrow = c(1, 2))\nplot(M2,which=1)\nplot(M3,which=1)\n```\n\n\n\n\n\n\n\n\n\n\n\nCode\n```{r}\n###| Plotting graphs side by side\npar(mfrow = c(1, 2))\nplot(M2, which = 2)\nplot(M3, which = 2)\n```\n\n\n\n\n\n\n\n\n\nIn the residuals plot, we see the same general trends in behaviour that we saw before. The graph on the left, fitted with \\(a+b\\), displays the problematic parabolic behaviour in the smoother. The graph on the right, fitted with \\(a+b+b^2\\), has a flatter smoother.\nSimilarly, in the Q-Q plots, we observe that the left graph deviates at the tails more than the right graph.",
    "crumbs": [
      "Home",
      "Linear modelling",
      "Model diagnostics"
    ]
  },
  {
    "objectID": "Modelling/Diagnostics.html#another-bad-model-revisited",
    "href": "Modelling/Diagnostics.html#another-bad-model-revisited",
    "title": "Model diagnostics",
    "section": "Another bad model revisited",
    "text": "Another bad model revisited\nNow, we fit both of the following models: \\[\\begin{align}\ny2_i & = a_i \\epsilon_i, \\\\\ny2_i & = \\log(a_i) + \\epsilon_i.\n\\end{align}\\]\nAgain, for ease, I have plotted the graphs side by side.\n\n\nCode\n```{r}\n###| a \nM4 &lt;- lm(y3 ~ a, data = data2)\n\n###| log(a)\nM5 &lt;- lm(y3 ~ log(a), data = data2)\n\n###| Plotting graphs side by side\npar(mfrow = c(1, 2))\n\nplot(M4,which=1)\nplot(M5,which=1)\n\nplot(M4, which = 2)\nplot(M5, which = 2)\n```\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThis time, it is much less clear which of these two models is better.\nComparing the Q-Q plots, the left graph appears to deviate more on the lower tail. So, the \\(\\log(a)\\) model appears to better meet the normality assumption.\nHowever, both models have issues with the smoother in the residuals v fitted graphs. For the \\(y3 ~ a\\) model, there is a general curve shape to the smoother and residuals that violates the linearity assumption. While this appears to be fixed somewhat by using \\(\\log(a)\\) instead, now the residuals get further and further away from the smoother and the fitted values get larger. (This shape is known as a megaphone.) This violates the assumption that the errors have constant variance.\nThus, we conclude that it appears neither model is a good fit.",
    "crumbs": [
      "Home",
      "Linear modelling",
      "Model diagnostics"
    ]
  },
  {
    "objectID": "EDA/Cars dataset.html",
    "href": "EDA/Cars dataset.html",
    "title": "cars dataset",
    "section": "",
    "text": "A key step when first reviewing a dataset is to determine the variables and the important properties of each variable. For categorical data, this may be finding the names of the different categories and the count of each category (the number of elements). For continuous data, this may be finding the minimum, maximum, mean and median values.\nThis page will go through some practical examples using the inbuilt mtcars dataset.",
    "crumbs": [
      "Home",
      "Exploratory data analysis",
      "cars dataset"
    ]
  },
  {
    "objectID": "EDA/Cars dataset.html#vs-and-am-variables",
    "href": "EDA/Cars dataset.html#vs-and-am-variables",
    "title": "cars dataset",
    "section": "vs and am variables",
    "text": "vs and am variables\nIn the above summary output, we observe that a mean is given for the vs and am variables. However, from the history about the dataset, we know that these variables can only take values \\(0\\) and \\(1\\). Thus, it would be better for these values to be treated as factors.\nThere are several ways to do this. I give the first example using base R. The second uses the dplyr package, a very handy package for data manipulation.\n\n\nCode\n```{r}\n###| Factoring using base R\ncars_data$am &lt;- factor(cars_data$am)\ncars_data$vs &lt;- factor(cars_data$vs)\n\n###| Summary\nsummary(cars_data)\n```\n\n\n      mpg             cyl             disp             hp       \n Min.   :10.40   Min.   :4.000   Min.   : 71.1   Min.   : 52.0  \n 1st Qu.:15.43   1st Qu.:4.000   1st Qu.:120.8   1st Qu.: 96.5  \n Median :19.20   Median :6.000   Median :196.3   Median :123.0  \n Mean   :20.09   Mean   :6.188   Mean   :230.7   Mean   :146.7  \n 3rd Qu.:22.80   3rd Qu.:8.000   3rd Qu.:326.0   3rd Qu.:180.0  \n Max.   :33.90   Max.   :8.000   Max.   :472.0   Max.   :335.0  \n      drat             wt             qsec       vs     am          gear      \n Min.   :2.760   Min.   :1.513   Min.   :14.50   0:18   0:19   Min.   :3.000  \n 1st Qu.:3.080   1st Qu.:2.581   1st Qu.:16.89   1:14   1:13   1st Qu.:3.000  \n Median :3.695   Median :3.325   Median :17.71                 Median :4.000  \n Mean   :3.597   Mean   :3.217   Mean   :17.85                 Mean   :3.688  \n 3rd Qu.:3.920   3rd Qu.:3.610   3rd Qu.:18.90                 3rd Qu.:4.000  \n Max.   :4.930   Max.   :5.424   Max.   :22.90                 Max.   :5.000  \n      carb      \n Min.   :1.000  \n 1st Qu.:2.000  \n Median :2.000  \n Mean   :2.812  \n 3rd Qu.:4.000  \n Max.   :8.000  \n\n\n\n\nCode\n```{r}\n###| Package requirement\n# install.packages(\"dplyr\")\nlibrary(dplyr)\n```\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n\nCode\n```{r}\n###| Save the dataset\ncars_dplyr &lt;- mtcars\n\n###| Factoring variables\ncars_dplyr &lt;- cars_dplyr %&gt;%\n  mutate(vs = factor(vs),\n         am = factor(am))\n\n###| Summary of only vs and am columns\nsummary(cars_data[,c(8,9)])\n```\n\n\n vs     am    \n 0:18   0:19  \n 1:14   1:13",
    "crumbs": [
      "Home",
      "Exploratory data analysis",
      "cars dataset"
    ]
  },
  {
    "objectID": "EDA/Cars dataset.html#observation-names",
    "href": "EDA/Cars dataset.html#observation-names",
    "title": "cars dataset",
    "section": "Observation names",
    "text": "Observation names\nWe can find the names of each row using the rownames() command.\n\n\nCode\n```{r}\n###| Row/observation names\nrownames(cars_data)\n```\n\n\n [1] \"Mazda RX4\"           \"Mazda RX4 Wag\"       \"Datsun 710\"         \n [4] \"Hornet 4 Drive\"      \"Hornet Sportabout\"   \"Valiant\"            \n [7] \"Duster 360\"          \"Merc 240D\"           \"Merc 230\"           \n[10] \"Merc 280\"            \"Merc 280C\"           \"Merc 450SE\"         \n[13] \"Merc 450SL\"          \"Merc 450SLC\"         \"Cadillac Fleetwood\" \n[16] \"Lincoln Continental\" \"Chrysler Imperial\"   \"Fiat 128\"           \n[19] \"Honda Civic\"         \"Toyota Corolla\"      \"Toyota Corona\"      \n[22] \"Dodge Challenger\"    \"AMC Javelin\"         \"Camaro Z28\"         \n[25] \"Pontiac Firebird\"    \"Fiat X1-9\"           \"Porsche 914-2\"      \n[28] \"Lotus Europa\"        \"Ford Pantera L\"      \"Ferrari Dino\"       \n[31] \"Maserati Bora\"       \"Volvo 142E\"         \n\n\nLooking at the list, we can see some cars are made by the same manufacturer. It may be important to consider this in future analysis. So, let us create a new variable, manufacturer, that will account for this.\n\n\nCode\n```{r}\n###| New variable\ncars_data$manufacturer &lt;- factor(rownames(cars_data))\n\n###| Grouping the manufacturers\nlevels(cars_data$manufacturer) &lt;- list(AMC = \"AMC Javelin\", \n                                       Cadillac = \"Cadillac Fleetwood\" ,\n                                       Camaro = \"Camaro Z28\", \n                                       Datsum = \"Datsun 710\",\n                                       Dodge = \"Dodge Challenger\",\n                                       Duster = \"Duster 360\",\n                                       Ferrari = \"Ferrari Dino\",\n                                       Fiat = c(\"Fiat 128\",\"Fiat X1-9\"),\n                                       Ford = \"Ford Pantera L\",\n                                       Honda = \"Honda Civic\",\n                                       Hornet = c(\"Hornet 4 Drive\",\"Hornet Sportabout\"),\n                                       Lincoln = \"Lincoln Continental\",\n                                       Chrysler = \"Chrysler Imperial\",\n                                       Lotus = \"Lotus Europa\",\n                                       Maserati = \"Maserati Bora\",\n                                       Mazda = c(\"Mazda RX4\",\"Mazda RX4 Wag\"),\n                                       Merc = c(\"Merc 230\",\"Merc 240D\",\"Merc 280\",\n                                                \"Merc 280C\",\"Merc 450SE\",\"Merc 450SL\",\n                                                \"Merc 450SLC\"),\n                                       Pontiac = \"Pontiac Firebird\",\n                                       Porsche = \"Porsche 914-2\",\n                                       Toyota = c(\"Toyota Corolla\",\"Toyota Corona\"),\n                                       Valiant = \"Valiant\",\n                                       Volvo = \"Volvo 142E\")\n\n###| Checking output\ncars_data$manufacturer\n```\n\n\n [1] Mazda    Mazda    Datsum   Hornet   Hornet   Valiant  Duster   Merc    \n [9] Merc     Merc     Merc     Merc     Merc     Merc     Cadillac Lincoln \n[17] Chrysler Fiat     Honda    Toyota   Toyota   Dodge    AMC      Camaro  \n[25] Pontiac  Fiat     Porsche  Lotus    Ford     Ferrari  Maserati Volvo   \n22 Levels: AMC Cadillac Camaro Datsum Dodge Duster Ferrari Fiat Ford ... Volvo\n\n\nNow we have a variable that lists manufacturers. We can check the categories using the levels() command.\n\n\nCode\n```{r}\n###| Levels()\nlevels(cars_data$manufacturer)\n```\n\n\n [1] \"AMC\"      \"Cadillac\" \"Camaro\"   \"Datsum\"   \"Dodge\"    \"Duster\"  \n [7] \"Ferrari\"  \"Fiat\"     \"Ford\"     \"Honda\"    \"Hornet\"   \"Lincoln\" \n[13] \"Chrysler\" \"Lotus\"    \"Maserati\" \"Mazda\"    \"Merc\"     \"Pontiac\" \n[19] \"Porsche\"  \"Toyota\"   \"Valiant\"  \"Volvo\"",
    "crumbs": [
      "Home",
      "Exploratory data analysis",
      "cars dataset"
    ]
  },
  {
    "objectID": "EDA/Cars dataset.html#should-it-be-categorical-or-continuous",
    "href": "EDA/Cars dataset.html#should-it-be-categorical-or-continuous",
    "title": "cars dataset",
    "section": "Should it be categorical or continuous?",
    "text": "Should it be categorical or continuous?\nThere a few clear cut instances in the cars dataset where the variables should be categorical. We have addressed these: vm, am and manufacturer. However, there are instances where it is less clear.\nFor example, consider the cylinders variable. In our data, we have observations with 3 distinct categories: 4, 6 and 8. (We can find this with unique() function.)\n\n\nCode\n```{r}\n###| Cylinders\nunique(cars_data$cyl)\n```\n\n\n[1] 6 4 8\n\n\nThus, we could argue we should treat cylinders as categorical data. However, treating cylinders as categorical removes the ability to treat this as a single variable. As one variable, we could test how increasing the number of cylinders impacts performance.\nWhen we come to modelling, we should test models with cylinders treated as a continuous and a categorical variable.",
    "crumbs": [
      "Home",
      "Exploratory data analysis",
      "cars dataset"
    ]
  },
  {
    "objectID": "EDA/summary tables.html",
    "href": "EDA/summary tables.html",
    "title": "dplyr: summary tables",
    "section": "",
    "text": "We begin by loading in the cars dataset we used on the previous page (the code required is available below if needed). Please note that we want to use the version that has the manufacturers included!\n\n\nCode\n```{r}\n#| code-fold: true\n\n###| Code to create the dataset used in previous pages\ncars_data &lt;- mtcars\n\ncars_data$am &lt;- factor(cars_data$am)\ncars_data$vs &lt;- factor(cars_data$vs)\n\ncars_data$manufacturer &lt;- factor(rownames(cars_data))\nlevels(cars_data$manufacturer) &lt;- list(AMC = \"AMC Javelin\", \n                                       Cadillac = \"Cadillac Fleetwood\" ,\n                                       Camaro = \"Camaro Z28\", \n                                       Datsum = \"Datsun 710\",\n                                       Dodge = \"Dodge Challenger\",\n                                       Duster = \"Duster 360\",\n                                       Ferrari = \"Ferrari Dino\",\n                                       Fiat = c(\"Fiat 128\",\"Fiat X1-9\"),\n                                       Ford = \"Ford Pantera L\",\n                                       Honda = \"Honda Civic\",\n                                       Hornet = c(\"Hornet 4 Drive\",\"Hornet Sportabout\"),\n                                       Lincoln = \"Lincoln Continental\",\n                                       Chrysler = \"Chrysler Imperial\",\n                                       Lotus = \"Lotus Europa\",\n                                       Maserati = \"Maserati Bora\",\n                                       Mazda = c(\"Mazda RX4\",\"Mazda RX4 Wag\"),\n                                       Merc = c(\"Merc 230\",\"Merc 240D\",\"Merc 280\",\n                                                \"Merc 280C\",\"Merc 450SE\",\"Merc 450SL\",\n                                                \"Merc 450SLC\"),\n                                       Pontiac = \"Pontiac Firebird\",\n                                       Porsche = \"Porsche 914-2\",\n                                       Toyota = c(\"Toyota Corolla\",\"Toyota Corona\"),\n                                       Valiant = \"Valiant\",\n                                       Volvo = \"Volvo 142E\")\n```\n\n\n\n\nCode\n```{r}\n###| Checking the data is correct\nhead(cars_data)\n```\n\n\n                   mpg cyl disp  hp drat    wt  qsec vs am gear carb\nMazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4\nDatsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1\nHornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1\nHornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2\nValiant           18.1   6  225 105 2.76 3.460 20.22  1  0    3    1\n                  manufacturer\nMazda RX4                Mazda\nMazda RX4 Wag            Mazda\nDatsun 710              Datsum\nHornet 4 Drive          Hornet\nHornet Sportabout       Hornet\nValiant                Valiant\n\n\n\nA basic summary table\nTo create a summary table, we could manually calculate every entry and then create a dataset of these values and then create the table. However, it is much quicker (and easier) to use the summarise() function that comes with the dplyr package.\n\n\n\n\n\n\nNote\n\n\n\nThe dplyr package will be installed/active if you have tidyverse. Alternatively, you can directly install and activate the package with the following commands:\n\n\nCode\n```{r}\n#| warning: false # will remove output messages\n\n###| Package downloading and activating\n# install.packages(\"dplyr\")\nlibrary(dplyr)\n```\n\n\nIf you are using RStudio, you can check which packages are installed using the bottom right window.\n\n\nThe following code gives some examples of how to extract various summary statistics using the summarise() command.\n\n\nCode\n```{r}\n###| Basic summary table on continuous data\ncars_data %&gt;%\n  summarise(\"Num. observations\" = n(),\n            \"Mean mpg\" = mean(mpg),\n            \"Range displacement\" = max(disp)-min(disp),\n            \"Median horsepower\" = median(hp))\n```\n\n\n  Num. observations Mean mpg Range displacement Median horsepower\n1                32 20.09062              400.9               123\n\n\nThings get more complicated for categorical factors. We may need to use the length(), which() and unique() functions to find our desired statistics.\n\n\nCode\n```{r}\n###| Basic summary table on categorical data\ncars_data %&gt;%\n  summarise(\"vs 1\" = length(which(vs == 1)),\n            \"am 0\" = length(which(am == 0)),\n            \"Num. manufacturers\" = length(unique(manufacturer))\n  )\n```\n\n\n  vs 1 am 0 Num. manufacturers\n1   14   19                 22\n\n\n\n\nCylinder level exploration\nRecall that we identified 3 distinct cylinder levels (check using unique(cars_data$cyl)). To do this, we will use the group_by() function.\n\n\nCode\n```{r}\n###| Basic summary table grouped by cylinders\ncars_data %&gt;%\n  group_by(cyl) %&gt;%\n  summarise(\"Num. observations\" = n(),\n            \"Mean mpg\" = mean(mpg),\n            \"Range displacement\" = max(disp)-min(disp),\n            \"Median horsepower\" = median(hp),\n            \"vs 1\" = length(which(vs == 1)),\n            \"am 0\" = length(which(am == 0)),\n            \"Num. manufacturers\" = length(unique(manufacturer))\n  )\n```\n\n\n# A tibble: 3 × 8\n    cyl `Num. observations` `Mean mpg` `Range displacement` `Median horsepower`\n  &lt;dbl&gt;               &lt;int&gt;      &lt;dbl&gt;                &lt;dbl&gt;               &lt;dbl&gt;\n1     4                  11       26.7                 75.6                 91 \n2     6                   7       19.7                113                  110 \n3     8                  14       15.1                196.                 192.\n# ℹ 3 more variables: `vs 1` &lt;int&gt;, `am 0` &lt;int&gt;, `Num. manufacturers` &lt;int&gt;\n\n\n\n\n\n\n\n\nImportant\n\n\n\nIt is important to note that this summary table had \\(3\\) rows and not \\(1\\)! The statistics in each row correspond to the cars that had X number of cylinders. For example, of the \\(11\\) cars with \\(4\\) cylinders, the mean mpg was \\(26.6\\), the displacement range \\(75.6\\) etc…\n\n\nWhen reading off this table, we can note a few things about the different types of cars:\n\n\nFewer cars had \\(6\\) cylinders than \\(4\\) or \\(8\\).\nAs the number of cylinders increased, the mean mpg decreased, the displacement range increased, and the median horsepower increased.\nNo \\(8\\) cylinder cars had vs 1.\nThere is no clear pattern in the am 0 or manufacturer identifiable from this table.\n\n\n\n\nMaking the tables more readable\nThus far, we have relied on the raw R output to read the tables. This is not ideal for reports or long periods of work. Instead, we can use the kable() function from the kableExtra package for neat tables.\n\n\nCode\n```{r}\n###| Package\n# install.packages(\"kableExtra\")\nlibrary(kableExtra)\n```\n\n\n\nAttaching package: 'kableExtra'\n\n\nThe following object is masked from 'package:dplyr':\n\n    group_rows\n\n\nCode\n```{r}\n###| Grouped summary table \nsummary &lt;- cars_data %&gt;%\n  group_by(cyl) %&gt;%\n  summarise(\"Num. observations\" = n(),\n            \"Mean mpg\" = mean(mpg),\n            \"Range displacement\" = max(disp)-min(disp),\n            \"Median horsepower\" = median(hp),\n            \"vs 1\" = length(which(vs == 1)),\n            \"am 0\" = length(which(am == 0)),\n            \"Num. manufacturers\" = length(unique(manufacturer))\n  )\n\n###| Output\nkable(summary)\n```\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncyl\nNum. observations\nMean mpg\nRange displacement\nMedian horsepower\nvs 1\nam 0\nNum. manufacturers\n\n\n\n\n4\n11\n26.66364\n75.6\n91.0\n10\n3\n8\n\n\n6\n7\n19.74286\n113.0\n110.0\n4\n4\n5\n\n\n8\n14\n15.10000\n196.2\n192.5\n0\n12\n12\n\n\n\n\n\nWe can continue to change various arguments of the kable function to get truly beautiful tables. An excellent site for this is LINK. A quick example of some commands are the following:\n\n\nCode\n```{r}\n###| Example kable extra\nkable(summary, booktabs = TRUE, \n      col.names = c(\"Cylinders\",\"Total\",\"Mean MPG\",\"Displacement range\",\n                    \"Median horsepower\",\"Num vs 1\",\"Num am 0\",\n                    \"Num unique manufacturers\")) %&gt;%\n  add_header_above(c(\" \" = 1, \"Summary Statistics\" = 7))\n```\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSummary Statistics\n\n\n\nCylinders\nTotal\nMean MPG\nDisplacement range\nMedian horsepower\nNum vs 1\nNum am 0\nNum unique manufacturers\n\n\n\n\n4\n11\n26.66364\n75.6\n91.0\n10\n3\n8\n\n\n6\n7\n19.74286\n113.0\n110.0\n4\n4\n5\n\n\n8\n14\n15.10000\n196.2\n192.5\n0\n12\n12",
    "crumbs": [
      "Home",
      "Exploratory data analysis",
      "dplyr: summary tables"
    ]
  },
  {
    "objectID": "Modelling/Linear modelling intro.html",
    "href": "Modelling/Linear modelling intro.html",
    "title": "Introduction",
    "section": "",
    "text": "This section will begin by introducing a linear model, the key assumptions we must make to fit such a model and model diagnostics.\nSpecifically, the pages cover the following:\n\n\nWhat is a linear model?\n\nModel assumptions, with extra notes on linearity\nPrinciple of parsimony\n\nA continuous data example\n\nUsing lm() and anova()\n\nA categorical data example\n\nIntercepts and reference terms\nInteraction terms\n\nCheck your understanding by fitting various models on the data.csv and coursework.csv files.",
    "crumbs": [
      "Home",
      "Linear modelling",
      "Introduction"
    ]
  },
  {
    "objectID": "Data/Raw data.html#data.csv",
    "href": "Data/Raw data.html#data.csv",
    "title": "Data",
    "section": "data.csv",
    "text": "data.csv\n\n\nCode\n```{r}\n###| data.csv data\ndata &lt;- data.frame(\"x1\" = c(2.37, 8.38, 7.70, 5.52, 4.41, 5.98, 3.53, 2.28, 2.88, 5.91, 6.88, 2.75, 8.17, 3.38, 8.39, 3.36, 9.53, 3.61, 7.80, 2.20, 9.04, 5.21, 3.96, 9.07, 4.90, 9.27, 6.81, 6.64, 5.26, 8.31, 6.27, 5.17, 5.37, 3.25, 2.60, 4.68, 8.11, 4.82, 5.15, 4.24, 9.17, 4.48, 9.45, 4.99, 4.84, 9.83, 8.19, 2.56, 2.89, 9.75, 9.78, 7.12, 7.41, 6.30, 8.51, 6.65, 3.19, 5.43, 9.14, 7.60, 7.12, 9.26, 2.42, 9.65, 7.43, 2.67, 2.32, 9.05, 4.44, 7.25, 5.85, 2.26, 2.31, 2.10, 5.88, 8.54, 8.32, 4.32, 2.78, 5.69, 3.67, 2.38, 6.95, 6.19, 7.02, 4.96, 9.28, 7.69, 2.32, 6.96, 6.61, 4.63, 5.66, 3.22, 5.88, 4.41, 8.54, 8.73, 5.41, 8.25),\n                   \"x2\" = c(20.41, 4.34, 8.42, 3.59, 10.91, 9.56, 12.69, 138.84, 23.59, 2.31, 11.70, 59.57, 4.87, 18.75, 2.93, 17.42, 5.20, 5.28, 3.87, 20.17, 3.96, 10.24, 18.88, 3.98, 26.57, 4.15, 6.16, 5.98, 11.39, 3.53, 12.69, 6.26, 10.55, 42.94, 43.11, 52.78, 2.40, 17.09, 9.06, 21.93, 2.74, 10.55, 4.15, 23.82, 13.05, 1.82, 3.47, 31.44, 19.23, 3.43, 1.95, 12.40, 6.09, 3.36, 8.02, 8.91, 35.90, 15.56, 1.27, 5.13, 5.02, 2.90, 40.68, 6.46, 5.82, 12.67, 16.56, 1.34, 23.58, 9.46, 5.93, 13.97, 58.33, 61.60, 5.84, 2.96, 4.49, 8.51, 40.62, 5.56, 14.71, 25.94, 3.14, 13.14, 2.35, 22.47, 2.36, 2.05, 40.24, 6.95, 14.36, 8.20, 7.19, 24.89, 6.31, 28.04, 4.33, 5.26, 17.58, 15.15),\n                  \"y\" =  c(6.53, 10.72, 10.18,  8.85, 8.31, 9.29, 8.06, 6.53, 7.21, 9.28, 9.91, 7.04, 10.49, 7.67, 10.64, 7.86, 11.43, 8.13, 10.48, 6.30, 11.18, 8.71, 7.97, 11.20, 8.57, 10.90, 9.40, 9.51, 8.80, 10.54, 9.66,8.83,  9.12,  7.25,  6.52,  8.54, 10.99,  8.90 , 8.83 , 8.08, 11.07, 8.62, 11.03, 8.43, 8.68, 11.18, 10.58, 6.93, 7.08, 11.41, 11.27, 9.96, 10.48, 9.75, 10.66, 9.85, 7.24, 9.04, 11.18, 10.32, 10.14, 11.04, 6.49, 11.41, 10.06, 7.15, 6.65, 10.91, 8.51, 9.83, 9.42, 6.54, 6.90, 6.36, 9.07, 10.81, 10.91, 8.04, 7.15, 9.14, 7.60, 6.59, 9.97, 9.24, 9.95, 8.35, 11.03, 10.61, 6.57, 9.66, 10.09, 8.74, 9.03, 7.28, 9.52, 8.45, 10.79, 11.08, 9.09, 10.50))\n```"
  },
  {
    "objectID": "Data/Raw data.html#coursework.csv",
    "href": "Data/Raw data.html#coursework.csv",
    "title": "Data",
    "section": "coursework.csv",
    "text": "coursework.csv\n\n\nCode\n```{r}\n###| coursework data\ncoursework &lt;- data.frame(\"cw\" = c(5,5,10,12,14,16),\n                         \"exam\" = c(38,45,69,65,75,96))\n```"
  },
  {
    "objectID": "Mathematics to Code/Mathematics to Code NewtonRaph Example.html",
    "href": "Mathematics to Code/Mathematics to Code NewtonRaph Example.html",
    "title": "Newton–Raphson Method — Translating Math into Code",
    "section": "",
    "text": "Mathematical Intuition\nWe want to find a root of (f(x)=0).\nWe use the tangent line at (x_n) to estimate a better guess:\n[ x_{n+1} = x_n - . ]\nRepeat until ( |x_{n+1} - x_n| ) is small.\n\n\n\nMath → Algorithm → Code Mapping\n\n\n\nMath concept\nR translation\n\n\n\n\nupdate rule\nx_new &lt;- x - f(x)/df(x)\n\n\nderivative\nfunction df(x)\n\n\nconvergence\nabs(x_new - x) &lt; tol\n\n\n\n\n\n\nCode\n```{mermaid}\nflowchart TD\n  Start([Start: choose x0, tol, max_iter])\n  Compute[\"x_next = x - f(x)/f'(x)\"]\n  Check{|x_next - x| &lt; tol?|}\n  Accept([Return x_next])\n  Update[\"x &lt;- x_next\"]\n  Start --&gt; Compute --&gt; Check\n  Check -- Yes --&gt; Accept\n  Check -- No --&gt; Update --&gt; Compute\n```\n\n\n\n\n\nflowchart TD\n  Start([Start: choose x0, tol, max_iter])\n  Compute[\"x_next = x - f(x)/f'(x)\"]\n  Check{|x_next - x| &lt; tol?|}\n  Accept([Return x_next])\n  Update[\"x &lt;- x_next\"]\n  Start --&gt; Compute --&gt; Check\n  Check -- Yes --&gt; Accept\n  Check -- No --&gt; Update --&gt; Compute\n\n\n\n\n\n\n\n\n\nImplementation in R\n\n\nCode\n```{r}\nnewton &lt;- function(f, df, x0, tol = 1e-10, max_iter = 100) {\n  x &lt;- x0\n  for (i in 1:max_iter) {\n    fx &lt;- f(x)\n    dfx &lt;- df(x)\n    if (dfx == 0) stop(\"Derivative is zero; choose a new x0\")\n    x_new &lt;- x - fx / dfx\n    if (abs(x_new - x) &lt; tol) return(x_new)\n    x &lt;- x_new\n  }\n  stop(\"Did not converge\")\n}\n\n# Examples\nf1 &lt;- function(x) x^2 - 2\ndf1 &lt;- function(x) 2*x\nnewton(f1, df1, x0 = 1)\n```\n\n\n[1] 1.414214\n\n\n\n\n\nReflection\nThe Newton–Raphson method shows how an iterative analytic idea (tangent approximation) translates into a computational fixed-point loop.",
    "crumbs": [
      "Home",
      "Mathematics to R",
      "Newton–Raphson Method — Translating Math into Code"
    ]
  },
  {
    "objectID": "Data Visualisation/advice.html",
    "href": "Data Visualisation/advice.html",
    "title": "Best Practices",
    "section": "",
    "text": "In this section, we go through what makes a good data visualization. These come from the lecture material for ST231, ST237, ST346, and ST404."
  },
  {
    "objectID": "Data Visualisation/advice.html#labeling",
    "href": "Data Visualisation/advice.html#labeling",
    "title": "Best Practices",
    "section": "Labeling",
    "text": "Labeling\nEverything on your graph should be clearly labeled. In general, a graph contains:\n\ntitle — a clear short title letting the reader know what they’re looking at\nExample: Relationship between experience and wages by gender\ncaption — a short description of the graph and, where necessary, the source of the data\nExample: A star plot showing the different characteristics of reviewed wines. Source: https://www.kaggle.com/datasets/zynicide/wine-reviews/data\naxis labels — clear labels for the x and y axes\n\nshort but descriptive\ninclude units of measurement\nExamples:\n\nTree diameter (meters)\nSurvival time (days)\nPatient age (years)\n\n\nlegend — short informative title and labels\nExample: You can do this with the legend() function in R before or after the plot() you with to add a legend to\nlines and bars — label any trend lines, annotation lines, and error bars\n\nEssentially, the reader should be able to understand your graph without having to wade through paragraphs of text. When in doubt, show your data visualization to someone unfamiliar with your assignment and ask them if anything is unclear."
  },
  {
    "objectID": "Data Visualisation/advice.html#keep-it-simple",
    "href": "Data Visualisation/advice.html#keep-it-simple",
    "title": "Best Practices",
    "section": "Keep it Simple!",
    "text": "Keep it Simple!\nIn data science, the goal of data visualization is to communicate information. Anything that doesn’t support this goal should be reduced or eliminated entirely.\n\nChart Junk — visual elements of charts that aren’t necessary to comprehend the information represented by the chart or that distract from this information.\n\nLet us now go through an example of chart junk.\n\nGraph with chart junk\n\n\nCode\n```{r}\n# Import relevant libraries\nlibrary(ggplot2)\n```\n\n\nWarning: package 'ggplot2' was built under R version 4.4.3\n\n\nCode\n```{r}\nlibrary(dplyr)\n```\n\n\nWarning: package 'dplyr' was built under R version 4.4.3\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n\nCode\n```{r}\n# Setup of the dataframe for plotting use\nmpg_summary &lt;- mtcars |&gt;\nmutate(cyl = factor(cyl)) |&gt;\ngroup_by(cyl) |&gt;\nsummarise(mean_mpg = mean(mpg))\n```\n\n\n\n\nCode\n```{r Graph with chart junk, fig.cap=\"Graph with chart junk from the mtcars dataset\"}\n# LOTS of plotting elements from ggplot2, see the page about ggplot2 for more background on these\nggplot(mpg_summary, aes(x = cyl, y = mean_mpg, fill = cyl)) +\ngeom_col(color = \"black\", width = 0.8) +\nlabs(\ntitle = \"Different Mean Miles Per Gallon for Cars with Different Numbers of Cylinders\",\nx = \"Number of Cylinders\",\ny = \"Mean Miles Per Gallon\",\nfill = \"Cylinder Groups\"\n) +\ntheme(\npanel.background = element_rect(fill = \"lightblue\"),\npanel.border = element_rect(color = \"darkblue\", fill = NA, linewidth = 2),\npanel.grid.major = element_line(color = \"black\"),\npanel.grid.minor = element_line(color = \"black\"),\nplot.title = element_text(size = 16, face = \"bold\")\n)\n```\n\n\n\n\n\nGraph with chart junk from the mtcars dataset\n\n\n\n\nIf the goal is to compare the fuel efficiency of cars with different numbers of cylinders, much of this visualization is unnecessary and distracts from the task:\n\nColored background and thick border draw attention away from the bars\nHeavy black grid lines dominate the data\nColor fill adds a legend but doesn’t encode new information\nWordy title (“different”, “numbers of”) adds clutter\nThe reader must constantly look back and forth between the bars and y-axis\n\nQUESTION FOR THE READER\nLet’s now try to clean up. But before we do, how would YOU clean this up?\n\n\nGraph with chart junk removed\n\n\nCode\n```{r Graph with chart junk removed, fig.cap=\"Graph with chart junk removed from the mtcars dataset\"}\n# A better plot using ggplot2 again\nggplot(mpg_summary, aes(x = cyl, y = mean_mpg)) +\ngeom_col(fill = \"grey70\", width = 0.6) +\ngeom_col(\ndata = filter(mpg_summary, cyl == \"8\"),\nfill = \"#D55E00\",\nwidth = 0.6\n) +\ngeom_text(\naes(label = round(mean_mpg, 1)),\nvjust = -0.5,\nsize = 4\n) +\nlabs(\ntitle = \"Average fuel efficiency by number of cylinders\",\ny = \"Miles per gallon\",\nx = NULL\n) +\ntheme_minimal() +\ntheme(\npanel.grid.major.x = element_blank(),\npanel.grid.minor = element_blank()\n)\n```\n\n\n\n\n\nGraph with chart junk removed from the mtcars dataset\n\n\n\n\nThe chart junk has been removed. In addition:\n\nX-axis label removed (cylinder categories are obvious)\nY-axis label made more informative\nthe title has been simplified\nOne bar (8 cylinders) highlighted to aid comparison\nValues added directly to bars, reducing reliance on the axis\nGrid lines softened or removed to avoid distraction\n\nI may or may not have gone a bit far leaving out the x-axis label. It’s a fine line, knowing when to stop simplifying.\nIn general, you want to reduce chart junk to a minimum. In other words, more signal, less noise. At the end of the day, the data visualisation is an art specific to every data scientist, but there is good and bad art!"
  },
  {
    "objectID": "Data Visualisation/advice.html#color-choice",
    "href": "Data Visualisation/advice.html#color-choice",
    "title": "Best Practices",
    "section": "Color choice",
    "text": "Color choice\nColor choice is about more than aesthetics. Choose colors that help convey the information contained in the plot.\nThe article How to Choose Colors for Data Visualizations by Mike Yi\n(link) is a great place to start.\nBasically, think about selecting among sequential, diverging, and qualitative color schemes:\n\nSequential — for plotting a quantitative variable that goes from low to high\nDiverging — for contrasting the extremes (low, medium, and high) of a quantitative variable\nQualitative — for distinguishing among the levels of a categorical variable\n\nThe article above can help you to choose among these schemes.\nOther things to keep in mind:\n\nMake sure that text is legible — avoid dark text on dark backgrounds, light text on light backgrounds, and colors that clash in a discordant fashion (i.e., they hurt to look at!)\nAvoid combinations of red and green — it can be difficult for a colorblind audience to distinguish these colors"
  },
  {
    "objectID": "Data Visualisation/advice.html#y-axis-scaling",
    "href": "Data Visualisation/advice.html#y-axis-scaling",
    "title": "Best Practices",
    "section": "y-Axis scaling",
    "text": "y-Axis scaling\nThis is a big one. You can make an effect seem massive or insignificant depending on how you scale a numeric y-axis.\nConsider the following example comparing the 9-month salaries of male and female assistant professors. The data come from the Academic Salaries dataset.\n\n\nCode\n```{r load-salary-data, message=FALSE, warning=FALSE}\n# More library imports\nlibrary(carData)\nlibrary(scales)\nlibrary(patchwork)\n\n# Setup of the dataset to be used\ndata(Salaries, package = \"carData\")\n\ndf &lt;- Salaries %&gt;%\n  filter(rank == \"AsstProf\") %&gt;%\n  group_by(sex) %&gt;%\n  summarize(\n    n = n(),\n    mean = mean(salary),\n    sd = sd(salary),\n    se = sd / sqrt(n),\n    ci = qt(0.975, df = n - 1) * se\n  )\n\ndf\n```\n\n\n# A tibble: 2 × 6\n  sex        n   mean    sd    se    ci\n  &lt;fct&gt;  &lt;int&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Female    11 78050. 9372. 2826. 6296.\n2 Male      56 81311. 7901. 1056. 2116.\n\n\nNow let us plot the data:\n\n\nCode\n```{r}\n# Create a base plot\np &lt;- ggplot(df, aes(x = sex, y = mean, group = 1)) +\n  geom_point(size = 4) +\n  geom_line() +\n  labs(\n    title = \"Mean salary differences by gender\",\n    subtitle = \"9-month academic salary, 2007–2008\",\n    caption = paste(\n      \"Source: Fox J. and Weisberg S. (2011)\",\n      \"An R Companion to Applied Regression,\",\n      \"Second Edition, Sage\"\n    ),\n    x = \"Gender\",\n    y = \"Salary\"\n  ) +\n  scale_y_continuous(labels = scales::dollar)\n\np\n```\n\n\n\n\n\n\n\n\n\nGreat, now what if we plot the same data, but with the y-axis ranging from 77,000 to 82,000?\n\n\nCode\n```{r plot-narrow-y, fig.cap=\"Plot with limited range of Y\"}\n# Using ggplot2's feature of \"adding\" and \"subtracting\" features!\np + scale_y_continuous(limits = c(77000, 82000))\n```\n\n\nScale for y is already present.\nAdding another scale for y, which will replace the existing scale.\n\n\n\n\n\nPlot with limited range of Y\n\n\n\n\nThere now appears to be a very large gender difference! Now let us try to plot with the y-axis ranging from 0 to 125,000:\n\n\nCode\n```{r plot-wide-y, fig.cap=\"Plot with wider range of Y\"}\n# Same as the above code snippet!\np + scale_y_continuous(limits = c(0, 125000))\n```\n\n\nScale for y is already present.\nAdding another scale for y, which will replace the existing scale.\n\n\n\n\n\nPlot with wider range of Y\n\n\n\n\nThere doesn’t appear to be any gender difference! The goal of ethical data visualization is to represent findings with as little distortion as possible. This means choosing an appropriate range for the y-axis. Bar charts should almost always start at y = 0. For other charts, the limits really depend on subject matter knowledge of the expected range of values.\n\nPlots with other scales\nSome data might look better if we plot them on a different y-axis scale! Let us look at the airquality dataset:\n\n\nCode\n```{r}\n# Setup of the new dataset we will be using\nozone_summary &lt;- airquality |&gt;\nfilter(!is.na(Ozone)) |&gt;\ngroup_by(Month) |&gt;\nsummarise(\nmean = mean(Ozone),\nsd = sd(Ozone),\nn = n(),\nse = sd / sqrt(n),\nci = qt(0.975, df = n - 1) * se\n)\n```\n\n\n\n\nCode\n```{r, fig.cap=\"Plot showing the difference between the normal and log scale\"}\n# Using ggplot for the linear and log scale plots\np_linear &lt;- ggplot(ozone_summary, aes(x = factor(Month), y = mean)) +\ngeom_col(fill = \"grey70\", width = 0.6) +\ngeom_errorbar(\naes(ymin = mean - ci, ymax = mean + ci),\nwidth = 0.1\n) +\nlabs(\ntitle = \"Mean ozone concentration by month\",\nsubtitle = \"Linear scale: comparisons reflect absolute differences\",\nx = NULL,\ny = \"Ozone concentration\"\n) +\ntheme_minimal()\n\np_log &lt;- ggplot(ozone_summary, aes(x = factor(Month), y = mean)) +\ngeom_col(fill = \"grey70\", width = 0.6) +\ngeom_errorbar(\naes(ymin = mean - ci, ymax = mean + ci),\nwidth = 0.1\n) +\nscale_y_log10() +\nlabs(\nsubtitle = \"Log scale: equal distances represent equal ratios (percentage changes)\",\nx = \"Month\",\ny = \"Ozone concentration (log scale)\"\n) +\ntheme_minimal()\n\n# Combining the two plots into one through the patchwork package\np_linear / p_log\n```\n\n\n\n\n\nPlot showing the difference between the normal and log scale\n\n\n\n\nThe upper panel uses a linear scale, where visual differences correspond to absolute changes in ozone concentration. The lower panel uses a logarithmic scale, where equal distances represent equal ratios rather than equal differences. For this right-skewed data, the log scale facilitates comparison in relative terms and reduces the dominance of large values."
  },
  {
    "objectID": "Data Visualisation/advice.html#further-resources",
    "href": "Data Visualisation/advice.html#further-resources",
    "title": "Best Practices",
    "section": "Further Resources",
    "text": "Further Resources\nIf you would like to learn more about ggplot2 there are several good sources included in the ggplot2 page!\nIf you would like to learn more about data visualization in general, here are some useful resources:\n\nScott Berinato’s Harvard Business Review article Visualizations that really work https://hbr.org/2016/06/visualizations-that-really-work\nWall Street Journal’s guide to information graphics: The dos and don’ts of presenting data, facts and figures (Wong 2010)\nA Practical Guide to Graphics Reporting: Information graphics for print, web & broadcast (George-Palilonis 2017)\nBeautiful Data: The stories behind elegant data solutions (Hammerbacher and Jeff 2009)\nThe Truthful Art: Data, charts, and maps for communication (Cairo 2016)\nThe Information is Beautiful website: https://informationisbeautiful.net\n\nThe best graphs are rarely created on the first attempt. Experiment until you have a visualization that clarifies the data and helps communicate a meaningful story. And have fun!"
  },
  {
    "objectID": "Data Visualisation/baseR and ggplot.html",
    "href": "Data Visualisation/baseR and ggplot.html",
    "title": "Introduction to ggplot2: The Grammar of Graphics",
    "section": "",
    "text": "This section offers a primer on how the ggplot2 package operates. Unlike many other plotting systems, ggplot2 is based on the “Grammar of Graphics,” which allows you to build graphs layer by layer. We will construct a complex visualization starting from a blank canvas and adding elements—like data points, trend lines, and labels—one step at a time.\nLet’s dive in with an example.",
    "crumbs": [
      "Home",
      "Data Visualisation",
      "Introduction to ggplot2: The Grammar of Graphics"
    ]
  },
  {
    "objectID": "Data Visualisation/importing data.html",
    "href": "Data Visualisation/importing data.html",
    "title": "Data Import and Preparation in R",
    "section": "",
    "text": "Before you can visualize or analyze data, you need to get it into R and prepare it properly. This step is crucial—even the most sophisticated analysis will fail if your data isn’t prepared correctly. Think of it like preparing ingredients before cooking: skipping or rushing this step will affect everything that follows.\nIn this guide, we’ll learn how to import data from various file formats and clean it for analysis. We’ll use the palmerpenguins dataset for most examples, which contains measurements of penguins from Antarctica.",
    "crumbs": [
      "Home",
      "Data Visualisation",
      "Data Import and Preparation in R"
    ]
  },
  {
    "objectID": "Data Visualisation/importing data.html#text-and-csv-files",
    "href": "Data Visualisation/importing data.html#text-and-csv-files",
    "title": "cars dataset",
    "section": "Text and CSV files",
    "text": "Text and CSV files\nThe readr package provides functions for importing delimited text files into R data frames.\n\n\nCode\n```{r,  eval=FALSE}\nlibrary(readr)\n\n# import data from a comma delimited file\nSalaries &lt;- read_csv(\"salaries.csv\")\n\n# import data from a tab delimited file\nSalaries &lt;- read_tsv(\"salaries.txt\")\n```\n\n\nThese function assume that the first line of data contains the variable names, values are separated by commas or tabs respectively, and that missing data are represented by blanks. For example, the first few lines of the comma delimited file looks like this.\n“rank”,“discipline”,“yrs.since.phd”,“yrs.service”,“sex”,“salary” “Prof”,“B”,19,18,“Male”,139750 “Prof”,“B”,20,16,“Male”,173200 “AsstProf”,“B”,4,3,“Male”,79750 “Prof”,“B”,45,39,“Male”,115000 “Prof”,“B”,40,41,“Male”,141500 “AssocProf”,“B”,6,6,“Male”,97000\nOptions allow you to alter these assumptions. See the ?read_delim for more details. https://www.rdocumentation.org/packages/readr/versions/0.1.1/topics/read_delim"
  },
  {
    "objectID": "Data Visualisation/importing data.html#other-file-types",
    "href": "Data Visualisation/importing data.html#other-file-types",
    "title": "cars dataset",
    "section": "Other File Types",
    "text": "Other File Types\nThe readxl package can import data from Excel workbooks. Both .xls and .xlsx formats are supported.\n\n\nCode\n```{r,  eval=FALSE}\nlibrary(readxl)\n\n# import data from an Excel workbook\nSalaries &lt;- read_excel(\"salaries.xlsx\", sheet=1)\n```\n\n\nSince workbooks can have more than one worksheet, you can specify the one you want with the sheet option. The default is sheet=1.\nThe haven package provides functions for importing data from a variety of statistical packages without needing to have the packages themselves installed on your machine.\n\n\nCode\n```{r,  eval=FALSE}\nlibrary(haven)\n\n# import data from Stata\nSalaries &lt;- read_dta(\"salaries.dta\")\n\n# import data from SPSS\nSalaries &lt;- read_sav(\"salaries.sav\")\n\n# import data from SAS\nSalaries &lt;- read_sas(\"salaries.sas7bdat\")\n```"
  },
  {
    "objectID": "Data Visualisation/importing data.html#select-function",
    "href": "Data Visualisation/importing data.html#select-function",
    "title": "cars dataset",
    "section": "select function",
    "text": "select function\nThe select function allows you to limit your dataset to specified variables (columns).\n\n\nCode\n```{r}\nlibrary(dplyr)\n```\n\n\nWarning: package 'dplyr' was built under R version 4.4.3\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n\nCode\n```{r}\n# keep the variables name, height, and gender\nnewdata &lt;- select(starwars, name, height, gender)\n\nhead(newdata)\n\n# keep the variables name and all variables \n# between mass and species inclusive\nnewdata &lt;- select(starwars, name, mass:species)\n\nhead(newdata)\n\n# keep all variables except birth_year and gender\nnewdata &lt;- select(starwars, -birth_year, -gender)\n\nhead(newdata)\n```\n\n\n# A tibble: 6 × 3\n  name           height gender   \n  &lt;chr&gt;           &lt;int&gt; &lt;chr&gt;    \n1 Luke Skywalker    172 masculine\n2 C-3PO             167 masculine\n3 R2-D2              96 masculine\n4 Darth Vader       202 masculine\n5 Leia Organa       150 feminine \n6 Owen Lars         178 masculine\n# A tibble: 6 × 10\n  name    mass hair_color skin_color eye_color birth_year sex   gender homeworld\n  &lt;chr&gt;  &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;    \n1 Luke …    77 blond      fair       blue            19   male  mascu… Tatooine \n2 C-3PO     75 &lt;NA&gt;       gold       yellow         112   none  mascu… Tatooine \n3 R2-D2     32 &lt;NA&gt;       white, bl… red             33   none  mascu… Naboo    \n4 Darth…   136 none       white      yellow          41.9 male  mascu… Tatooine \n5 Leia …    49 brown      light      brown           19   fema… femin… Alderaan \n6 Owen …   120 brown, gr… light      blue            52   male  mascu… Tatooine \n# ℹ 1 more variable: species &lt;chr&gt;\n# A tibble: 6 × 12\n  name      height  mass hair_color skin_color eye_color sex   homeworld species\n  &lt;chr&gt;      &lt;int&gt; &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;     &lt;chr&gt; &lt;chr&gt;     &lt;chr&gt;  \n1 Luke Sky…    172    77 blond      fair       blue      male  Tatooine  Human  \n2 C-3PO        167    75 &lt;NA&gt;       gold       yellow    none  Tatooine  Droid  \n3 R2-D2         96    32 &lt;NA&gt;       white, bl… red       none  Naboo     Droid  \n4 Darth Va…    202   136 none       white      yellow    male  Tatooine  Human  \n5 Leia Org…    150    49 brown      light      brown     fema… Alderaan  Human  \n6 Owen Lars    178   120 brown, gr… light      blue      male  Tatooine  Human  \n# ℹ 3 more variables: films &lt;list&gt;, vehicles &lt;list&gt;, starships &lt;list&gt;"
  },
  {
    "objectID": "Data Visualisation/importing data.html#selecting-observations",
    "href": "Data Visualisation/importing data.html#selecting-observations",
    "title": "cars dataset",
    "section": "Selecting Observations",
    "text": "Selecting Observations\nThe filter function allows you to limit your dataset to observations (rows) meeting a specific criteria. Multiple criteria can be combined with the & (AND) and | (OR) symbols.\n\n\nCode\n```{r}\n# select females\nnewdata &lt;- filter(starwars, \n                  sex == \"female\")\n\nhead(newdata)\n\n# select females that are from Alderaan\nnewdata &lt;- filter(starwars, \n                  sex == \"female\" & \n                  homeworld == \"Alderaan\")\n\nhead(newdata)\n\n# select individuals that are from Alderaan, Coruscant, or Endor\nnewdata &lt;- filter(starwars, \n                  homeworld == \"Alderaan\" | \n                  homeworld == \"Coruscant\" | \n                  homeworld == \"Endor\")\n\nhead(newdata)\n\n# this can be written more succinctly as\nnewdata &lt;- filter(starwars, \n                  homeworld %in% \n                    c(\"Alderaan\", \"Coruscant\", \"Endor\"))\n\nhead(newdata)\n```\n\n\n# A tibble: 6 × 14\n  name      height  mass hair_color skin_color eye_color birth_year sex   gender\n  &lt;chr&gt;      &lt;int&gt; &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; \n1 Leia Org…    150    49 brown      light      brown             19 fema… femin…\n2 Beru Whi…    165    75 brown      light      blue              47 fema… femin…\n3 Mon Moth…    150    NA auburn     fair       blue              48 fema… femin…\n4 Padmé Am…    185    45 brown      light      brown             46 fema… femin…\n5 Shmi Sky…    163    NA black      fair       brown             72 fema… femin…\n6 Ayla Sec…    178    55 none       blue       hazel             48 fema… femin…\n# ℹ 5 more variables: homeworld &lt;chr&gt;, species &lt;chr&gt;, films &lt;list&gt;,\n#   vehicles &lt;list&gt;, starships &lt;list&gt;\n# A tibble: 1 × 14\n  name      height  mass hair_color skin_color eye_color birth_year sex   gender\n  &lt;chr&gt;      &lt;int&gt; &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; \n1 Leia Org…    150    49 brown      light      brown             19 fema… femin…\n# ℹ 5 more variables: homeworld &lt;chr&gt;, species &lt;chr&gt;, films &lt;list&gt;,\n#   vehicles &lt;list&gt;, starships &lt;list&gt;\n# A tibble: 6 × 14\n  name      height  mass hair_color skin_color eye_color birth_year sex   gender\n  &lt;chr&gt;      &lt;int&gt; &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; \n1 Leia Org…    150    49 brown      light      brown             19 fema… femin…\n2 Wicket S…     88    20 brown      brown      brown              8 male  mascu…\n3 Finis Va…    170    NA blond      fair       blue              91 male  mascu…\n4 Adi Gall…    184    50 none       dark       blue              NA fema… femin…\n5 Bail Pre…    191    NA black      tan        brown             67 male  mascu…\n6 Jocasta …    167    NA white      fair       blue              NA fema… femin…\n# ℹ 5 more variables: homeworld &lt;chr&gt;, species &lt;chr&gt;, films &lt;list&gt;,\n#   vehicles &lt;list&gt;, starships &lt;list&gt;\n# A tibble: 6 × 14\n  name      height  mass hair_color skin_color eye_color birth_year sex   gender\n  &lt;chr&gt;      &lt;int&gt; &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; \n1 Leia Org…    150    49 brown      light      brown             19 fema… femin…\n2 Wicket S…     88    20 brown      brown      brown              8 male  mascu…\n3 Finis Va…    170    NA blond      fair       blue              91 male  mascu…\n4 Adi Gall…    184    50 none       dark       blue              NA fema… femin…\n5 Bail Pre…    191    NA black      tan        brown             67 male  mascu…\n6 Jocasta …    167    NA white      fair       blue              NA fema… femin…\n# ℹ 5 more variables: homeworld &lt;chr&gt;, species &lt;chr&gt;, films &lt;list&gt;,\n#   vehicles &lt;list&gt;, starships &lt;list&gt;"
  },
  {
    "objectID": "Data Visualisation/importing data.html#creatingrecoding-variables",
    "href": "Data Visualisation/importing data.html#creatingrecoding-variables",
    "title": "cars dataset",
    "section": "Creating/Recoding Variables",
    "text": "Creating/Recoding Variables\nThe mutate function allows you to create new variables or transform existing ones.\n\n\nCode\n```{r}\n# convert height in centimeters to inches, \n# and mass in kilograms to pounds\nnewdata &lt;- mutate(starwars, \n                  height = height * 0.394,\n                  mass   = mass   * 2.205)\n```\n\n\nThe ifelse function (part of base R) can be used for recoding data. The format is ifelse(test, return if TRUE, return if FALSE).\n\n\nCode\n```{r}\n# if height is greater than 180 then heightcat = \"tall\", \n# otherwise heightcat = \"short\"\n\nnewdata &lt;- mutate(starwars, \n                  heightcat = ifelse(height &gt; 180, \n                                     \"tall\", \n                                     \"short\"))\n                  \n# convert any eye color that is not black, blue or brown, to other.\nnewdata &lt;- mutate(starwars, \n                  eye_color = ifelse(eye_color %in% \n                                     c(\"black\", \"blue\", \"brown\"),\n                                     eye_color,\n                                     \"other\"))\n                  \n# set heights greater than 200 or less than 75 to missing\nnewdata &lt;- mutate(starwars, \n                  height = ifelse(height &lt; 75 | height &gt; 200,\n                                     NA,\n                                     height))\n```\n\n\n2.2.4 Summarizing data\nThe summarize function can be used to reduce multiple values down to a single value (such as a mean). It is often used in conjunction with the by_group function, to calculate statistics by group. In the code below, the na.rm=TRUE option is used to drop missing values before calculating the means.\nlibrary(dplyr)"
  },
  {
    "objectID": "Data Visualisation/importing data.html#a-tibble-1-2",
    "href": "Data Visualisation/importing data.html#a-tibble-1-2",
    "title": "cars dataset",
    "section": "# A tibble: 1 × 2",
    "text": "# A tibble: 1 × 2"
  },
  {
    "objectID": "Data Visualisation/importing data.html#mean_ht-mean_mass",
    "href": "Data Visualisation/importing data.html#mean_ht-mean_mass",
    "title": "cars dataset",
    "section": "mean_ht mean_mass",
    "text": "mean_ht mean_mass"
  },
  {
    "objectID": "Data Visualisation/importing data.html#section-1",
    "href": "Data Visualisation/importing data.html#section-1",
    "title": "cars dataset",
    "section": "1 175. 97.3",
    "text": "1 175. 97.3"
  },
  {
    "objectID": "Data Visualisation/importing data.html#a-tibble-3-3",
    "href": "Data Visualisation/importing data.html#a-tibble-3-3",
    "title": "cars dataset",
    "section": "# A tibble: 3 × 3",
    "text": "# A tibble: 3 × 3"
  },
  {
    "objectID": "Data Visualisation/importing data.html#gender-mean_ht-mean_wt",
    "href": "Data Visualisation/importing data.html#gender-mean_ht-mean_wt",
    "title": "cars dataset",
    "section": "gender mean_ht mean_wt",
    "text": "gender mean_ht mean_wt"
  },
  {
    "objectID": "Data Visualisation/importing data.html#feminine-167.-54.7",
    "href": "Data Visualisation/importing data.html#feminine-167.-54.7",
    "title": "cars dataset",
    "section": "1 feminine 167. 54.7",
    "text": "1 feminine 167. 54.7"
  },
  {
    "objectID": "Data Visualisation/importing data.html#masculine-177.-107.",
    "href": "Data Visualisation/importing data.html#masculine-177.-107.",
    "title": "cars dataset",
    "section": "2 masculine 177. 107.",
    "text": "2 masculine 177. 107."
  },
  {
    "objectID": "Data Visualisation/importing data.html#section-3",
    "href": "Data Visualisation/importing data.html#section-3",
    "title": "cars dataset",
    "section": "3  175 81",
    "text": "3  175 81\nGraphs are often created from summarized data, rather than from the original observations. You will see several examples in Chapter 4. 2.2.5 Using pipes\nPackages like dplyr and tidyr allow you to write your code in a compact format using the pipe %&gt;% operator. Here is an example.\nlibrary(dplyr)"
  },
  {
    "objectID": "Data Visualisation/importing data.html#data.frame-3-obs.-of-1-variable",
    "href": "Data Visualisation/importing data.html#data.frame-3-obs.-of-1-variable",
    "title": "cars dataset",
    "section": "‘data.frame’: 3 obs. of 1 variable:",
    "text": "‘data.frame’: 3 obs. of 1 variable:"
  },
  {
    "objectID": "Data Visualisation/importing data.html#dob-chr-11101963-jan-23-91-1212001",
    "href": "Data Visualisation/importing data.html#dob-chr-11101963-jan-23-91-1212001",
    "title": "cars dataset",
    "section": "$ dob: chr “11/10/1963” “Jan-23-91” “12:1:2001”",
    "text": "$ dob: chr “11/10/1963” “Jan-23-91” “12:1:2001”\nThere are many ways to convert character variables to Date variables. One of they simplest is to use the functions provided in the lubridate package. These include ymd, dmy, and mdy for importing year-month-day, day-month-year, and month-day-year formats respectively.\nlibrary(lubridate) # convert dob from character to date df\\(dob &lt;- mdy(df\\)dob) str(df)"
  },
  {
    "objectID": "Data Visualisation/importing data.html#data.frame-3-obs.-of-1-variable-1",
    "href": "Data Visualisation/importing data.html#data.frame-3-obs.-of-1-variable-1",
    "title": "cars dataset",
    "section": "‘data.frame’: 3 obs. of 1 variable:",
    "text": "‘data.frame’: 3 obs. of 1 variable:"
  },
  {
    "objectID": "Data Visualisation/importing data.html#dob-date-format-1963-11-10-1991-01-23",
    "href": "Data Visualisation/importing data.html#dob-date-format-1963-11-10-1991-01-23",
    "title": "cars dataset",
    "section": "$ dob: Date, format: “1963-11-10” “1991-01-23” …",
    "text": "$ dob: Date, format: “1963-11-10” “1991-01-23” …\nThe values are recorded internally as the number of days since January 1, 1970. Now that the variable is a Date variable, you can perform date arithmetic (how old are they now), extract date elements (month, day, year), and reformat the values (e.g., October 11, 1963). Date variables are important for time-dependent graphs (Chapter 8). 2.2.7 Reshaping data\nSome graphs require the data to be in wide format, while some graphs require the data to be in long format. An example of wide data is given in Table 2.1. Table 2.1: Wide data id name sex height weight 01 Bill Male 70 180 02 Bob Male 72 195 03 Mary Female 62 130\nYou can convert a wide dataset to a long dataset (Table 2.2) using"
  },
  {
    "objectID": "Report Writing/stylereport.html",
    "href": "Report Writing/stylereport.html",
    "title": "Warwick Statistics Society R Course 2024-2025",
    "section": "",
    "text": "4 Content Here are some guidelines. 1. The report must be self-contained: everything should either be stated ex- plicitly, be justified by a reference to some other source, or be common knowledge. In particular, the source of any data should be clearly indi- cated. 2. It is not usually sensible to describe everything that you did in detail. Indeed, if you modify your approach, there is no need to describe the earlier approach more than briefly. 5 Presentation Reports should be attractive and easy to find one’s way through. Hence, they should be neat, clean and tidy, and must be legible. It is advisable that you try to word-process the report– not a difficult thing to do on the School of Mathematics or other University PCs available to you using Word or Latex. 5.1 Figures, Plots, diagrams, etc. Tables, figures, graphs, and diagrams should be titled and numbered (and prefer- ably given a caption). Sections (which should have headings) and pages should 5 also be numbered. Headings should stand out (by being underlined or on a sepa- rate line, for example) and should never appear as the last line of a page. Think of a report as needing signposts, provided by the section numbers. Similarly, graphs need to be neatly drawn, carefully labelled and titled: scales should be chosen sensibly and the units indicated. Freehand graphs, carefully drawn, may be appropriate; a sketch graph with various amendments, and axes carelessly drawn, will never be. As far as possible, tables and diagrams should be placed in the text near to the passage referring to them. 5.2 Tables Tables need titles, numbering and captions, should be boxed in, and figures in columns should be aligned correctly, usually so that the decimal points fall in the same column. Rows and columns usually need labels or headings, and units must be stated in, or perhaps close to, the table. 5.3 Computer output Computer output needs some thought. For a student project, it may not be nec- essary to copy the results from the output so that they have the same appearance as the rest of the report; it should suffice if the output is edited appropriately first and then pasted onto the body of the report or otherwise attach it. A possibly helpful reference is Chapman & Mahon (1986). 6 Use of English It is very important that you think carefully about your use of English. The ob- ject of writing, as of speaking, is to communicate. Writing, in particular, requires very careful use of language, especially when abstract and difficult concepts (such as those involved in statistical modelling and analysis) are to be communicated. It is easy to read and understand English which is well written and follows the rules of good usage. However, as the quality of writing deteriorates, it becomes progressively more difficult for the reader to work out its intended meaning. Fi- nally it becomes impossible. While many project reports are written to a very high standard, many others contain much that is unintelligible. An obvious, and easily corrected, problem occurs when the author fails to use properly constructed sentences. (A good first test check here is to identify the verb in each sentence!) A much more insidious (and very frequent) problem occurs when the author un- consciously assumes that the reader is somehow following his/her quite unwritten train of thought. Thus the reader is presumed to know exactly what the author is talking about—for example, what variables are currently being considered, what is being held fixed, and what is being allowed to vary - when in fact none of this 6 has ever been stated. Attached to this document are some illustrative quotations, with commentary where appropriate, which have been taken from recent project reports. In most cases you will find that the sentences look just fine - until you try to decode the meaning. How should you attempt to improve the quality of your writing? It is important to understand that, like learning to drive, this is something you have to work at. No doubt an ability to write well comes more easily to some than to others, but everyone needs to put some effort into acquir- ing this skill, and anyone can improve if they do. Of course there are plenty of books on how to write well, but perhaps the most useful thing you can do is to read widely (books, articles in quality newspapers, etc ) and learn to observe how others write. 7 Style 1. Be brief and to the point and use shorter rather than longer words. Thus, ‘schools and colleges’ is to be preferred to ‘educational establishments’ if the two phrases are used with the same meaning. If you find that you are writing about something not relevant to your heading then either the material belongs elsewhere, possibly even to a new separate section, or you are rambling and the material should be omitted. 2. In general, try to avoid the use of the personal pronoun “I”, as it can get very irritating to the reader. Impersonal verbs and the passive form are usually to be preferred, e.g. “A regression analysis was carried out” instead of “I carried out a regression analysis”. 3. Use of tenses: A scientific report should be written in the present tense e.g ”The statistical analysis shows that……”, not ”The statistical analysis showed that…..”. You use the past tense only when describing events that occurred in the past e.g ”The data were collected in a study conducted by Royal Statistical Society……”. 4. Try to get your spelling correct! The main problem is knowing which words’ spelling you are shaky on. If in doubt, look up the word in a good dictionary (Oxford, Cassells, for example) or use a spell-checker. 5. Avoid using words inappropriately. For example, the similar-sounding words “tendency” and “trend” are not the same and cannot be used in- terchangeably. Do not use the word “significant” other than in a statistical sense. 6. If it is not too late, try to write grammatically: whole sentences, each with its main verb; no telegraphic style. Thus, the following is not acceptable. 7 “A standard analysis is possible. By regression.” Mathematical/Statistical writing follows the same grammar and syntax as ordinary English. 7. A common error: the word “data” is treated as if it were a singular noun instead of as a plural noun, which it is! (Data=plural of the singular noun datum.) The correct use of the word is “Data are …”. 8. A good style, which is a pleasure to read, is not something which comes naturally to mathematicians on the whole. Nevertheless, it is worth trying to aim for it. The only way to develop a good style is to read good books, practice writing and read critically what you have written. Gowers (1973) and Fowler (1983) (see references at the end) are useful books on grammar, punctuation and style."
  },
  {
    "objectID": "Report Writing/reportintro.html",
    "href": "Report Writing/reportintro.html",
    "title": "Introduction to Report Writing",
    "section": "",
    "text": "“We have the duty of formulating, of summarizing, and of communicating our conclusions, in intelligible form, in recognition of the right of other free minds to utilize them in making their own decisions.”\n\nIn this section, we will be going though report writing techniques and conventions that will help in you ST117 final project, and the entirety of ST231. Specifically, the pages cover the following:\n\nStructuring your Report\n\n\nReporting descriptive statistics\n\n\nReporting numbers: how many decimal places?\n\n\nPresenting your data: tables and graphs\n\n\nStyling your Report\n\n\nUse of English\n\n\nProper use of Large Language, and other generative AI models\n\n\nPresenting the results of a statistical test 1 Summary 2 2 Introduction 2 3 Structure 2 3.1 Title . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3 3.2 Summary/Abstract . . . . . . . . . . . . . . . . . . . . . . . . . . 3 3.3 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3 3.4 Methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3 3.5 Results, conclusions and recommendations . . . . . . . . . . . . . 4 3.6 General discussion . . . . . . . . . . . . . . . . . . . . . . . . . . 4 3.7 References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5 3.8 Appendix . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5 4 Content 5 5 Presentation 5 5.1 Figures, Plots, diagrams, etc. . . . . . . . . . . . . . . . . . . . . 5 5.2 Tables . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6 5.3 Computer output . . . . . . . . . . . . . . . . . . . . . . . . . . . 6 6 Use of English 6 7 Style 7 8 Detailed Preparation 8 9 Afterwards 8",
    "crumbs": [
      "Home",
      "Report Writing",
      "Introduction to Report Writing"
    ]
  },
  {
    "objectID": "Mathematics to Code/Mathematics to Code MonteCarlo Example.html",
    "href": "Mathematics to Code/Mathematics to Code MonteCarlo Example.html",
    "title": "Monte Carlo Approximation of π — Translating Math into Code",
    "section": "",
    "text": "Mathematical Intuition\nWe throw random points ((x,y)) uniformly in the square ([-1,1]^2).\nThe fraction inside the unit circle (x^2 + y^2 ) equals (/4):\n[ . ]\n\n\n\nMath → Algorithm → Code Mapping\n\n\n\nMath idea\nR translation\n\n\n\n\nsample (x, y)\nrunif(N, -1, 1)\n\n\nindicator (I_i)\n(x^2 + y^2 &lt;= 1)\n\n\nestimate\n4 * mean(I)\n\n\n\n\n\n\nCode\n```{mermaid}\nflowchart TD\n  A([Start: choose N])\n  B[Sample N points (x,y) in [-1,1]^2]\n  C{x^2 + y^2 &lt;= 1?}\n  D[Count proportion inside]\n  E[pi_hat = 4 * proportion]\n  F([Return pi_hat])\n  A --&gt; B --&gt; C --&gt; D --&gt; E --&gt; F\n```\n\n\n\n\n\nflowchart TD\n  A([Start: choose N])\n  B[Sample N points (x,y) in [-1,1]^2]\n  C{x^2 + y^2 &lt;= 1?}\n  D[Count proportion inside]\n  E[pi_hat = 4 * proportion]\n  F([Return pi_hat])\n  A --&gt; B --&gt; C --&gt; D --&gt; E --&gt; F\n\n\n\n\n\n\n\n\n\nImplementation in R\n\n\nCode\n```{r}\nset.seed(0)\n\nestimate_pi &lt;- function(N) {\n  x &lt;- runif(N, -1, 1)\n  y &lt;- runif(N, -1, 1)\n  inside &lt;- (x^2 + y^2) &lt;= 1\n  4 * mean(inside)\n}\n\nestimate_pi(10000)\n```\n\n\n[1] 3.12\n\n\n\n\n\nVisualization\n\n\nCode\n```{r}\nset.seed(1)\nN &lt;- 10000\nx &lt;- runif(N, -1, 1)\ny &lt;- runif(N, -1, 1)\ninside &lt;- (x^2 + y^2) &lt;= 1\n\nplot(x[inside], y[inside], col='skyblue', pch=16, cex=0.5,\n     xlab='x', ylab='y', asp=1,\n     main='Monte Carlo π Approximation',\n     xlim=c(-1,1), ylim=c(-1,1))\npoints(x[!inside], y[!inside], col='gray', pch=16, cex=0.5)\nsymbols(0, 0, circles=1, inches=FALSE, add=TRUE, lwd=2)\n```\n\n\n\n\n\n\n\n\n\n\n\n\nReflection\nMonte Carlo estimation translates a probabilistic argument into a simulation-based computation.",
    "crumbs": [
      "Home",
      "Mathematics to R",
      "Monte Carlo Approximation of π — Translating Math into Code"
    ]
  },
  {
    "objectID": "Mathematics to Code/Mathematics to Code intro.html",
    "href": "Mathematics to Code/Mathematics to Code intro.html",
    "title": "Introduction",
    "section": "",
    "text": "“Mathematicians do not deal in objects, but in relations between objects; thus, they are free to replace some objects by others so lone as the relations remain unchanged. Content to them is irrelevant; they are interested in form only.”\n\nThis section goes through the process of transforming a mathematical problem into code. We will connect abstract ideas in mathematics to practical code, with focus on algorithmic thinking, problem decomposition, and structural clarity.\nSpecifically, the pages cover the following:\n\n\nIntuition\n\nAbstracting a problem into mathematics\nRe-writing a mathematics problem into code\n\nEuclidean Algorithm Example (Algebra Example)\nNewton-Raphson Method (Numerics and Analysis Example)\nMonte Carlo approximation of (Probability and Simulation Example)",
    "crumbs": [
      "Home",
      "Mathematics to R",
      "Introduction"
    ]
  },
  {
    "objectID": "Data Visualisation/timegraph.html",
    "href": "Data Visualisation/timegraph.html",
    "title": "multivariate time series",
    "section": "",
    "text": "Chapter 8 Time-dependent graphs\nA graph can be a powerful vehicle for displaying change over time. The most common time-dependent graph is the time series line graph. Other options include the dumbbell charts and the slope graph. 8.1 Time series\nA time series is a set of quantitative values obtained at successive time points. The intervals between time points (e.g., hours, days, weeks, months, or years) are usually equal.\nConsider the Economics time series that come with the ggplot2 package. It contains US monthly economic data collected from January 1967 thru January 2015. Let’s plot the personal savings rate (psavert) over time. We can do this with a simple line plot.\nlibrary(ggplot2) ggplot(economics, aes(x = date, y = psavert)) + geom_line() + labs(title = “Personal Savings Rate”, x = “Date”, y = “Personal Savings Rate”)\nSimple time series\nFigure 8.1: Simple time series\nThe scale_x_date function can be used to reformat dates (see Section 2.2.6). In the graph below, tick marks appear every 5 years and dates are presented in MMM-YY format. Additionally, the time series line is given an off-red color and made thicker, a nonparametric trend line (loess, Section 5.2.1.1) and titles are added, and the theme is simplified.\nlibrary(ggplot2) library(scales) ggplot(economics, aes(x = date, y = psavert)) + geom_line(color = “indianred3”, size=1 ) + geom_smooth() + scale_x_date(date_breaks = ‘5 years’, labels = date_format(“%b-%y”)) + labs(title = “Personal Savings Rate”, subtitle = “1967 to 2015”, x = ““, y =”Personal Savings Rate”) + theme_minimal()\nSimple time series with modified date axis\nFigure 8.2: Simple time series with modified date axis\nWhen plotting time series, be sure that the date variable is class Date and not class character. See Section 2.2.6 for details.\nLet’s close this section with a multivariate time series (more than one series). We’ll compare closing prices for Apple and Meta from Jan 1, 2018 to July 31, 2023. The getSymbols function in the quantmod package is used to obtain the stock data from Yahoo Finance.\n\nmultivariate time series\n\n\none time install\n\n\ninstall.packages(“quantmod”)\nlibrary(quantmod) library(dplyr)\n\n\nget apple (AAPL) closing prices\napple &lt;- getSymbols(“AAPL”, return.class = “data.frame”, from=“2023-01-01”)\napple &lt;- AAPL %&gt;% mutate(Date = as.Date(row.names(.))) %&gt;% select(Date, AAPL.Close) %&gt;% rename(Close = AAPL.Close) %&gt;% mutate(Company = “Apple”)\n\n\nget Meta (META) closing prices\nmeta &lt;- getSymbols(“META”, return.class = “data.frame”, from=“2023-01-01”)\nmeta &lt;- META %&gt;% mutate(Date = as.Date(row.names(.))) %&gt;% select(Date, META.Close) %&gt;% rename(Close = META.Close) %&gt;% mutate(Company = “Meta”)\n\n\ncombine data for both companies\nmseries &lt;- rbind(apple, meta)\n\n\nplot data\nlibrary(ggplot2) ggplot(mseries, aes(x=Date, y= Close, color=Company)) + geom_line(size=1) + scale_x_date(date_breaks = ‘1 month’, labels = scales::date_format(“%b”)) + scale_y_continuous(limits = c(120, 280), breaks = seq(120, 280, 20), labels = scales::dollar) + labs(title = “NASDAQ Closing Prices”, subtitle = “Jan - June 2023”, caption = “source: Yahoo Finance”, y = “Closing Price”) + theme_minimal() + scale_color_brewer(palette = “Dark2”)\nMultivariate time series\nFigure 8.3: Multivariate time series\nYou can see the how the two stocks diverge after February. 8.2 Dummbbell charts\nDumbbell charts are useful for displaying change between two time points for several groups or observations. The geom_dumbbell function from the ggalt package is used.\nUsing the gapminder dataset let’s plot the change in life expectancy from 1952 to 2007 in the Americas. The dataset is in long format (Section 2.2.7). We will need to convert it to wide format in order to create the dumbbell plot\nlibrary(ggalt) library(tidyr) library(dplyr)\n\n\nload data\ndata(gapminder, package = “gapminder”)\n\n\nsubset data\nplotdata_long &lt;- filter(gapminder, continent == “Americas” & year %in% c(1952, 2007)) %&gt;% select(country, year, lifeExp)\n\n\nconvert data to wide format\nplotdata_wide &lt;- pivot_wider(plotdata_long, names_from = year, values_from = lifeExp) names(plotdata_wide) &lt;- c(“country”, “y1952”, “y2007”)\n\n\ncreate dumbbell plot\nggplot(plotdata_wide, aes(y = country, x = y1952, xend = y2007)) +\ngeom_dumbbell()\nSimple dumbbell chart\nFigure 8.4: Simple dumbbell chart\nThe graph will be easier to read if the countries are sorted and the points are sized and colored. In the next graph, we’ll sort by 1952 life expectancy, and modify the line and point size, color the points, add titles and labels, and simplify the theme.\n\n\ncreate dumbbell plot\nggplot(plotdata_wide, aes(y = reorder(country, y1952), x = y1952, xend = y2007)) +\ngeom_dumbbell(size = 1.2, size_x = 3, size_xend = 3, colour = “grey”, colour_x = “red”, colour_xend = “blue”) + theme_minimal() + labs(title = “Change in Life Expectancy”, subtitle = “1952 to 2007”, x = “Life Expectancy (years)”, y = ““)\nSorted, colored dumbbell chart\nFigure 8.5: Sorted, colored dumbbell chart\nIt is easier to discern patterns here. For example Haiti started with the lowest life expectancy in 1952 and still has the lowest in 2007. Paraguay started relatively high by has made few gains. 8.3 Slope graphs\nWhen there are several groups and several time points, a slope graph can be helpful. Let’s plot life expectancy for six Central American countries in 1992, 1997, 2002, and 2007. Again we’ll use the gapminder data.\nTo create a slope graph, we’ll use the newggslopegraph function from the CGPfunctions package.\nThe newggslopegraph function parameters are (in order)\ndata frame\ntime variable (which must be a factor)\nnumeric variable to be plotted\nand grouping variable (creating one line per group).\nlibrary(CGPfunctions)\n\n\nSelect Central American countries data\n\n\nfor 1992, 1997, 2002, and 2007\ndf &lt;- gapminder %&gt;% filter(year %in% c(1992, 1997, 2002, 2007) & country %in% c(“Panama”, “Costa Rica”, “Nicaragua”, “Honduras”, “El Salvador”, “Guatemala”, “Belize”)) %&gt;% mutate(year = factor(year), lifeExp = round(lifeExp))\n\n\ncreate slope graph\nnewggslopegraph(df, year, lifeExp, country) + labs(title=“Life Expectancy by Country”, subtitle=“Central America”, caption=“source: gapminder”)\nSlope graph\nFigure 8.6: Slope graph\nIn the graph above, Costa Rica has the highest life expectancy across the range of years studied. Guatemala has the lowest, and caught up with Honduras (also low at 69) in 2002. 8.4 Area Charts\nA simple area chart is basically a line graph, with a fill from the line to the x-axis.\n\n\nbasic area chart\nggplot(economics, aes(x = date, y = psavert)) + geom_area(fill=“lightblue”, color=“black”) + labs(title = “Personal Savings Rate”, x = “Date”, y = “Personal Savings Rate”)\nBasic area chart\nFigure 8.7: Basic area chart\nA stacked area chart can be used to show differences between groups over time. Consider the uspopage dataset from the gcookbook package. The dataset describes the age distribution of the US population from 1900 to 2002. The variables are year, age group (AgeGroup), and number of people in thousands (Thousands). Let’s plot the population of each age group over time.\n\n\nstacked area chart\ndata(uspopage, package = “gcookbook”) ggplot(uspopage, aes(x = Year, y = Thousands, fill = AgeGroup)) + geom_area() + labs(title = “US Population by age”, x = “Year”, y = “Population in Thousands”)\nStacked area chart\nFigure 8.8: Stacked area chart\nIt is best to avoid scientific notation in your graphs. How likely is it that the average reader will know that 3e+05 means 300,000,000? It is easy to change the scale in ggplot2. Simply divide the Thousands variable by 1000 and report it as Millions. While we are at it, let’s\ncreate black borders to highlight the difference between groups\nreverse the order the groups to match increasing age\nimprove labeling\nchoose a different color scheme\nchoose a simpler theme.\nThe levels of the AgeGroup variable can be reversed using the fct_rev function in the forcats package.\n\n\nstacked area chart\ndata(uspopage, package = “gcookbook”) ggplot(uspopage, aes(x = Year, y = Thousands/1000, fill = forcats::fct_rev(AgeGroup))) + geom_area(color = “black”) + labs(title = “US Population by age”, subtitle = “1900 to 2002”, caption = “source: U.S. Census Bureau, 2003, HS-3”, x = “Year”, y = “Population in Millions”, fill = “Age Group”) + scale_fill_brewer(palette = “Set2”) + theme_minimal()\nStacked area chart with simpler scale\nFigure 8.9: Stacked area chart with simpler scale\nApparently, the number of young children have not changed very much in the past 100 years.\nStacked area charts are most useful when interest is on both (1) group change over time and (2) overall change over time. Place the most important groups at the bottom. These are the easiest to interpret in this type of plot. 8.5 Stream graph\nStream graphs (Byron and Wattenberg 2008) are basically a variation on the stacked area chart. In a stream graph, the data is typically centered at each x-value around a mid-point and mirrored above and below that point. This is easiest to see in an example.\nLet’s plot the previous stacked area chart (Figure 8.9) as a stream graph.\n\n\nbasic stream graph\ndata(uspopage, package = “gcookbook”) library(ggstream) ggplot(uspopage, aes(x = Year, y = Thousands/1000, fill = forcats::fct_rev(AgeGroup))) + geom_stream() + labs(title = “US Population by age”, subtitle = “1900 to 2002”, caption = “source: U.S. Census Bureau, 2003, HS-3”, x = “Year”, y = ““, fill =”Age Group”) + scale_fill_brewer(palette = “Set2”) + theme_minimal() + theme(panel.grid.major.y = element_blank(), panel.grid.minor.y = element_blank(), axis.text.y = element_blank())\nBasic stream graph\nFigure 8.10: Basic stream graph\nThe theme function is used to surpress the y-axis, whose values are not easily interpreted. To interpret this graph, look at each value on the x-axis and compare the relative vertical heights of each group. You can see, for example, that the relative proportion of older people has increased significantly.\nAn interesting variation is the proportional steam graph displays in Figure 8.11\n\n\nbasic stream graph\ndata(uspopage, package = “gcookbook”) library(ggstream) ggplot(uspopage, aes(x = Year, y = Thousands/1000, fill = forcats::fct_rev(AgeGroup))) + geom_stream(type=“proportional”) + labs(title = “US Population by age”, subtitle = “1900 to 2002”, caption = “source: U.S. Census Bureau, 2003, HS-3”, x = “Year”, y = “Proportion”, fill = “Age Group”) + scale_fill_brewer(palette = “Set2”) + theme_minimal()\nProportional stream graph\nFigure 8.11: Proportional stream graph\nThis is similar to the filled bar chart (Section 5.1.3) and makes it easier to see the relative change in values by group across time."
  },
  {
    "objectID": "Data Visualisation/multivar.html",
    "href": "Data Visualisation/multivar.html",
    "title": "plot experience vs. salary",
    "section": "",
    "text": "Chapter 6 Multivariate Graphs\nIn the last two chapters, you looked at ways to display the distribution of a single variable, or the relationship between two variables. We are usually interested in understanding the relations among several variables. Multivariate graphs display the relationships among three or more variables. There are two common methods for accommodating multiple variables: grouping and faceting. 6.1 Grouping\nIn grouping, the values of the first two variables are mapped to the x and y axes. Then additional variables are mapped to other visual characteristics such as color, shape, size, line type, and transparency. Grouping allows you to plot the data for multiple groups in a single graph.\nUsing the Salaries dataset, let’s display the relationship between yrs.since.phd and salary.\nlibrary(ggplot2) data(Salaries, package=“carData”)\n\nplot experience vs. salary\nggplot(Salaries, aes(x = yrs.since.phd, y = salary)) + geom_point() + labs(title = “Academic salary by years since degree”)\nSimple scatterplot\nFigure 6.1: Simple scatterplot\nNext, let’s include the rank of the professor, using color.\n\n\nplot experience vs. salary (color represents rank)\nggplot(Salaries, aes(x = yrs.since.phd, y = salary, color=rank)) + geom_point() + labs(title = “Academic salary by rank and years since degree”)\nScatterplot with color mapping\nFigure 6.2: Scatterplot with color mapping\nFinally, let’s add the gender of professor, using shape of the points to indicate sex. We’ll increase the point size and transparency to make the individual points clearer.\n\n\nplot experience vs. salary\n\n\n(color represents rank, shape represents sex)\nggplot(Salaries, aes(x = yrs.since.phd, y = salary, color = rank, shape = sex)) + geom_point(size = 3, alpha = .6) + labs(title = “Academic salary by rank, sex, and years since degree”)\nScatterplot with color and shape mapping\nFigure 6.3: Scatterplot with color and shape mapping\nNotice the difference between specifying a constant value (such as size = 3) and a mapping of a variable to a visual characteristic (e.g., color = rank). Mappings are always placed within the aes function, while the assignment of a constant value always appear outside of the aes function.\nHere is another example. We’ll graph the relationship between years since Ph.D. and salary using the size of the points to indicate years of service. This is called a bubble plot.\nlibrary(ggplot2) data(Salaries, package=“carData”)\n\n\nplot experience vs. salary\n\n\n(color represents rank and size represents service)\nggplot(Salaries, aes(x = yrs.since.phd, y = salary, color = rank, size = yrs.service)) + geom_point(alpha = .6) + labs(title = paste0(“Academic salary by rank, years of service,”, “and years since degree”))\nScatterplot with size and color mapping\nFigure 6.4: Scatterplot with size and color mapping\nBubble plots are described in more detail in a later chapter.\nAs a final example, let’s look at the yrs.since.phd vs salary and add sex using color and quadratic best fit lines.\n\n\nplot experience vs. salary with\n\n\nfit lines (color represents sex)\nggplot(Salaries, aes(x = yrs.since.phd, y = salary, color = sex)) + geom_point(alpha = .4, size=3) + geom_smooth(se=FALSE, method=“lm”, formula=y~poly(x,2), size = 1.5) + labs(x = “Years Since Ph.D.”, title = “Academic Salary by Sex and Years Experience”, subtitle = “9-month salary for 2008-2009”, y = ““, color =”Sex”) + scale_y_continuous(label = scales::dollar) + scale_color_brewer(palette=“Set1”) + theme_minimal()\nScatterplot with color mapping and quadratic fit lines\nFigure 6.5: Scatterplot with color mapping and quadratic fit lines 6.2 Faceting\nGrouping allows you to plot multiple variables in a single graph, using visual characteristics such as color, shape, and size. In faceting, a graph consists of several separate plots or small multiples, one for each level of a third variable, or combination of two variables. It is easiest to understand this with an example.\n\n\nplot salary histograms by rank\nggplot(Salaries, aes(x = salary)) + geom_histogram() + facet_wrap(~rank, ncol = 1) + labs(title = “Salary histograms by rank”)\nSalary distribution by rank\nFigure 6.6: Salary distribution by rank\nThe facet_wrap function creates a separate graph for each level of rank. The ncol option controls the number of columns.\nIn the next example, two variables are used to define the facets.\n\n\nplot salary histograms by rank and sex\nggplot(Salaries, aes(x = salary/1000)) + geom_histogram() + facet_grid(sex ~ rank) + labs(title = “Salary histograms by sex and rank”, x = “Salary ($1000)”)\nSalary distribution by rank and sex\nFigure 6.7: Salary distribution by rank and sex\nHere, the facet_grid function defines the rows (sex) and columns (rank) that separate the data into 6 plots in one graph.\nWe can also combine grouping and faceting.\n\n\nplot salary by years of experience by sex and discipline\nggplot(Salaries, aes(x=yrs.since.phd, y = salary, color=sex)) + geom_point() + geom_smooth(method=“lm”, se=FALSE) + facet_wrap(~discipline, ncol = 1)\nSalary by experience, rank, and sex\nFigure 6.8: Salary by experience, rank, and sex\nLet’s make this last plot more attractive.\n\n\nplot salary by years of experience by sex and discipline\nggplot(Salaries, aes(x=yrs.since.phd, y = salary, color=sex)) + geom_point(size = 2, alpha=.5) + geom_smooth(method=“lm”, se=FALSE, size = 1.5) + facet_wrap(~factor(discipline, labels = c(“Theoretical”, “Applied”)), ncol = 1) + scale_y_continuous(labels = scales::dollar) + theme_minimal() + scale_color_brewer(palette=“Set1”) + labs(title = paste0(“Relationship of salary and years”, “since degree by sex and discipline”), subtitle = “9-month salary for 2008-2009”, color = “Gender”, x = “Years since Ph.D.”, y = “Academic Salary”)\nSalary by experience, rank, and sex (better labeled)\nFigure 6.9: Salary by experience, rank, and sex (better labeled)\nSee the Customizing section to learn more about customizing the appearance of a graph.\nAs a final example, we’ll shift to a new dataset and plot the change in life expectancy over time for countries in the “Americas”. The data comes from the gapminder dataset in the gapminder package. Each country appears in its own facet. The theme functions are used to simplify the background color, rotate the x-axis text, and make the font size smaller.\n\n\nplot life expectancy by year separately\n\n\nfor each country in the Americas\ndata(gapminder, package = “gapminder”)\n\n\nSelect the Americas data\nplotdata &lt;- dplyr::filter(gapminder, continent == “Americas”)\n\n\nplot life expectancy by year, for each country\nggplot(plotdata, aes(x=year, y = lifeExp)) + geom_line(color=“grey”) + geom_point(color=“blue”) + facet_wrap(~country) + theme_minimal(base_size = 9) + theme(axis.text.x = element_text(angle = 45, hjust = 1)) + labs(title = “Changes in Life Expectancy”, x = “Year”, y = “Life Expectancy”)\nChanges in life expectancy by country\nFigure 6.10: Changes in life expectancy by country\nWe can see that life expectancy is increasing in each country, but that Haiti is lagging behind.\nCombining grouping and faceting with graphs for one (Chapter 4) or two (Chapter 5) variables allows you to create a wide range of visualizations for exploring data! You are limited only by your imagination and the over-riding goal of communicating information clearly."
  },
  {
    "objectID": "Data Visualisation/introvisualisation.html",
    "href": "Data Visualisation/introvisualisation.html",
    "title": "Warwick Statistics Society R Course 2024-2025",
    "section": "",
    "text": "“The greatest value of a picture is when it forces us to notice what we never expected to see.” – John W. Tukey https://rkabacoff.github.io/datavis/index.html",
    "crumbs": [
      "Home",
      "Data Visualisation",
      "introvisualisation.html"
    ]
  },
  {
    "objectID": "Data Visualisation/othergraphs.html",
    "href": "Data Visualisation/othergraphs.html",
    "title": "Specialized Visualization Techniques",
    "section": "",
    "text": "This chapter covers specialized visualization techniques that don’t fit neatly into other categories but are incredibly useful for specific types of data and questions. Think of these as tools for your “advanced visualization toolkit”—you won’t use them every day, but when you need them, they’re perfect for the job.\nWe’ll explore: - Visualizing three-dimensional relationships - Displaying flows and transitions - Creating comparison matrices - Specialized chart types for specific purposes\nLet’s load our packages:\n\n\nWarning: package 'ggplot2' was built under R version 4.4.3\n\n\nWarning: package 'palmerpenguins' was built under R version 4.4.3\n\n\nWarning: package 'dplyr' was built under R version 4.4.3"
  },
  {
    "objectID": "Data Visualisation/othergraphs.html#a-tibble-6-4",
    "href": "Data Visualisation/othergraphs.html#a-tibble-6-4",
    "title": "basic 3-D scatterplot",
    "section": "# A tibble: 6 × 4",
    "text": "# A tibble: 6 × 4"
  },
  {
    "objectID": "Data Visualisation/othergraphs.html#groups-class-sex-survived-6",
    "href": "Data Visualisation/othergraphs.html#groups-class-sex-survived-6",
    "title": "basic 3-D scatterplot",
    "section": "# Groups: Class, Sex, Survived [6]",
    "text": "# Groups: Class, Sex, Survived [6]"
  },
  {
    "objectID": "Data Visualisation/othergraphs.html#class-sex-survived-n",
    "href": "Data Visualisation/othergraphs.html#class-sex-survived-n",
    "title": "basic 3-D scatterplot",
    "section": "Class Sex Survived n",
    "text": "Class Sex Survived n"
  },
  {
    "objectID": "Data Visualisation/othergraphs.html#st-female-no-4",
    "href": "Data Visualisation/othergraphs.html#st-female-no-4",
    "title": "basic 3-D scatterplot",
    "section": "1 1st Female No 4",
    "text": "1 1st Female No 4"
  },
  {
    "objectID": "Data Visualisation/othergraphs.html#st-female-yes-141",
    "href": "Data Visualisation/othergraphs.html#st-female-yes-141",
    "title": "basic 3-D scatterplot",
    "section": "2 1st Female Yes 141",
    "text": "2 1st Female Yes 141"
  },
  {
    "objectID": "Data Visualisation/othergraphs.html#st-male-no-118",
    "href": "Data Visualisation/othergraphs.html#st-male-no-118",
    "title": "basic 3-D scatterplot",
    "section": "3 1st Male No 118",
    "text": "3 1st Male No 118"
  },
  {
    "objectID": "Data Visualisation/othergraphs.html#st-male-yes-62",
    "href": "Data Visualisation/othergraphs.html#st-male-yes-62",
    "title": "basic 3-D scatterplot",
    "section": "4 1st Male Yes 62",
    "text": "4 1st Male Yes 62"
  },
  {
    "objectID": "Data Visualisation/othergraphs.html#nd-female-no-13",
    "href": "Data Visualisation/othergraphs.html#nd-female-no-13",
    "title": "basic 3-D scatterplot",
    "section": "5 2nd Female No 13",
    "text": "5 2nd Female No 13"
  },
  {
    "objectID": "Data Visualisation/othergraphs.html#nd-female-yes-93",
    "href": "Data Visualisation/othergraphs.html#nd-female-yes-93",
    "title": "basic 3-D scatterplot",
    "section": "6 2nd Female Yes 93",
    "text": "6 2nd Female Yes 93\nNext create an alluvial diagram in ggplot2 using the ggplot, geom_alluvium and geom_stratum functions. The categorical variables are mapped to axes and n to y. This will produce Figure 10.10\nlibrary(ggalluvial) ggplot(titanic_table, aes(axis1 = Class, axis2 = Sex, axis3 = Survived, y = n)) + geom_alluvium(aes(fill = Class)) + geom_stratum() + geom_text(stat = “stratum”, aes(label = after_stat(stratum)))\nBasic alluvial diagram\nFigure 10.10: Basic alluvial diagram\nTo interpret the graph, start with the variable on the left (Class) and follow the flow to the right. The height of the category level represent the proportion of observations in that level. For example the crew made up roughly 40% of the passengers. Roughly, 30% of passengers survived.\nThe height of the flow represents the proportion of observations contained in the two variable levels they connect. About 50% of first class passengers were females and all female first class passengers survived. The crew was overwhelmingly male and roughly 75% of this group perished.\nAs a second example, let’s look at the relationship between the number carburetors, cylinders, gears, and the transmission type (manual or automatic) for the 32 cars in the mtcars dataset. We’ll treat each variable as categorical.\nFirst, we need to prepare the data.\nlibrary(dplyr) data(mtcars) mtcars_table &lt;- mtcars %&gt;% mutate(am = factor(am, labels = c(“Auto”, “Man”)), cyl = factor(cyl), gear = factor(gear), carb = factor(carb)) %&gt;% group_by(cyl, gear, carb, am) %&gt;% count()\nhead(mtcars_table)"
  },
  {
    "objectID": "Data Visualisation/othergraphs.html#a-tibble-6-5",
    "href": "Data Visualisation/othergraphs.html#a-tibble-6-5",
    "title": "basic 3-D scatterplot",
    "section": "# A tibble: 6 × 5",
    "text": "# A tibble: 6 × 5"
  },
  {
    "objectID": "Data Visualisation/othergraphs.html#groups-cyl-gear-carb-am-6",
    "href": "Data Visualisation/othergraphs.html#groups-cyl-gear-carb-am-6",
    "title": "basic 3-D scatterplot",
    "section": "# Groups: cyl, gear, carb, am [6]",
    "text": "# Groups: cyl, gear, carb, am [6]"
  },
  {
    "objectID": "Data Visualisation/othergraphs.html#cyl-gear-carb-am-n",
    "href": "Data Visualisation/othergraphs.html#cyl-gear-carb-am-n",
    "title": "basic 3-D scatterplot",
    "section": "cyl gear carb am n",
    "text": "cyl gear carb am n"
  },
  {
    "objectID": "Data Visualisation/othergraphs.html#auto-1",
    "href": "Data Visualisation/othergraphs.html#auto-1",
    "title": "basic 3-D scatterplot",
    "section": "1 4 3 1 Auto 1",
    "text": "1 4 3 1 Auto 1"
  },
  {
    "objectID": "Data Visualisation/othergraphs.html#man-4",
    "href": "Data Visualisation/othergraphs.html#man-4",
    "title": "basic 3-D scatterplot",
    "section": "2 4 4 1 Man 4",
    "text": "2 4 4 1 Man 4"
  },
  {
    "objectID": "Data Visualisation/othergraphs.html#auto-2",
    "href": "Data Visualisation/othergraphs.html#auto-2",
    "title": "basic 3-D scatterplot",
    "section": "3 4 4 2 Auto 2",
    "text": "3 4 4 2 Auto 2"
  },
  {
    "objectID": "Data Visualisation/othergraphs.html#man-2",
    "href": "Data Visualisation/othergraphs.html#man-2",
    "title": "basic 3-D scatterplot",
    "section": "4 4 4 2 Man 2",
    "text": "4 4 4 2 Man 2"
  },
  {
    "objectID": "Data Visualisation/othergraphs.html#man-2-1",
    "href": "Data Visualisation/othergraphs.html#man-2-1",
    "title": "basic 3-D scatterplot",
    "section": "5 4 5 2 Man 2",
    "text": "5 4 5 2 Man 2"
  },
  {
    "objectID": "Data Visualisation/othergraphs.html#auto-2-1",
    "href": "Data Visualisation/othergraphs.html#auto-2-1",
    "title": "basic 3-D scatterplot",
    "section": "6 6 3 1 Auto 2",
    "text": "6 6 3 1 Auto 2\nNext create the graph. Several options and functions are added to enhance the results. Specifically,\nthe flow borders are set to black (geom_alluvium)\nthe strata are given transparency (geom_strata)\nthe strata are labeled and made wider (scale_x_discrete)\ntitles are added (labs)\nthe theme is simplified (theme_minimal)\nand the legend is suppressed (theme)\nggplot(mtcars_table, aes(axis1 = carb, axis2 = cyl, axis3 = gear, axis4 = am, y = n)) + geom_alluvium(aes(fill = carb), color=“black”) + geom_stratum(alpha=.8) + geom_text(stat = “stratum”, aes(label = after_stat(stratum))) + scale_x_discrete(limits = c(“Carburetors”, “Cylinders”, “Gears”, “Transmission”), expand = c(.1, .1)) + # scale_fill_brewer(palette=“Paired”) + labs(title = “Mtcars data”, subtitle = “stratified by carb, cyl, gear, and am”, y = “Frequency”) + theme_minimal() + theme(legend.position = “none”)\nBasic alluvial diagram for the mtcars dataset\nFigure 10.11: Basic alluvial diagram for the mtcars dataset\nI think that these changes make the graph easier to follow. For example, all 8 carburetor cars have 8 cylinders, 5 gears, and a manual transmission. Most 4 carburetor cars have 8 cylinders, 3 gears, and an automatic transmission.\nSee the ggalluvial website (https://github.com/corybrunson/ggalluvial) for additional details. 10.5 Heatmaps\nA heatmap displays a set of data using colored tiles for each variable value within each observation. There are many varieties of heatmaps. Although base R comes with a heatmap function, we’ll use the more powerful superheat package (I love these names).\nFirst, let’s create a heatmap for the mtcars dataset that come with base R. The mtcars dataset contains information on 32 cars measured on 11 variables."
  },
  {
    "objectID": "Data Visualisation/othergraphs.html#a-tibble-3-6",
    "href": "Data Visualisation/othergraphs.html#a-tibble-3-6",
    "title": "basic 3-D scatterplot",
    "section": "# A tibble: 3 × 6",
    "text": "# A tibble: 3 × 6"
  },
  {
    "objectID": "Data Visualisation/othergraphs.html#group-sleep_total-sleep_rem-sleep_cycle-brainwt-bodywt",
    "href": "Data Visualisation/othergraphs.html#group-sleep_total-sleep_rem-sleep_cycle-brainwt-bodywt",
    "title": "basic 3-D scatterplot",
    "section": "group sleep_total sleep_rem sleep_cycle brainwt bodywt",
    "text": "group sleep_total sleep_rem sleep_cycle brainwt bodywt"
  },
  {
    "objectID": "Data Visualisation/othergraphs.html#cow-0-0-1-1-1",
    "href": "Data Visualisation/othergraphs.html#cow-0-0-1-1-1",
    "title": "basic 3-D scatterplot",
    "section": "1 Cow 0 0 1 1 1",
    "text": "1 Cow 0 0 1 1 1"
  },
  {
    "objectID": "Data Visualisation/othergraphs.html#dog-1-1-0-0-0",
    "href": "Data Visualisation/othergraphs.html#dog-1-1-0-0-0",
    "title": "basic 3-D scatterplot",
    "section": "2 Dog 1 1 0 0 0",
    "text": "2 Dog 1 1 0 0 0"
  },
  {
    "objectID": "Data Visualisation/othergraphs.html#pig-0.836-0.773-0.5-0.312-0.123",
    "href": "Data Visualisation/othergraphs.html#pig-0.836-0.773-0.5-0.312-0.123",
    "title": "basic 3-D scatterplot",
    "section": "3 Pig 0.836 0.773 0.5 0.312 0.123",
    "text": "3 Pig 0.836 0.773 0.5 0.312 0.123"
  },
  {
    "objectID": "Data Visualisation/univariate.html",
    "href": "Data Visualisation/univariate.html",
    "title": "simple bar chart",
    "section": "",
    "text": "Chapter 4 Univariate Graphs\nThe first step in any comprehensive data analysis is to explore each import variable in turn. Univariate graphs plot the distribution of data from a single variable. The variable can be categorical (e.g., race, sex, political affiliation) or quantitative (e.g., age, weight, income).\nThe dataset Marriage contains the marriage records of 98 individuals in Mobile County, Alabama (see Appendix A.5). We’ll explore the distribution of three variables from this dataset - the age and race of the wedding participants, and the occupation of the wedding officials. 4.1 Categorical\nThe race of the participants and the occupation of the officials are both categorical variables.The distribution of a single categorical variable is typically plotted with a bar chart, a pie chart, or (less commonly) a tree map or waffle chart. 4.1.1 Bar chart\nIn Figure 4.1, a bar chart is used to display the distribution of wedding participants by race."
  },
  {
    "objectID": "Data Visualisation/univariate.html#section",
    "href": "Data Visualisation/univariate.html#section",
    "title": "simple bar chart",
    "section": "[1] 5.181946",
    "text": "[1] 5.181946"
  },
  {
    "objectID": "Mathematics to Code/Mathematics to Code Euclidean Example.html",
    "href": "Mathematics to Code/Mathematics to Code Euclidean Example.html",
    "title": "Euclidean Algorithm — Translating Math into Code",
    "section": "",
    "text": "Mathematical Intuition\nRecall from Sets and Numbers the Euclidean algorithm where we want to find the greatest common divisor (GCD) of two integers (a, b):\nThe algorithmic idea: repeatedly replace the pair (a, b) with (b, a modb) until the second number becomes 0. Let us now look at a simplified flowchart of what we want our computer program to do.\nQUESTION FOR THE READER: TRY TO DRAW THE FLOWCHART ON YOUR OWN!\n\n\n\nMath → Algorithm → Code Mapping\n\n\n\nMath operation\nR equivalent\nMeaning\n\n\n\n\n(a modb)\na %% b\nremainder\n\n\nrecursive call\ngcd(b, a %% b)\nrepeat step\n\n\nstop if (b = 0)\nif (b == 0)\nbase case\n\n\n\n\n\n\n\n\n\nflowchart TD\n  A([Start: a, b])\n  B{Is b equal to 0?}\n  C[Set a to b&lt;br/&gt;Set b to a mod b]\n  D([Return absolute value of a])\n\n  A --&gt; B\n  B -- No --&gt; C --&gt; B\n  B -- Yes --&gt; D\n\n\n\n\n\n\n\n\n\n\nImplementation in R\n\n\nCode\n```{r}\n# Define the GCD function\ngcd_iterative &lt;- function(a, b) {\n  a &lt;- abs(as.integer(a))\n  b &lt;- abs(as.integer(b))\n  while (b != 0) {\n    r &lt;- a %% b\n    a &lt;- b\n    b &lt;- r\n  }\n  return(a)\n}\n\n# Set up the recursive part of the function\ngcd_recursive &lt;- function(a, b) {\n  a &lt;- abs(as.integer(a))\n  b &lt;- abs(as.integer(b))\n  if (b == 0) return(a)\n  gcd_recursive(b, a %% b)\n}\n```\n\n\n\n\n\nExample usage\n\n\nCode\n```{r}\ngcd_iterative(1071, 462)\n```\n\n\n[1] 21\n\n\nIn this example, we can see how we can break down algebraic reasoning (these are the skills proofs of theorems and lemmas give you!) into their basic building blocks and then express them as a loop or recursive function as you would do on paper! We have successfully turned a symbolic rule into a computational process! Now it is your turn, try to implement any algorithm of your choosing and see if you can get it to work!",
    "crumbs": [
      "Home",
      "Mathematics to R",
      "Euclidean Algorithm — Translating Math into Code"
    ]
  },
  {
    "objectID": "Mathematics to Code/Mathematics to Code intuit.html",
    "href": "Mathematics to Code/Mathematics to Code intuit.html",
    "title": "Mathematical intuition behind coding",
    "section": "",
    "text": "Imagine you’re trying to explain a puzzle to a robot. Robots don’t guess or assume, they only understand exact instructions. That’s what programming is: explaining a math idea to a robot so it can follow it step by step. If your instructions are fuzzy, the robot gets confused, just like someone trying to make a cake with missing steps!",
    "crumbs": [
      "Home",
      "Mathematics to R",
      "Mathematical intuition behind coding"
    ]
  },
  {
    "objectID": "Mathematics to Code/Mathematics to Code intuit.html#why-mathematics-makes-you-a-better-programmer",
    "href": "Mathematics to Code/Mathematics to Code intuit.html#why-mathematics-makes-you-a-better-programmer",
    "title": "Mathematical intuition behind coding",
    "section": "Why Mathematics Makes You a Better Programmer",
    "text": "Why Mathematics Makes You a Better Programmer\nMathematics trains you to: Define problems precisely through rigourous proofs (NOTHING is assumed unless stated) - Work with abstract structures (ideas of groups, rings, fields in algebra) - Think algorithmically (the many algorithms you will come across e.g. Euclidean, Gram-Schmidt) - Break complex problems into parts (this is essentially what you do during a proof!) - Understand edge cases and generalization (this is also a skill gained in proofs!)\n\n\n\n\n\n\nMath to Code Mindset\n\n\n\nWhen approaching a coding task, ask yourself: - What is the input? - What transformation is required? - What is the output? - Can I represent it mathematically?\n\n\n\n\n\n\n\n\nImportant\n\n\n\nYour code is exectued by a machine. Machines do not guess or assume, they only understand exact instructions. Therefore, keep in mind to specify your code.\n\n\n\n\n\n\n\ngraph TD\n    A[Start with a Problem] --&gt; B[Translate into Math Language]\n    B --&gt; C[Define Inputs and Outputs]\n    C --&gt; D[Design Algorithm (Steps)]\n    D --&gt; E[Write Code]\n    E --&gt; F[Test and Validate]\n    F --&gt; G[Refactor or Extend]",
    "crumbs": [
      "Home",
      "Mathematics to R",
      "Mathematical intuition behind coding"
    ]
  },
  {
    "objectID": "Report Writing/structurereport.html",
    "href": "Report Writing/structurereport.html",
    "title": "Examples of Mathematics translated into code",
    "section": "",
    "text": "There are many ways to structure a report, some better than others. If you are new to report writing, especially in the field of statistics, I will provide a very basic, but versatile structure to help you in your first steps. The report is made up of several components, listed below in the order in which they should appear. Longer reports, such as the final assignments in both ST117 and ST231, are better split into sections, while shorter reports, like the ST231 assignments, to not really require as full a structure as suggested. In any case, you must avoid a narrative approach like: “First I did this, then that, etc.”. This makes the report difficult to follow; in this case, showing is much more effective than telling.\n\n\nEvery report needs a title, preferably on a separate title page, which should also include the author’s name and department or other affiliation, and the date. The title should be short and informative. In general, this much detail won’t be required and it is most likely that your lecturers will have a template with an appropriate title ready.\nA brief summary – the shorter the better, and certainly no more than half a page – should follow, to tell the reader what the report is about, in general terms, and why it may be worth reading. A good abstract is solely a skeleton outline of (a) the problem, (b) what you have done, (c) your conclusions. It should not, if possible, use numbers, symbols or technical terms. Again, this is not required to be as detailed, nut as you move higher up on the academic and corporate ladder, titles and abstracts will play a larger role in gauging interest in your work, so keep this in mind.\nHere is an example of a title and an abstract:\nTitle: Statistical methods for healthcare regulation: rating, screening and surveillance\nAuthor(s): David Spiegelhalter, Christopher Sherlaw-Johnson, Martin Bardsley, Ian Blunt, Christopher Wood, Olivia Grigg\nAffiliation: Medical Research Council Biostatistics Unit, Cambridge, and related institutions\nDate: First published 21 November 2011 Wiley Online Library\nAbstract (as published):\nCurrent demand for accountability and efficiency of healthcare organizations, combined with the greater availability of routine data on clinical care and outcomes, has led to an increased focus on statistical methods in healthcare regulation. We consider three different regulatory functions in which statistical analysis plays a vital role: rating organizations, deciding whom to inspect and continuous surveillance for arising problems. A common approach to data standardization based on (possibly overdispersed) Z-scores is proposed, although specific tools are used for assessing performance against a target, combining indicators when screening for inspection, and continuous monitoring using risk-adjusted sequential testing procedures. We pay particular attention to the problem of simultaneously monitoring over 200 000 indicators for excess mortality, both with respect to the statistical issues surrounding massive multiplicity, and the organizational aspects of dealing with such a complex but high-profile process.\nNotice that the authors: \n\nKeep under half a page.\n\nAvoid numbers or statistical symbols.\n\nDo not interpret results in depth here — just state the what, how, and conclusion.\n\n\n\n3.3 Introduction This should describe the general context and background, including a general description of what data are available, the manner in which and the purpose for which they were collected. It should also provide the aims of the investigation, together with some indication of the methods used. It may well be an expanded version of the summary, and in general should not exceed two pages in length. 3.4 Methods These should now be described in a fair amount of detail, including any theory that is necessary. How much detail is always difficult to decide. Aim to write as though for someone of comparable standing, e.g. a student in the same year as yourself, who does not know anything in detail about the subject of the re- port. The reader should be able to repeat the study on the basis of your report. Don’t be afraid of putting very detailed and long descriptions into one or more appendices. This component may well have to be split into sections, e.g. 3 1. a preliminary analysis, using graphical and simple descriptive methods, 2. a full-scale analysis. The second section may further have to be split into two subsections e.g. (a) a description, explanation or development of the methodology to be used, (b) the actual analysis. Subsection (a) will probably need to be quite technical, certainly more technical than the rest of the report. It should describe in detail the precise mathemat- ical/statistical tools and techniques to be used and reveal the manner in which they lead to the desired results. Do not shy away from using mathematical no- tation (get well familiar with the capabilities of your word-processor to produce mathematical expressions) but be careful to define every bit of the notation you use. A mathematical expression is totally meaningless if any of the symbols used in it is undefined. Similarly pages of mathematical development and explanations are rendered useless and total waste of space if any of the symbols involved in these explanations are not defined. I In the subsection containing the actual analysis it is important that you de- scribe your analysis sufficiently clearly and carefully to enable it to be reproduced by the reader. 3.5 Results, conclusions and recommendations Give the main results and conclusions. Subsidiary results and deductions can be left in this section if they do not detract from the flow of the presentation of the main results and conclusion; otherwise they may be gathered into a separate component, be combined with the description of methods, or be put into an appendix. Your conclusions should be expressed in a way that can be understood by a non-statistician and should make sense even if the reader of your report had omitted to read the middle section on detailed statistical analysis. Try to report your conclusion in the context of the experiment from which the data came. 3.6 General discussion It may be appropriate to give some account of previous investigation of the same or related problems, or to relate the present conclusion to others in a connected area. It is worth discussing how far the original aim was successfully achieved, if it was not, why not, and how you might have done things differently. Reserva- tions about the data also belong here. (In real life, data sets may well contain errors or have been obtained from a badly designed experiment). This general discussion can in fact appear not as a section in itself but can be subsumed in the Introduction. 4 3.7 References These should always be included if you refer to books or papers from journals. The simplest, and widely-used style, is to refer to authors in the text in the format “Surname (Year of Publication)”, and to give the full references in the References section as shown at the end of this article i.e. for a journal article reference give Author’s surname, author’s initials, title of paper including subtitle if there is one, journal name, year of publication, volume, first and last page numbers of article, in that order; for a book reference give, in the following order, the author’es surname, the author’s initials, (year of publication) Title of book (in italics), publishing company, city of publication. 3.8 Appendix Whatever does not fit naturally into the main body of the report and cannot reasonably be omitted should go into an appendix. However, you don’t want the report to suffer from appendicitis! A case of the appendix or appendices tail wagging the main text dog makes the report hard to read."
  },
  {
    "objectID": "Report Writing/structurereport.html#titles-and-abstracts",
    "href": "Report Writing/structurereport.html#titles-and-abstracts",
    "title": "Examples of Mathematics translated into code",
    "section": "",
    "text": "Every report needs a title, preferably on a separate title page, which should also include the author’s name and department or other affiliation, and the date. The title should be short and informative. In general, this much detail won’t be required and it is most likely that your lecturers will have a template with an appropriate title ready.\nA brief summary – the shorter the better, and certainly no more than half a page – should follow, to tell the reader what the report is about, in general terms, and why it may be worth reading. A good abstract is solely a skeleton outline of (a) the problem, (b) what you have done, (c) your conclusions. It should not, if possible, use numbers, symbols or technical terms. Again, this is not required to be as detailed, nut as you move higher up on the academic and corporate ladder, titles and abstracts will play a larger role in gauging interest in your work, so keep this in mind.\nHere is an example of a title and an abstract:\nTitle: Statistical methods for healthcare regulation: rating, screening and surveillance\nAuthor(s): David Spiegelhalter, Christopher Sherlaw-Johnson, Martin Bardsley, Ian Blunt, Christopher Wood, Olivia Grigg\nAffiliation: Medical Research Council Biostatistics Unit, Cambridge, and related institutions\nDate: First published 21 November 2011 Wiley Online Library\nAbstract (as published):\nCurrent demand for accountability and efficiency of healthcare organizations, combined with the greater availability of routine data on clinical care and outcomes, has led to an increased focus on statistical methods in healthcare regulation. We consider three different regulatory functions in which statistical analysis plays a vital role: rating organizations, deciding whom to inspect and continuous surveillance for arising problems. A common approach to data standardization based on (possibly overdispersed) Z-scores is proposed, although specific tools are used for assessing performance against a target, combining indicators when screening for inspection, and continuous monitoring using risk-adjusted sequential testing procedures. We pay particular attention to the problem of simultaneously monitoring over 200 000 indicators for excess mortality, both with respect to the statistical issues surrounding massive multiplicity, and the organizational aspects of dealing with such a complex but high-profile process.\nNotice that the authors: \n\nKeep under half a page.\n\nAvoid numbers or statistical symbols.\n\nDo not interpret results in depth here — just state the what, how, and conclusion."
  },
  {
    "objectID": "Report Writing/structurereport.html#to-include-or-not-to-include-that-is-the-question",
    "href": "Report Writing/structurereport.html#to-include-or-not-to-include-that-is-the-question",
    "title": "Examples of Mathematics translated into code",
    "section": "",
    "text": "3.3 Introduction This should describe the general context and background, including a general description of what data are available, the manner in which and the purpose for which they were collected. It should also provide the aims of the investigation, together with some indication of the methods used. It may well be an expanded version of the summary, and in general should not exceed two pages in length. 3.4 Methods These should now be described in a fair amount of detail, including any theory that is necessary. How much detail is always difficult to decide. Aim to write as though for someone of comparable standing, e.g. a student in the same year as yourself, who does not know anything in detail about the subject of the re- port. The reader should be able to repeat the study on the basis of your report. Don’t be afraid of putting very detailed and long descriptions into one or more appendices. This component may well have to be split into sections, e.g. 3 1. a preliminary analysis, using graphical and simple descriptive methods, 2. a full-scale analysis. The second section may further have to be split into two subsections e.g. (a) a description, explanation or development of the methodology to be used, (b) the actual analysis. Subsection (a) will probably need to be quite technical, certainly more technical than the rest of the report. It should describe in detail the precise mathemat- ical/statistical tools and techniques to be used and reveal the manner in which they lead to the desired results. Do not shy away from using mathematical no- tation (get well familiar with the capabilities of your word-processor to produce mathematical expressions) but be careful to define every bit of the notation you use. A mathematical expression is totally meaningless if any of the symbols used in it is undefined. Similarly pages of mathematical development and explanations are rendered useless and total waste of space if any of the symbols involved in these explanations are not defined. I In the subsection containing the actual analysis it is important that you de- scribe your analysis sufficiently clearly and carefully to enable it to be reproduced by the reader. 3.5 Results, conclusions and recommendations Give the main results and conclusions. Subsidiary results and deductions can be left in this section if they do not detract from the flow of the presentation of the main results and conclusion; otherwise they may be gathered into a separate component, be combined with the description of methods, or be put into an appendix. Your conclusions should be expressed in a way that can be understood by a non-statistician and should make sense even if the reader of your report had omitted to read the middle section on detailed statistical analysis. Try to report your conclusion in the context of the experiment from which the data came. 3.6 General discussion It may be appropriate to give some account of previous investigation of the same or related problems, or to relate the present conclusion to others in a connected area. It is worth discussing how far the original aim was successfully achieved, if it was not, why not, and how you might have done things differently. Reserva- tions about the data also belong here. (In real life, data sets may well contain errors or have been obtained from a badly designed experiment). This general discussion can in fact appear not as a section in itself but can be subsumed in the Introduction. 4 3.7 References These should always be included if you refer to books or papers from journals. The simplest, and widely-used style, is to refer to authors in the text in the format “Surname (Year of Publication)”, and to give the full references in the References section as shown at the end of this article i.e. for a journal article reference give Author’s surname, author’s initials, title of paper including subtitle if there is one, journal name, year of publication, volume, first and last page numbers of article, in that order; for a book reference give, in the following order, the author’es surname, the author’s initials, (year of publication) Title of book (in italics), publishing company, city of publication. 3.8 Appendix Whatever does not fit naturally into the main body of the report and cannot reasonably be omitted should go into an appendix. However, you don’t want the report to suffer from appendicitis! A case of the appendix or appendices tail wagging the main text dog makes the report hard to read."
  },
  {
    "objectID": "Report Writing/useofaireport.html",
    "href": "Report Writing/useofaireport.html",
    "title": "Examples of Mathematics translated into code",
    "section": "",
    "text": "To start off, I want to make this clear: You should NOT be using AI to do your coursework for you! In no way is this section endorsing the use of LLMs like ChatGPT, Gemini, or other models to cut corners on assignments and coursework. This section will simply go through the healthy, and acceptable ways to use AI in your everyday studies.\n\n\nClarifying Concepts\n\n    Use AI to explain statistical ideas (e.g., Bayesian inference, p-values, regression assumptions) in simpler terms.\n\n    Great for quick refreshers before you start writing.\n\nCode Debugging & Optimisation\n\n    Paste your R / Python code and ask AI to find errors or suggest more efficient approaches.\n\n    Useful for spotting typos, missing parentheses, or inefficient loops.\n\nExploratory Data Analysis Help\n\n    Ask AI for ideas on which plots or summary stats to include.\n\n    Use it to remember ggplot2 or matplotlib syntax you’ve forgotten.\n\nReport Structure Guidance\n\n    Get sample outlines, section names, and suggestions for logical flow.\n\n    Ask for alternative ways to present your results (e.g., tables vs plots).\n\nFinding References & Resources\n\n    Ask for academic sources, journal article suggestions, or textbooks.\n\n    Always check the actual source before citing — AI can suggest leads but you must verify.\n\nPlain-Language Drafting\n\n    Use AI to rephrase technical findings for a non-statistical audience.\n\n    Helpful for the Abstract, Discussion, or Recommendations sections.\n\n\n\nCopy-Pasting AI Output as Your Work\n\n    Risks plagiarism and academic misconduct.\n\n    Even if AI generates correct text/code, rewrite in your own words and verify every number.\n\nTrusting Generated Code Blindly\n\n    AI can produce syntactically correct but statistically wrong methods (e.g., mis-specified models, wrong assumptions).\n\n    Always check the logic and outputs yourself.\n\nUsing AI for Fabricated Results\n\n    Never generate fake datasets, fake statistical outputs, or invented references.\n\n    Fabrication can be detected and is a serious offence.\n\nSkipping Understanding\n\n    If you let AI do all the work, you won’t be able to defend your answers if questioned.\n\n    Make sure you can explain every step in your own words.\n\nOverusing AI for Writing\n\n    Avoid making your whole report “AI-polished” to the point it loses your voice.\n\n    Many professors can spot a fully AI-written paper — and it may lack context-specific insight.\n\nIgnoring Data Privacy\n\n    Don’t paste sensitive or unpublished data into AI tools if your university or project has confidentiality requirements."
  },
  {
    "objectID": "Report Writing/useofaireport.html#good-ways-to-use-ai-in-statistics-assignments",
    "href": "Report Writing/useofaireport.html#good-ways-to-use-ai-in-statistics-assignments",
    "title": "Examples of Mathematics translated into code",
    "section": "",
    "text": "Clarifying Concepts\n\n    Use AI to explain statistical ideas (e.g., Bayesian inference, p-values, regression assumptions) in simpler terms.\n\n    Great for quick refreshers before you start writing.\n\nCode Debugging & Optimisation\n\n    Paste your R / Python code and ask AI to find errors or suggest more efficient approaches.\n\n    Useful for spotting typos, missing parentheses, or inefficient loops.\n\nExploratory Data Analysis Help\n\n    Ask AI for ideas on which plots or summary stats to include.\n\n    Use it to remember ggplot2 or matplotlib syntax you’ve forgotten.\n\nReport Structure Guidance\n\n    Get sample outlines, section names, and suggestions for logical flow.\n\n    Ask for alternative ways to present your results (e.g., tables vs plots).\n\nFinding References & Resources\n\n    Ask for academic sources, journal article suggestions, or textbooks.\n\n    Always check the actual source before citing — AI can suggest leads but you must verify.\n\nPlain-Language Drafting\n\n    Use AI to rephrase technical findings for a non-statistical audience.\n\n    Helpful for the Abstract, Discussion, or Recommendations sections."
  },
  {
    "objectID": "Report Writing/useofaireport.html#what-to-avoid-when-using-ai",
    "href": "Report Writing/useofaireport.html#what-to-avoid-when-using-ai",
    "title": "Examples of Mathematics translated into code",
    "section": "",
    "text": "Copy-Pasting AI Output as Your Work\n\n    Risks plagiarism and academic misconduct.\n\n    Even if AI generates correct text/code, rewrite in your own words and verify every number.\n\nTrusting Generated Code Blindly\n\n    AI can produce syntactically correct but statistically wrong methods (e.g., mis-specified models, wrong assumptions).\n\n    Always check the logic and outputs yourself.\n\nUsing AI for Fabricated Results\n\n    Never generate fake datasets, fake statistical outputs, or invented references.\n\n    Fabrication can be detected and is a serious offence.\n\nSkipping Understanding\n\n    If you let AI do all the work, you won’t be able to defend your answers if questioned.\n\n    Make sure you can explain every step in your own words.\n\nOverusing AI for Writing\n\n    Avoid making your whole report “AI-polished” to the point it loses your voice.\n\n    Many professors can spot a fully AI-written paper — and it may lack context-specific insight.\n\nIgnoring Data Privacy\n\n    Don’t paste sensitive or unpublished data into AI tools if your university or project has confidentiality requirements."
  },
  {
    "objectID": "Data Visualisation/customising graphs.html",
    "href": "Data Visualisation/customising graphs.html",
    "title": "Graph Customisation",
    "section": "",
    "text": "When you first create plots in R, the default settings work well for exploring your data. However, when you’re preparing visualizations for presentations, reports, or publications, you’ll want to polish them to make your message clearer and more visually appealing.\nIn this tutorial, we’ll learn how to customize various aspects of ggplot2 graphs including axes, colors, labels, legends, and themes. We’ll primarily use the palmerpenguins dataset, which contains measurements of three penguin species from islands in Antarctica.\nFirst, let’s load our packages and data:\n\n\nCode\n```{r}\n#| message: false\nlibrary(ggplot2)\n```\n\n\nWarning: package 'ggplot2' was built under R version 4.4.3\n\n\nCode\n```{r}\n#| message: false\nlibrary(palmerpenguins)\n```\n\n\nWarning: package 'palmerpenguins' was built under R version 4.4.3\n\n\nCode\n```{r}\n#| message: false\nlibrary(dplyr)\n```\n\n\nWarning: package 'dplyr' was built under R version 4.4.3\n\n\nCode\n```{r}\n#| message: false\n# View the first few rows\nhead(penguins)\n```\n\n\n# A tibble: 6 × 8\n  species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n1 Adelie  Torgersen           39.1          18.7               181        3750\n2 Adelie  Torgersen           39.5          17.4               186        3800\n3 Adelie  Torgersen           40.3          18                 195        3250\n4 Adelie  Torgersen           NA            NA                  NA          NA\n5 Adelie  Torgersen           36.7          19.3               193        3450\n6 Adelie  Torgersen           39.3          20.6               190        3650\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;",
    "crumbs": [
      "Home",
      "Data Visualisation",
      "Graph Customisation"
    ]
  },
  {
    "objectID": "Data Visualisation/customising graphs.html#quantitative-axes",
    "href": "Data Visualisation/customising graphs.html#quantitative-axes",
    "title": "Graph Customisation",
    "section": "Quantitative axes",
    "text": "Quantitative axes\nQuantitative x- and y-axes can be modified using the scale_x_continuous and scale_y_continuous functions respectively\nOptions include\nbreaks - a numeric vector of positions\nlimits - a numeric vector with the min and max for the scale"
  },
  {
    "objectID": "Data Visualisation/bivariate.html",
    "href": "Data Visualisation/bivariate.html",
    "title": "Visualizing Bivariate Data",
    "section": "",
    "text": "One of the most fundamental questions in data analysis is: “How does variable A relate to variable B?”\nBivariate analysis allows us to investigate relationships, correlations, and differences between groups. The specific type of graph you choose depends entirely on the data types you are working with (Categorical or Quantitative)."
  },
  {
    "objectID": "Data Visualisation/bivariate.html#a-tibble-12-5",
    "href": "Data Visualisation/bivariate.html#a-tibble-12-5",
    "title": "Dealing with bivariate data",
    "section": "# A tibble: 12 × 5",
    "text": "# A tibble: 12 × 5"
  },
  {
    "objectID": "Data Visualisation/bivariate.html#groups-class-7",
    "href": "Data Visualisation/bivariate.html#groups-class-7",
    "title": "Dealing with bivariate data",
    "section": "# Groups: class [7]",
    "text": "# Groups: class [7]"
  },
  {
    "objectID": "Data Visualisation/bivariate.html#class-drv-n-pct-lbl",
    "href": "Data Visualisation/bivariate.html#class-drv-n-pct-lbl",
    "title": "Dealing with bivariate data",
    "section": "class drv n pct lbl",
    "text": "class drv n pct lbl"
  },
  {
    "objectID": "Data Visualisation/bivariate.html#seater-r-5-1-100",
    "href": "Data Visualisation/bivariate.html#seater-r-5-1-100",
    "title": "Dealing with bivariate data",
    "section": "1 2seater r 5 1 100%",
    "text": "1 2seater r 5 1 100%"
  },
  {
    "objectID": "Data Visualisation/bivariate.html#compact-4-12-0.255-26",
    "href": "Data Visualisation/bivariate.html#compact-4-12-0.255-26",
    "title": "Dealing with bivariate data",
    "section": "2 compact 4 12 0.255 26%",
    "text": "2 compact 4 12 0.255 26%"
  },
  {
    "objectID": "Data Visualisation/bivariate.html#compact-f-35-0.745-74",
    "href": "Data Visualisation/bivariate.html#compact-f-35-0.745-74",
    "title": "Dealing with bivariate data",
    "section": "3 compact f 35 0.745 74%",
    "text": "3 compact f 35 0.745 74%"
  },
  {
    "objectID": "Data Visualisation/bivariate.html#midsize-4-3-0.0732-7",
    "href": "Data Visualisation/bivariate.html#midsize-4-3-0.0732-7",
    "title": "Dealing with bivariate data",
    "section": "4 midsize 4 3 0.0732 7%",
    "text": "4 midsize 4 3 0.0732 7%"
  },
  {
    "objectID": "Data Visualisation/bivariate.html#midsize-f-38-0.927-93",
    "href": "Data Visualisation/bivariate.html#midsize-f-38-0.927-93",
    "title": "Dealing with bivariate data",
    "section": "5 midsize f 38 0.927 93%",
    "text": "5 midsize f 38 0.927 93%"
  },
  {
    "objectID": "Data Visualisation/bivariate.html#minivan-f-11-1-100",
    "href": "Data Visualisation/bivariate.html#minivan-f-11-1-100",
    "title": "Dealing with bivariate data",
    "section": "6 minivan f 11 1 100%",
    "text": "6 minivan f 11 1 100%"
  },
  {
    "objectID": "Data Visualisation/bivariate.html#pickup-4-33-1-100",
    "href": "Data Visualisation/bivariate.html#pickup-4-33-1-100",
    "title": "Dealing with bivariate data",
    "section": "7 pickup 4 33 1 100%",
    "text": "7 pickup 4 33 1 100%"
  },
  {
    "objectID": "Data Visualisation/bivariate.html#subcompact-4-4-0.114-11",
    "href": "Data Visualisation/bivariate.html#subcompact-4-4-0.114-11",
    "title": "Dealing with bivariate data",
    "section": "8 subcompact 4 4 0.114 11%",
    "text": "8 subcompact 4 4 0.114 11%"
  },
  {
    "objectID": "Data Visualisation/bivariate.html#subcompact-f-22-0.629-63",
    "href": "Data Visualisation/bivariate.html#subcompact-f-22-0.629-63",
    "title": "Dealing with bivariate data",
    "section": "9 subcompact f 22 0.629 63%",
    "text": "9 subcompact f 22 0.629 63%"
  },
  {
    "objectID": "Data Visualisation/bivariate.html#subcompact-r-9-0.257-26",
    "href": "Data Visualisation/bivariate.html#subcompact-r-9-0.257-26",
    "title": "Dealing with bivariate data",
    "section": "10 subcompact r 9 0.257 26%",
    "text": "10 subcompact r 9 0.257 26%"
  },
  {
    "objectID": "Data Visualisation/bivariate.html#suv-4-51-0.823-82",
    "href": "Data Visualisation/bivariate.html#suv-4-51-0.823-82",
    "title": "Dealing with bivariate data",
    "section": "11 suv 4 51 0.823 82%",
    "text": "11 suv 4 51 0.823 82%"
  },
  {
    "objectID": "Data Visualisation/bivariate.html#suv-r-11-0.177-18",
    "href": "Data Visualisation/bivariate.html#suv-r-11-0.177-18",
    "title": "Dealing with bivariate data",
    "section": "12 suv r 11 0.177 18%",
    "text": "12 suv r 11 0.177 18%\nNext, we’ll use this dataset and the geom_text function to add labels to each bar segment."
  },
  {
    "objectID": "Data Visualisation/bivariate.html#stacked-bar-charts",
    "href": "Data Visualisation/bivariate.html#stacked-bar-charts",
    "title": "Visualizing Bivariate Data",
    "section": "1.1 Stacked Bar Charts",
    "text": "1.1 Stacked Bar Charts\nThe default behavior of a bar chart in ggplot2 is to stack categories on top of one another. This gives you a sense of the total count while showing the breakdown of subgroups.\n\n\nCode\n```{r Data Penguins}\nlibrary(ggplot2)\n```\n\n\nWarning: package 'ggplot2' was built under R version 4.4.3\n\n\nCode\n```{r Data Penguins}\nlibrary(palmerpenguins)\n```\n\n\nWarning: package 'palmerpenguins' was built under R version 4.4.3\n\n\nCode\n```{r Data Penguins}\npenguins &lt;- palmerpenguins::penguins\npenguins &lt;- na.omit(penguins)\n\nhead(penguins)\n\n# Stacked bar chart\nggplot(penguins, aes(x = island, fill = species)) + \n  geom_bar(position = \"stack\") +\n  labs(title = \"Species Distribution by Island (Stacked)\")\n```\n\n\n# A tibble: 6 × 8\n  species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n1 Adelie  Torgersen           39.1          18.7               181        3750\n2 Adelie  Torgersen           39.5          17.4               186        3800\n3 Adelie  Torgersen           40.3          18                 195        3250\n4 Adelie  Torgersen           36.7          19.3               193        3450\n5 Adelie  Torgersen           39.3          20.6               190        3650\n6 Adelie  Torgersen           38.9          17.8               181        3625\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\n\n\n\n\n\n\n\n\nFrom this chart, we can quickly see that Biscoe island has the most penguins overall, and Torgersen island is exclusively inhabited by Adelie penguins."
  },
  {
    "objectID": "Data Visualisation/bivariate.html#grouped-bar-charts",
    "href": "Data Visualisation/bivariate.html#grouped-bar-charts",
    "title": "Visualizing Bivariate Data",
    "section": "1.2 Grouped Bar Charts",
    "text": "1.2 Grouped Bar Charts\nIf you want to compare the specific counts of species side-by-side, the “dodged” bar chart is preferred. It un-stacks the bars and places them next to each other.\n\n\nCode\n```{r Penguins 1}\n# Grouped bar chart\nggplot(penguins, aes(x = island, fill = species)) + \n  geom_bar(position = \"dodge\") +\n  labs(title = \"Species Distribution by Island (Grouped)\")\n```\n\n\n\n\n\n\n\n\n\nNote: By default, if a category has zero observations (like Chinstrap penguins on Biscoe), the bar is omitted, and the remaining bars expand to fill the space. If you want to preserve the width and show the gap, use position_dodge(preserve = \"single\")."
  },
  {
    "objectID": "Data Visualisation/bivariate.html#segmented-100-fill-bar-charts",
    "href": "Data Visualisation/bivariate.html#segmented-100-fill-bar-charts",
    "title": "Visualizing Bivariate Data",
    "section": "1.3 Segmented (100% Fill) Bar Charts",
    "text": "1.3 Segmented (100% Fill) Bar Charts\nSometimes, raw counts matter less than percentages. If we want to know “What proportion of penguins on Dream Island are Chinstraps?”, we use the “fill” position. This stretches every bar to 100%.\n\n\nCode\n```{r Penguins 2}\nlibrary(scales)\n```\n\n\nWarning: package 'scales' was built under R version 4.4.3\n\n\nCode\n```{r Penguins 2}\n# Segmented bar chart\nggplot(penguins, aes(x = island, fill = species)) + \n  geom_bar(position = \"fill\") + \n  scale_y_continuous(labels = percent) +\n  labs(y = \"Proportion\", title = \"Species Proportion by Island\") +\n  theme_minimal()\n```"
  },
  {
    "objectID": "Data Visualisation/bivariate.html#adding-labels",
    "href": "Data Visualisation/bivariate.html#adding-labels",
    "title": "Visualizing Bivariate Data",
    "section": "1.4 Adding Labels",
    "text": "1.4 Adding Labels\nA segmented bar chart is most effective when the actual percentages are written on the plot. To do this, we must first calculate the percentages manually using dplyr, and then plot the summary data.\n\n\nCode\n```{r Penguins 3}\nlibrary(dplyr)\n```\n\n\nWarning: package 'dplyr' was built under R version 4.4.3\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n\nCode\n```{r Penguins 3}\n# 1. Create a summary table with labels\nplotdata &lt;- penguins %&gt;%\n  group_by(island, species) %&gt;%\n  summarize(n = n()) %&gt;% \n  mutate(pct = n / sum(n),\n         lbl = scales::percent(pct, accuracy = 1))\n```\n\n\n`summarise()` has grouped output by 'island'. You can override using the\n`.groups` argument.\n\n\nCode\n```{r Penguins 3}\n# 2. Plot using the summary data\nggplot(plotdata, aes(x = island, y = pct, fill = species)) + \n  # Use geom_col for pre-calculated data\n  geom_col(position = \"fill\") + \n  geom_text(aes(label = lbl), \n            position = position_fill(vjust = 0.5), \n            color = \"white\", fontface = \"bold\") +\n  scale_y_continuous(labels = percent) +\n  labs(y = \"Percent\", title = \"Species Composition by Island\") +\n  theme_minimal()\n```"
  },
  {
    "objectID": "Data Visualisation/bivariate.html#scatterplots",
    "href": "Data Visualisation/bivariate.html#scatterplots",
    "title": "Visualizing Bivariate Data",
    "section": "2.1 Scatterplots",
    "text": "2.1 Scatterplots\nThe scatterplot is the standard for bivariate quantitative data. Let’s look at the relationship between Flipper Length and Body Mass.\n\n\nCode\n```{r Penguins 4}\n# Enhanced scatterplot\nggplot(penguins, aes(x = flipper_length_mm, y = body_mass_g)) + \n  geom_point(color = \"cornflowerblue\", size = 2, alpha = 0.6) + \n  labs(title = \"Flipper Length vs. Body Mass\",\n       x = \"Flipper Length (mm)\",\n       y = \"Body Mass (g)\") +\n  theme_minimal()\n```"
  },
  {
    "objectID": "Data Visualisation/bivariate.html#adding-trend-lines",
    "href": "Data Visualisation/bivariate.html#adding-trend-lines",
    "title": "Visualizing Bivariate Data",
    "section": "2.2 Adding Trend Lines",
    "text": "2.2 Adding Trend Lines\nTo summarize the relationship, we can add a trend line using geom_smooth().\n\nLinear Fit\nThe most common approach is a straight linear regression line (method = \"lm\").\n\n\nCode\n```{r}\nggplot(penguins, aes(x = flipper_length_mm, y = body_mass_g)) + \n  geom_point(color = \"cornflowerblue\", alpha = 0.6) + \n  geom_smooth(method = \"lm\", color = \"black\", size = 1) +\n  labs(title = \"Linear Relationship\")\n```\n\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\nPolynomial and Loess Curves\nNot all data is linear. Sometimes relationships curve.\n\nPolynomial: Uses a formula (e.g., quadratic) to fit a curve.\nLoess: A non-parametric method that follows the data locally. This is the default in ggplot2 for smaller datasets.\n\nLet’s look at a different dataset, gapminder, to see a curved relationship between GDP per Capita and Life Expectancy.\n\n\nCode\n```{r}\nlibrary(gapminder)\n```\n\n\nWarning: package 'gapminder' was built under R version 4.4.3\n\n\nCode\n```{r}\n# Loess Curve (Standard Smoothing)\nggplot(gapminder, aes(x = gdpPercap, y = lifeExp)) + \n  geom_point(alpha = 0.3, color = \"darkcyan\") + \n  geom_smooth(method = \"loess\", color = \"red\") + \n  scale_x_log10(labels = scales::dollar) + # Log scale helps visualize GDP\n  labs(title = \"GDP vs Life Expectancy (Loess Fit)\",\n       subtitle = \"Note the logarithmic X axis\")\n```\n\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "Data Visualisation/bivariate.html#time-series-line-plots",
    "href": "Data Visualisation/bivariate.html#time-series-line-plots",
    "title": "Visualizing Bivariate Data",
    "section": "2.3 Time Series (Line Plots)",
    "text": "2.3 Time Series (Line Plots)\nIf one of your quantitative variables is Time, a line plot is the standard choice. Below is the change in Life Expectancy in the United States over time.\n\n\nCode\n```{r}\n# Filter for US data\nus_data &lt;- filter(gapminder, country == \"United States\")\n\n# Line plot with points\nggplot(us_data, aes(x = year, y = lifeExp)) + \n  geom_line(size = 1.2, color = \"grey\") + \n  geom_point(size = 3, color = \"steelblue\") + \n  labs(title = \"US Life Expectancy (1952-2007)\",\n       y = \"Life Expectancy (years)\") +\n  theme_minimal()\n```"
  },
  {
    "objectID": "Data Visualisation/bivariate.html#bar-charts-summary-statistics",
    "href": "Data Visualisation/bivariate.html#bar-charts-summary-statistics",
    "title": "Visualizing Bivariate Data",
    "section": "3.1 Bar Charts (Summary Statistics)",
    "text": "3.1 Bar Charts (Summary Statistics)\nWe can plot the Mean of a variable for each group. Here, we calculate the average body mass for each penguin species.\n\n\nCode\n```{r}\n# Calculate means\nmean_data &lt;- penguins %&gt;%\n  group_by(species) %&gt;%\n  summarize(mean_mass = mean(body_mass_g))\n\n# Plot means\nggplot(mean_data, aes(x = species, y = mean_mass)) + \n  geom_col(fill = \"steelblue\", width = 0.7) + \n  geom_text(aes(label = round(mean_mass, 0)), vjust = -0.5) +\n  scale_y_continuous(limits = c(0, 6000)) +\n  labs(title = \"Average Body Mass by Species\", y = \"Mass (g)\") +\n  theme_minimal()\n```\n\n\n\n\n\n\n\n\n\nWarning: Bar charts of means can be misleading because they hide the spread of the data. A species with highly variable weights looks the same as a species with consistent weights."
  },
  {
    "objectID": "Data Visualisation/bivariate.html#distributions-boxplots-and-violins",
    "href": "Data Visualisation/bivariate.html#distributions-boxplots-and-violins",
    "title": "Visualizing Bivariate Data",
    "section": "3.2 Distributions: Boxplots and Violins",
    "text": "3.2 Distributions: Boxplots and Violins\nTo see the spread, we use distribution plots.\n\nBoxplots\nBoxplots summarize the distribution using quartiles. They show the median, the IQR (Interquartile Range), and outliers.\n\n\nCode\n```{r}\nggplot(penguins, aes(x = species, y = body_mass_g, fill = species)) + \n  geom_boxplot(alpha = 0.6) + \n  labs(title = \"Body Mass Distribution by Species\") +\n  theme_minimal() +\n  theme(legend.position = \"none\")\n```\n\n\n\n\n\n\n\n\n\n\n\nViolin Plots\nViolin plots show the “density” of the data. The wider the violin, the more data points exist at that value.\n\n\nCode\n```{r}\nggplot(penguins, aes(x = species, y = body_mass_g, fill = species)) + \n  geom_violin(trim = FALSE, alpha = 0.6) + \n  geom_boxplot(width = 0.1, fill = \"white\") + # Add boxplot inside for reference\n  labs(title = \"Violin Plot with Embedded Boxplot\") +\n  theme_minimal() +\n  theme(legend.position = \"none\")\n```"
  },
  {
    "objectID": "Data Visualisation/bivariate.html#ridgeline-plots",
    "href": "Data Visualisation/bivariate.html#ridgeline-plots",
    "title": "Visualizing Bivariate Data",
    "section": "3.3 Ridgeline Plots",
    "text": "3.3 Ridgeline Plots\nRidgeline plots (or “Joyplots”) are excellent when you have many categories. They display density curves stacked vertically.\n\n\nCode\n```{r}\nlibrary(ggridges)\n```\n\n\nWarning: package 'ggridges' was built under R version 4.4.3\n\n\nCode\n```{r}\nggplot(penguins, aes(x = body_mass_g, y = species, fill = species)) + \n  geom_density_ridges(alpha = 0.7) + \n  labs(title = \"Ridgeline Plot of Body Mass\") +\n  theme_ridges() + \n  theme(legend.position = \"none\")\n```\n\n\nPicking joint bandwidth of 153"
  },
  {
    "objectID": "Data Visualisation/bivariate.html#mean-with-error-bars",
    "href": "Data Visualisation/bivariate.html#mean-with-error-bars",
    "title": "Visualizing Bivariate Data",
    "section": "3.4 Mean with Error Bars",
    "text": "3.4 Mean with Error Bars\nScientific publications often require plots showing the Mean +/- the Standard Error (SEM) or Confidence Interval.\n\n\nCode\n```{r}\n# Calculate stats\nsummary_stats &lt;- penguins %&gt;%\n  group_by(species, sex) %&gt;%\n  summarize(\n    n = n(),\n    mean = mean(body_mass_g),\n    sd = sd(body_mass_g),\n    se = sd / sqrt(n)\n  )\n```\n\n\n`summarise()` has grouped output by 'species'. You can override using the\n`.groups` argument.\n\n\nCode\n```{r}\n# Plot Mean +/- SE\npd &lt;- position_dodge(0.2) # To separate overlapping bars\n\nggplot(summary_stats, aes(x = species, y = mean, color = sex, group = sex)) + \n  geom_point(position = pd, size = 4) + \n  geom_errorbar(aes(ymin = mean - se, ymax = mean + se), width = 0.2, position = pd, size = 1) +\n  labs(title = \"Mean Body Mass by Species and Sex\",\n       subtitle = \"Error bars represent Standard Error\",\n       y = \"Body Mass (g)\") +\n  theme_minimal()\n```"
  },
  {
    "objectID": "Data Visualisation/bivariate.html#jitter-and-strip-plots",
    "href": "Data Visualisation/bivariate.html#jitter-and-strip-plots",
    "title": "Visualizing Bivariate Data",
    "section": "3.5 Jitter and Strip Plots",
    "text": "3.5 Jitter and Strip Plots\nIf your dataset isn’t massive, the most honest way to show the data is to show all the points. To prevent points from overlapping, we “jitter” them (add random noise).\n\n\nCode\n```{r}\nggplot(penguins, aes(x = species, y = body_mass_g, color = species)) + \n  geom_jitter(width = 0.2, alpha = 0.6) + \n  stat_summary(fun = mean, geom = \"point\", shape = 95, size = 10, color = \"black\") + # Add mean bar\n  labs(title = \"Raw Data with Mean Indicator\") +\n  theme_minimal() +\n  theme(legend.position = \"none\")\n```"
  },
  {
    "objectID": "Data Visualisation/bivariate.html#cleveland-dot-plots-lollipop-charts",
    "href": "Data Visualisation/bivariate.html#cleveland-dot-plots-lollipop-charts",
    "title": "Visualizing Bivariate Data",
    "section": "3.6 Cleveland Dot Plots (Lollipop Charts)",
    "text": "3.6 Cleveland Dot Plots (Lollipop Charts)\nWhen comparing a numeric value across many categories (like countries), a bar chart becomes cluttered. A Cleveland dot plot (or lollipop chart) is a cleaner alternative.\nLet’s look at Life Expectancy in the Americas in 2007.\n\n\nCode\n```{r}\n# Prepare data\namericas &lt;- gapminder %&gt;% \n  filter(continent == \"Americas\" & year == 2007)\n\n# Lollipop Chart\nggplot(americas, aes(x = lifeExp, y = reorder(country, lifeExp))) + \n  geom_segment(aes(x = 60, xend = lifeExp, y = country, yend = country), color = \"grey\") +\n  geom_point(size = 3, color = \"darkcyan\") + \n  labs(title = \"Life Expectancy in the Americas (2007)\",\n       x = \"Life Expectancy (Years)\", y = \"\") +\n  theme_minimal() +\n  theme(panel.grid.major.y = element_blank()) # Remove horizontal grid lines for clarity\n```"
  },
  {
    "objectID": "Data Visualisation/othergraphs.html#basic-bubble-chart",
    "href": "Data Visualisation/othergraphs.html#basic-bubble-chart",
    "title": "Specialized Visualization Techniques",
    "section": "Basic Bubble Chart",
    "text": "Basic Bubble Chart\nLet’s explore the relationship between penguin flipper length, body mass, and bill length:"
  },
  {
    "objectID": "Data Visualisation/othergraphs.html#enhanced-bubble-chart",
    "href": "Data Visualisation/othergraphs.html#enhanced-bubble-chart",
    "title": "Specialized Visualization Techniques",
    "section": "Enhanced Bubble Chart",
    "text": "Enhanced Bubble Chart\nLet’s improve this with better styling and add a fourth variable (species) using color:\n\n\n\n\n\n\n\n\n\nThe scale_size_continuous(range = c(2, 12)) controls the minimum and maximum bubble sizes.\nNote: Bubble charts are controversial because humans are better at judging length than area. Use them when the approximate relationship is more important than exact values."
  },
  {
    "objectID": "Data Visualisation/othergraphs.html#creating-a-correlation-matrix",
    "href": "Data Visualisation/othergraphs.html#creating-a-correlation-matrix",
    "title": "Specialized Visualization Techniques",
    "section": "Creating a Correlation Matrix",
    "text": "Creating a Correlation Matrix\nLet’s visualize correlations between penguin measurements:\n\n\n\n\n\n\n\n\n\nStrong positive correlations appear in red, negative correlations in blue, and weak correlations in white."
  },
  {
    "objectID": "Data Visualisation/othergraphs.html#clustered-heatmap-for-groups",
    "href": "Data Visualisation/othergraphs.html#clustered-heatmap-for-groups",
    "title": "Specialized Visualization Techniques",
    "section": "Clustered Heatmap for Groups",
    "text": "Clustered Heatmap for Groups\nLet’s create a heatmap showing average measurements by species:"
  },
  {
    "objectID": "Data Visualisation/othergraphs.html#custom-scatterplot-matrix",
    "href": "Data Visualisation/othergraphs.html#custom-scatterplot-matrix",
    "title": "Specialized Visualization Techniques",
    "section": "Custom Scatterplot Matrix",
    "text": "Custom Scatterplot Matrix\nYou can customize the appearance with your own functions:"
  },
  {
    "objectID": "Data Visualisation/othergraphs.html#basic-alluvial-diagram",
    "href": "Data Visualisation/othergraphs.html#basic-alluvial-diagram",
    "title": "Specialized Visualization Techniques",
    "section": "Basic Alluvial Diagram",
    "text": "Basic Alluvial Diagram\nLet’s examine how penguins are distributed across species, islands, and sex:\n\n\n\n\n\n\n\n\n\nHow to read this: - Start on the left with species - Follow the flows to see how each species is distributed across islands - Continue following to see the sex distribution - Flow width represents the number of penguins"
  },
  {
    "objectID": "Data Visualisation/othergraphs.html#enhanced-alluvial-diagram",
    "href": "Data Visualisation/othergraphs.html#enhanced-alluvial-diagram",
    "title": "Specialized Visualization Techniques",
    "section": "Enhanced Alluvial Diagram",
    "text": "Enhanced Alluvial Diagram\nLet’s create a more detailed version with better styling:"
  },
  {
    "objectID": "Data Visualisation/othergraphs.html#waterfall-chart-with-net-total",
    "href": "Data Visualisation/othergraphs.html#waterfall-chart-with-net-total",
    "title": "Specialized Visualization Techniques",
    "section": "Waterfall Chart with Net Total",
    "text": "Waterfall Chart with Net Total\nLet’s add a total column to show the final balance:\n\n\n\n\n\n\n\n\n\nThis shows clearly how the initial grant is allocated across different expenses."
  },
  {
    "objectID": "Data Visualisation/importing data.html#csv-and-text-files",
    "href": "Data Visualisation/importing data.html#csv-and-text-files",
    "title": "Data Import and Preparation in R",
    "section": "CSV and Text Files",
    "text": "CSV and Text Files\nThe readr package provides efficient functions for importing text-based data:\nThese functions assume that: - The first row contains column names - Values are separated by commas (CSV) or tabs (TSV) - Missing data appears as blank cells\nHere’s what the first few lines of a CSV file look like:\nspecies,island,bill_length_mm,bill_depth_mm,flipper_length_mm,body_mass_g,sex\nAdelie,Torgersen,39.1,18.7,181,3750,male\nAdelie,Torgersen,39.5,17.4,186,3800,female\nAdelie,Torgersen,40.3,18.0,195,3250,female\nTip: For more options (like different delimiters or handling special cases), check the help documentation with ?read_csv.",
    "crumbs": [
      "Home",
      "Data Visualisation",
      "Data Import and Preparation in R"
    ]
  },
  {
    "objectID": "Data Visualisation/importing data.html#excel-files",
    "href": "Data Visualisation/importing data.html#excel-files",
    "title": "Data Import and Preparation in R",
    "section": "Excel Files",
    "text": "Excel Files\nThe readxl package handles Excel workbooks (both .xls and .xlsx):\nSince Excel files can have multiple worksheets, use the sheet option to specify which one you want. The default is the first sheet.",
    "crumbs": [
      "Home",
      "Data Visualisation",
      "Data Import and Preparation in R"
    ]
  },
  {
    "objectID": "Data Visualisation/importing data.html#files-from-other-statistical-software",
    "href": "Data Visualisation/importing data.html#files-from-other-statistical-software",
    "title": "Data Import and Preparation in R",
    "section": "Files from Other Statistical Software",
    "text": "Files from Other Statistical Software\nThe haven package lets you import data from other statistical programs without needing those programs installed:",
    "crumbs": [
      "Home",
      "Data Visualisation",
      "Data Import and Preparation in R"
    ]
  },
  {
    "objectID": "Data Visualisation/importing data.html#selecting-variables-columns",
    "href": "Data Visualisation/importing data.html#selecting-variables-columns",
    "title": "Data Import and Preparation in R",
    "section": "Selecting Variables (Columns)",
    "text": "Selecting Variables (Columns)\nUse select() to keep only the columns you need:\n\n\n# A tibble: 6 × 3\n  species island    body_mass_g\n  &lt;fct&gt;   &lt;fct&gt;           &lt;int&gt;\n1 Adelie  Torgersen        3750\n2 Adelie  Torgersen        3800\n3 Adelie  Torgersen        3250\n4 Adelie  Torgersen          NA\n5 Adelie  Torgersen        3450\n6 Adelie  Torgersen        3650\n\n\n\n\n# A tibble: 6 × 5\n  species bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;fct&gt;            &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n1 Adelie            39.1          18.7               181        3750\n2 Adelie            39.5          17.4               186        3800\n3 Adelie            40.3          18                 195        3250\n4 Adelie            NA            NA                  NA          NA\n5 Adelie            36.7          19.3               193        3450\n6 Adelie            39.3          20.6               190        3650\n\n\n\n\n# A tibble: 6 × 6\n  species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n1 Adelie  Torgersen           39.1          18.7               181        3750\n2 Adelie  Torgersen           39.5          17.4               186        3800\n3 Adelie  Torgersen           40.3          18                 195        3250\n4 Adelie  Torgersen           NA            NA                  NA          NA\n5 Adelie  Torgersen           36.7          19.3               193        3450\n6 Adelie  Torgersen           39.3          20.6               190        3650",
    "crumbs": [
      "Home",
      "Data Visualisation",
      "Data Import and Preparation in R"
    ]
  },
  {
    "objectID": "Data Visualisation/importing data.html#filtering-observations-rows",
    "href": "Data Visualisation/importing data.html#filtering-observations-rows",
    "title": "Data Import and Preparation in R",
    "section": "Filtering Observations (Rows)",
    "text": "Filtering Observations (Rows)\nUse filter() to keep only rows that meet certain conditions. You can combine conditions with & (AND) and | (OR):\n\n\n# A tibble: 6 × 8\n  species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n1 Adelie  Torgersen           39.1          18.7               181        3750\n2 Adelie  Torgersen           39.5          17.4               186        3800\n3 Adelie  Torgersen           40.3          18                 195        3250\n4 Adelie  Torgersen           NA            NA                  NA          NA\n5 Adelie  Torgersen           36.7          19.3               193        3450\n6 Adelie  Torgersen           39.3          20.6               190        3650\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\n\n\n\n# A tibble: 6 × 8\n  species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n1 Adelie  Torgersen           39.1          18.7               181        3750\n2 Adelie  Torgersen           39.5          17.4               186        3800\n3 Adelie  Torgersen           40.3          18                 195        3250\n4 Adelie  Torgersen           NA            NA                  NA          NA\n5 Adelie  Torgersen           36.7          19.3               193        3450\n6 Adelie  Torgersen           39.3          20.6               190        3650\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\n\n\n\n# A tibble: 6 × 8\n  species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n1 Adelie  Torgersen           39.1          18.7               181        3750\n2 Adelie  Torgersen           39.5          17.4               186        3800\n3 Adelie  Torgersen           40.3          18                 195        3250\n4 Adelie  Torgersen           NA            NA                  NA          NA\n5 Adelie  Torgersen           36.7          19.3               193        3450\n6 Adelie  Torgersen           39.3          20.6               190        3650\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\n\nCommon comparison operators: - == equals - != not equals - &gt; greater than - &lt; less than - &gt;= greater than or equal to - &lt;= less than or equal to",
    "crumbs": [
      "Home",
      "Data Visualisation",
      "Data Import and Preparation in R"
    ]
  },
  {
    "objectID": "Data Visualisation/importing data.html#creating-and-modifying-variables",
    "href": "Data Visualisation/importing data.html#creating-and-modifying-variables",
    "title": "Data Import and Preparation in R",
    "section": "Creating and Modifying Variables",
    "text": "Creating and Modifying Variables\nUse mutate() to create new columns or modify existing ones:\n\n\n# A tibble: 6 × 5\n  species body_mass_g body_mass_kg flipper_length_mm flipper_length_cm\n  &lt;fct&gt;         &lt;int&gt;        &lt;dbl&gt;             &lt;int&gt;             &lt;dbl&gt;\n1 Adelie         3750         3.75               181              18.1\n2 Adelie         3800         3.8                186              18.6\n3 Adelie         3250         3.25               195              19.5\n4 Adelie           NA        NA                   NA              NA  \n5 Adelie         3450         3.45               193              19.3\n6 Adelie         3650         3.65               190              19  \n\n\n\nRecoding with ifelse()\nThe ifelse() function helps you create categorical variables based on conditions:\n\n\n# A tibble: 6 × 3\n  species body_mass_g size \n  &lt;fct&gt;         &lt;int&gt; &lt;chr&gt;\n1 Adelie         3750 small\n2 Adelie         3800 small\n3 Adelie         3250 small\n4 Adelie           NA &lt;NA&gt; \n5 Adelie         3450 small\n6 Adelie         3650 small\n\n\n\n\n# A tibble: 6 × 2\n  island    island_short\n  &lt;fct&gt;     &lt;chr&gt;       \n1 Torgersen Other       \n2 Torgersen Other       \n3 Torgersen Other       \n4 Torgersen Other       \n5 Torgersen Other       \n6 Torgersen Other",
    "crumbs": [
      "Home",
      "Data Visualisation",
      "Data Import and Preparation in R"
    ]
  },
  {
    "objectID": "Data Visualisation/importing data.html#summarizing-data",
    "href": "Data Visualisation/importing data.html#summarizing-data",
    "title": "Data Import and Preparation in R",
    "section": "Summarizing Data",
    "text": "Summarizing Data\nUse summarize() to calculate summary statistics. Combine it with group_by() to get statistics for each group:\n\n\n# A tibble: 1 × 2\n  mean_flipper mean_mass\n         &lt;dbl&gt;     &lt;dbl&gt;\n1         201.     4202.\n\n\nNote: The na.rm = TRUE option tells R to ignore missing values when calculating means.\n\n\n# A tibble: 3 × 4\n  species   mean_flipper mean_mass count\n  &lt;fct&gt;            &lt;dbl&gt;     &lt;dbl&gt; &lt;int&gt;\n1 Adelie            190.     3701.   152\n2 Chinstrap         196.     3733.    68\n3 Gentoo            217.     5076.   124\n\n\n\n\n# A tibble: 5 × 5\n  species   island    mean_bill_length sd_bill_length count\n  &lt;fct&gt;     &lt;fct&gt;                &lt;dbl&gt;          &lt;dbl&gt; &lt;int&gt;\n1 Adelie    Biscoe                39.0           2.48    44\n2 Adelie    Dream                 38.5           2.47    56\n3 Adelie    Torgersen             39.0           3.03    52\n4 Chinstrap Dream                 48.8           3.34    68\n5 Gentoo    Biscoe                47.5           3.08   124\n\n\nMany visualizations work best with summarized data rather than raw observations.",
    "crumbs": [
      "Home",
      "Data Visualisation",
      "Data Import and Preparation in R"
    ]
  },
  {
    "objectID": "Data Visualisation/importing data.html#using-the-pipe-operator",
    "href": "Data Visualisation/importing data.html#using-the-pipe-operator",
    "title": "Data Import and Preparation in R",
    "section": "Using the Pipe Operator",
    "text": "Using the Pipe Operator\nThe pipe operator %&gt;% (or |&gt; in newer R versions) lets you chain operations together, making your code cleaner and easier to read:\n\n\n# A tibble: 3 × 2\n  island    mean_mass\n  &lt;fct&gt;         &lt;dbl&gt;\n1 Biscoe        3710.\n2 Dream         3688.\n3 Torgersen     3706.\n\n\n\n\n# A tibble: 3 × 2\n  island    mean_mass\n  &lt;fct&gt;         &lt;dbl&gt;\n1 Biscoe        3710.\n2 Dream         3688.\n3 Torgersen     3706.\n\n\nThe pipe takes the output from the left side and passes it as the first argument to the function on the right side.",
    "crumbs": [
      "Home",
      "Data Visualisation",
      "Data Import and Preparation in R"
    ]
  },
  {
    "objectID": "Data Visualisation/importing data.html#working-with-dates",
    "href": "Data Visualisation/importing data.html#working-with-dates",
    "title": "Data Import and Preparation in R",
    "section": "Working with Dates",
    "text": "Working with Dates\nDates often come into R as text. The lubridate package makes it easy to convert them to proper date format:\n\n\nWarning: package 'lubridate' was built under R version 4.4.3\n\n\n\nAttaching package: 'lubridate'\n\n\nThe following objects are masked from 'package:base':\n\n    date, intersect, setdiff, union\n\n\n'data.frame':   3 obs. of  2 variables:\n $ person    : chr  \"Alice\" \"Bob\" \"Charlie\"\n $ birth_date: chr  \"03/15/1995\" \"Jul-22-98\" \"1:10:2000\"\n\n\n\n\n'data.frame':   3 obs. of  2 variables:\n $ person    : chr  \"Alice\" \"Bob\" \"Charlie\"\n $ birth_date: Date, format: \"1995-03-15\" \"1998-07-22\" ...\n\n\nCommon date conversion functions: - ymd() for year-month-day format (2024-01-15) - mdy() for month-day-year format (01/15/2024) - dmy() for day-month-year format (15-01-2024)\nOnce converted, you can do date arithmetic and extract components:\n\n\n   person birth_date      age\n1   Alice 1995-03-15 30.78879\n2     Bob 1998-07-22 27.43951\n3 Charlie 2000-01-10 25.97129",
    "crumbs": [
      "Home",
      "Data Visualisation",
      "Data Import and Preparation in R"
    ]
  },
  {
    "objectID": "Data Visualisation/importing data.html#reshaping-data-wide-vs.-long-format",
    "href": "Data Visualisation/importing data.html#reshaping-data-wide-vs.-long-format",
    "title": "Data Import and Preparation in R",
    "section": "Reshaping Data: Wide vs. Long Format",
    "text": "Reshaping Data: Wide vs. Long Format\nSome analyses require data in “wide” format, others need “long” format.\nWide format (each measurement type gets its own column):\n\n\n   id    name height_cm weight_kg\n1 P01   Alice       165        62\n2 P02     Bob       178        75\n3 P03 Charlie       172        70\n\n\nLong format (all measurements in one column):\n\n\nWarning: package 'tidyr' was built under R version 4.4.3\n\n\n# A tibble: 6 × 4\n  id    name    measurement value\n  &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;       &lt;dbl&gt;\n1 P01   Alice   height_cm     165\n2 P01   Alice   weight_kg      62\n3 P02   Bob     height_cm     178\n4 P02   Bob     weight_kg      75\n5 P03   Charlie height_cm     172\n6 P03   Charlie weight_kg      70\n\n\nConverting back to wide:\n\n\n# A tibble: 3 × 4\n  id    name    height_cm weight_kg\n  &lt;chr&gt; &lt;chr&gt;       &lt;dbl&gt;     &lt;dbl&gt;\n1 P01   Alice         165        62\n2 P02   Bob           178        75\n3 P03   Charlie       172        70\n\n\nLong format is often required for ggplot2, while wide format is easier for humans to read.",
    "crumbs": [
      "Home",
      "Data Visualisation",
      "Data Import and Preparation in R"
    ]
  },
  {
    "objectID": "Data Visualisation/importing data.html#checking-for-missing-values",
    "href": "Data Visualisation/importing data.html#checking-for-missing-values",
    "title": "Data Import and Preparation in R",
    "section": "Checking for Missing Values",
    "text": "Checking for Missing Values\nFirst, see how much data is missing:\n\n\n          species            island    bill_length_mm     bill_depth_mm \n                0                 0                 2                 2 \nflipper_length_mm       body_mass_g               sex              year \n                2                 2                11                 0 \n\n\n\n\n          species            island    bill_length_mm     bill_depth_mm \n              0.0               0.0               0.6               0.6 \nflipper_length_mm       body_mass_g               sex              year \n              0.6               0.6               3.2               0.0",
    "crumbs": [
      "Home",
      "Data Visualisation",
      "Data Import and Preparation in R"
    ]
  },
  {
    "objectID": "Data Visualisation/importing data.html#approach-1-remove-variables-with-too-many-missing-values",
    "href": "Data Visualisation/importing data.html#approach-1-remove-variables-with-too-many-missing-values",
    "title": "Data Import and Preparation in R",
    "section": "Approach 1: Remove Variables with Too Many Missing Values",
    "text": "Approach 1: Remove Variables with Too Many Missing Values\nIf a variable has too many missing values (say, &gt;50%), it might not be useful:\n\n\n[1] 8\n\n\n[1] 8",
    "crumbs": [
      "Home",
      "Data Visualisation",
      "Data Import and Preparation in R"
    ]
  },
  {
    "objectID": "Data Visualisation/importing data.html#approach-2-listwise-deletion",
    "href": "Data Visualisation/importing data.html#approach-2-listwise-deletion",
    "title": "Data Import and Preparation in R",
    "section": "Approach 2: Listwise Deletion",
    "text": "Approach 2: Listwise Deletion\nRemove any rows that contain missing values:\n\n\n[1] 344\n\n\n[1] 342\n\n\nWarning: This can remove a lot of data if missingness is spread across many rows!",
    "crumbs": [
      "Home",
      "Data Visualisation",
      "Data Import and Preparation in R"
    ]
  },
  {
    "objectID": "Data Visualisation/importing data.html#approach-3-imputation",
    "href": "Data Visualisation/importing data.html#approach-3-imputation",
    "title": "Data Import and Preparation in R",
    "section": "Approach 3: Imputation",
    "text": "Approach 3: Imputation\nImputation means replacing missing values with educated guesses. The VIM package offers sophisticated methods:\nThis method finds the 5 most similar complete cases and uses their median (for numeric variables) or most common value (for categorical variables) to fill in the missing data.\nImportant: Missing data can seriously bias your results. If you have substantial missing data, consult with a statistician before deciding how to handle it.",
    "crumbs": [
      "Home",
      "Data Visualisation",
      "Data Import and Preparation in R"
    ]
  },
  {
    "objectID": "Data Visualisation/importing data.html#best-practices-for-missing-data",
    "href": "Data Visualisation/importing data.html#best-practices-for-missing-data",
    "title": "Data Import and Preparation in R",
    "section": "Best Practices for Missing Data",
    "text": "Best Practices for Missing Data\n\nInvestigate why data is missing - Is it random or systematic?\nDocument your decisions - Always note how you handled missing values\nCompare methods - Try multiple approaches and see how results differ\nReport missingness - Tell readers how much data was missing",
    "crumbs": [
      "Home",
      "Data Visualisation",
      "Data Import and Preparation in R"
    ]
  },
  {
    "objectID": "Data Visualisation/baseR and ggplot.html#geoms",
    "href": "Data Visualisation/baseR and ggplot.html#geoms",
    "title": "Introduction to ggplot2: The Grammar of Graphics",
    "section": "2.1 Geoms",
    "text": "2.1 Geoms\n“Geoms” (geometric objects) represent the actual marks on the plot—points, bars, lines, etc. We add these using functions starting with geom_. To create a scatterplot, we use geom_point().\nIn ggplot2, we chain these layers together using the + operator.\n\n\nCode\n```{r}\n# Add geometric points\nggplot(data = penguins, mapping = aes(x = flipper_length_mm, y = body_mass_g)) + \n  geom_point()\n```\n\n\n\n\n\n\n\n\n\nThe plot above shows a strong positive correlation: as flipper length increases, body mass tends to increase.\nWe can customize the appearance of these geoms. Parameters like color, size, and alpha (transparency) can be set directly inside the geom function. Transparency is particularly useful when you have many points overlapping each other.\n\n\nCode\n```{r}\n# Make points blue, larger, and semi-transparent\nggplot(data = penguins, mapping = aes(x = flipper_length_mm, y = body_mass_g)) + \n  geom_point(color = \"darkcyan\", alpha = 0.6, size = 3)\n```",
    "crumbs": [
      "Home",
      "Data Visualisation",
      "Introduction to ggplot2: The Grammar of Graphics"
    ]
  },
  {
    "objectID": "Data Visualisation/baseR and ggplot.html#smoothers-trend-lines",
    "href": "Data Visualisation/baseR and ggplot.html#smoothers-trend-lines",
    "title": "Introduction to ggplot2: The Grammar of Graphics",
    "section": "2.2 Smoothers (Trend Lines)",
    "text": "2.2 Smoothers (Trend Lines)\nTo visualize the trend more clearly, we can add a smoothing layer using geom_smooth(). We can control the method (linear vs. curved), the color, and whether to show the confidence interval. Here, we’ll use a linear model (method = \"lm\").\n\n\nCode\n```{r}\n# Add a line of best fit\nggplot(data = penguins, mapping = aes(x = flipper_length_mm, y = body_mass_g)) + \n  geom_point(color = \"darkcyan\", alpha = 0.6, size = 3) + \n  geom_smooth(method = \"lm\")\n```\n\n\n`geom_smooth()` using formula = 'y ~ x'",
    "crumbs": [
      "Home",
      "Data Visualisation",
      "Introduction to ggplot2: The Grammar of Graphics"
    ]
  },
  {
    "objectID": "Data Visualisation/baseR and ggplot.html#grouping-with-aesthetics",
    "href": "Data Visualisation/baseR and ggplot.html#grouping-with-aesthetics",
    "title": "Introduction to ggplot2: The Grammar of Graphics",
    "section": "2.3 Grouping with Aesthetics",
    "text": "2.3 Grouping with Aesthetics\nWhile the plot above is informative, it treats all penguins as one homogeneous group. We know our dataset contains different Species.\nWe can map variables to visual characteristics like color or shape inside the aes() function. This allows us to superimpose groups on a single graph. Let’s map species to color.\n\n\nCode\n```{r}\n# Map species to color\nggplot(data = penguins, mapping = aes(x = flipper_length_mm, y = body_mass_g, color = species)) + \n  geom_point(alpha = 0.6, size = 3) + \n  geom_smooth(method = \"lm\", se = FALSE, size = 1.5)\n```\n\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nNotice the difference:\n\ncolor = species is inside aes() because it maps data to a visual.\nse = FALSE was added to geom_smooth to remove the shaded confidence intervals for a cleaner look.\n\nWe can now see that Gentoo penguins are generally larger than Adelie or Chinstrap penguins.",
    "crumbs": [
      "Home",
      "Data Visualisation",
      "Introduction to ggplot2: The Grammar of Graphics"
    ]
  },
  {
    "objectID": "Data Visualisation/baseR and ggplot.html#scales",
    "href": "Data Visualisation/baseR and ggplot.html#scales",
    "title": "Introduction to ggplot2: The Grammar of Graphics",
    "section": "2.4 Scales",
    "text": "2.4 Scales\n“Scales” control how the data values are translated into visual properties (like specific colors or axis ticks). Scale functions always start with scale_.\nLet’s modify the X-axis breaks and manually define the colors for our species to be more distinct.\n\n\nCode\n```{r}\n# Customize axes and color palette\nggplot(data = penguins, mapping = aes(x = flipper_length_mm, y = body_mass_g, color = species)) + \n  geom_point(alpha = 0.6, size = 3) + \n  geom_smooth(method = \"lm\", se = FALSE, size = 1.5) + \n  scale_x_continuous(breaks = seq(170, 230, 10)) + \n  scale_y_continuous(breaks = seq(2500, 6500, 1000)) +\n  scale_color_manual(values = c(\"darkorange\", \"purple\", \"cyan4\"))\n```\n\n\n`geom_smooth()` using formula = 'y ~ x'",
    "crumbs": [
      "Home",
      "Data Visualisation",
      "Introduction to ggplot2: The Grammar of Graphics"
    ]
  },
  {
    "objectID": "Data Visualisation/baseR and ggplot.html#facets",
    "href": "Data Visualisation/baseR and ggplot.html#facets",
    "title": "Introduction to ggplot2: The Grammar of Graphics",
    "section": "2.5 Facets",
    "text": "2.5 Facets\nSometimes a plot becomes too cluttered with multiple groups. Faceting solves this by splitting the plot into sub-plots (small multiples) based on a categorical variable.\nLet’s see if the relationship holds true across the different “Weight Classes” we defined earlier.\n\n\nCode\n```{r}\n# Split the plot by weight class\nggplot(data = penguins, mapping = aes(x = flipper_length_mm, y = body_mass_g, color = species)) + \n  geom_point(alpha = 0.6) + \n  geom_smooth(method = \"lm\", se = FALSE) + \n  scale_color_manual(values = c(\"darkorange\", \"purple\", \"cyan4\")) + \n  facet_wrap(~weight_class)\n```\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nFaceting allows us to simultaneously view the data cut by different dimensions without overlapping points obscuring the view.",
    "crumbs": [
      "Home",
      "Data Visualisation",
      "Introduction to ggplot2: The Grammar of Graphics"
    ]
  },
  {
    "objectID": "Data Visualisation/baseR and ggplot.html#labels",
    "href": "Data Visualisation/baseR and ggplot.html#labels",
    "title": "Introduction to ggplot2: The Grammar of Graphics",
    "section": "2.6 Labels",
    "text": "2.6 Labels\nGood data visualization requires clear communication. The labs() function allows you to customize the title, subtitle, captions, and axis labels so the viewer doesn’t have to guess what “flipper_length_mm” means.\n\n\nCode\n```{r}\n# Add professional labels\nggplot(data = penguins, mapping = aes(x = flipper_length_mm, y = body_mass_g, color = species)) + \n  geom_point(alpha = 0.6) + \n  geom_smooth(method = \"lm\", se = FALSE) + \n  scale_color_manual(values = c(\"darkorange\", \"purple\", \"cyan4\")) + \n  facet_wrap(~weight_class) + \n  labs(\n    title = \"Penguin Size Characteristics\",\n    subtitle = \"Comparison of Flipper Length vs Body Mass by Species\",\n    caption = \"Source: Palmer Station LTER / palmerpenguins package\",\n    x = \"Flipper Length (mm)\",\n    y = \"Body Mass (g)\",\n    color = \"Penguin Species\"\n  )\n```\n\n\n`geom_smooth()` using formula = 'y ~ x'",
    "crumbs": [
      "Home",
      "Data Visualisation",
      "Introduction to ggplot2: The Grammar of Graphics"
    ]
  },
  {
    "objectID": "Data Visualisation/baseR and ggplot.html#themes",
    "href": "Data Visualisation/baseR and ggplot.html#themes",
    "title": "Introduction to ggplot2: The Grammar of Graphics",
    "section": "2.7 Themes",
    "text": "2.7 Themes\nFinally, we can polish the overall look using Themes. Theme functions (starting with theme_) control non-data elements like background colors, fonts, and grid lines. theme_minimal() is a popular choice for a clean, modern look.\n\n\nCode\n```{r}\n# Apply a minimal theme\nggplot(data = penguins, mapping = aes(x = flipper_length_mm, y = body_mass_g, color = species)) + \n  geom_point(alpha = 0.6) + \n  geom_smooth(method = \"lm\", se = FALSE) + \n  scale_color_manual(values = c(\"darkorange\", \"purple\", \"cyan4\")) + \n  facet_wrap(~weight_class) + \n  labs(\n    title = \"Penguin Size Characteristics\",\n    subtitle = \"Comparison of Flipper Length vs Body Mass by Species\",\n    caption = \"Source: Palmer Station LTER\",\n    x = \"Flipper Length (mm)\",\n    y = \"Body Mass (g)\",\n    color = \"Penguin Species\"\n  ) + \n  theme_minimal()\n```\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nFrom this final plot, we can conclude:\n\nThere is a positive linear relationship between flipper length and body mass.\nGentoo penguins (cyan) are distinctively larger than the other two species.\nThe relationship between size and mass appears consistent across species (similar slopes).",
    "crumbs": [
      "Home",
      "Data Visualisation",
      "Introduction to ggplot2: The Grammar of Graphics"
    ]
  },
  {
    "objectID": "Data Visualisation/baseR and ggplot.html#global-vs-local-mapping",
    "href": "Data Visualisation/baseR and ggplot.html#global-vs-local-mapping",
    "title": "Introduction to ggplot2: The Grammar of Graphics",
    "section": "3.1 Global vs Local Mapping",
    "text": "3.1 Global vs Local Mapping\nIn the previous examples, we defined our mapping aes(...) inside the main ggplot() function. This is a Global mapping—it applies to every layer (both points and lines).\nHowever, you can also place mappings inside a specific Geom. This creates a Local mapping that applies only to that layer.\nObserve the difference when we move color = species into the geom_point() function only:\n\n\nCode\n```{r}\n# Mapping color LOCALLY in geom_point only\nggplot(penguins, aes(x = flipper_length_mm, y = body_mass_g)) + \n  geom_point(aes(color = species), alpha = 0.6, size = 3) + \n  geom_smooth(method = \"lm\", se = FALSE, color = \"black\")\n```\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nBecause the color mapping was only inside geom_point, the geom_smooth did not “know” about the species groups. Consequently, it drew a single black trend line for the entire dataset, rather than one line per species.",
    "crumbs": [
      "Home",
      "Data Visualisation",
      "Introduction to ggplot2: The Grammar of Graphics"
    ]
  },
  {
    "objectID": "Data Visualisation/baseR and ggplot.html#graphs-as-objects",
    "href": "Data Visualisation/baseR and ggplot.html#graphs-as-objects",
    "title": "Introduction to ggplot2: The Grammar of Graphics",
    "section": "3.2 Graphs as Objects",
    "text": "3.2 Graphs as Objects\nIn R, a graph is just an object. You can save it to a variable, modify it later, and print it when ready. This is excellent for keeping your code clean or generating multiple versions of a plot programmatically.\n\n\nCode\n```{r}\n# 1. Create the base plot object\nmy_plot &lt;- ggplot(data = penguins, aes(x = flipper_length_mm, y = body_mass_g)) + \n  geom_point(aes(color = species))\n\n# 2. Add a theme and labels to the object\nfinal_plot &lt;- my_plot + \n  theme_light() + \n  labs(title = \"Saved Graph Object\")\n\n# 3. Print the final result\nfinal_plot\n```",
    "crumbs": [
      "Home",
      "Data Visualisation",
      "Introduction to ggplot2: The Grammar of Graphics"
    ]
  },
  {
    "objectID": "Data Visualisation/baseR and ggplot.html#geoms-1",
    "href": "Data Visualisation/baseR and ggplot.html#geoms-1",
    "title": "Introduction to ggplot2: The Grammar of Graphics",
    "section": "2.1 Geoms",
    "text": "2.1 Geoms\n“Geoms” (geometric objects) represent the actual marks on the plot—points, bars, lines, etc. We add these using functions starting with geom_. To create a scatterplot, we use geom_point().\nIn ggplot2, we chain these layers together using the + operator.\nquarto-executable-code-5450563D\n# Add geometric points\nggplot(data = penguins, mapping = aes(x = flipper_length_mm, y = body_mass_g)) + \n  geom_point()\nThe plot above shows a strong positive correlation: as flipper length increases, body mass tends to increase.\nWe can customize the appearance of these geoms. Parameters like color, size, and alpha (transparency) can be set directly inside the geom function. Transparency is particularly useful when you have many points overlapping each other.\nquarto-executable-code-5450563D\n# Make points blue, larger, and semi-transparent\nggplot(data = penguins, mapping = aes(x = flipper_length_mm, y = body_mass_g)) + \n  geom_point(color = \"darkcyan\", alpha = 0.6, size = 3)",
    "crumbs": [
      "Home",
      "Data Visualisation",
      "Introduction to ggplot2: The Grammar of Graphics"
    ]
  },
  {
    "objectID": "Data Visualisation/baseR and ggplot.html#smoothers-trend-lines-1",
    "href": "Data Visualisation/baseR and ggplot.html#smoothers-trend-lines-1",
    "title": "Introduction to ggplot2: The Grammar of Graphics",
    "section": "2.2 Smoothers (Trend Lines)",
    "text": "2.2 Smoothers (Trend Lines)\nTo visualize the trend more clearly, we can add a smoothing layer using geom_smooth(). We can control the method (linear vs. curved), the color, and whether to show the confidence interval. Here, we’ll use a linear model (method = \"lm\").\nquarto-executable-code-5450563D\n# Add a line of best fit\nggplot(data = penguins, mapping = aes(x = flipper_length_mm, y = body_mass_g)) + \n  geom_point(color = \"darkcyan\", alpha = 0.6, size = 3) + \n  geom_smooth(method = \"lm\")",
    "crumbs": [
      "Home",
      "Data Visualisation",
      "Introduction to ggplot2: The Grammar of Graphics"
    ]
  },
  {
    "objectID": "Data Visualisation/baseR and ggplot.html#grouping-with-aesthetics-1",
    "href": "Data Visualisation/baseR and ggplot.html#grouping-with-aesthetics-1",
    "title": "Introduction to ggplot2: The Grammar of Graphics",
    "section": "2.3 Grouping with Aesthetics",
    "text": "2.3 Grouping with Aesthetics\nWhile the plot above is informative, it treats all penguins as one homogeneous group. We know our dataset contains different Species.\nWe can map variables to visual characteristics like color or shape inside the aes() function. This allows us to superimpose groups on a single graph. Let’s map species to color.\nquarto-executable-code-5450563D\n# Map species to color\nggplot(data = penguins, mapping = aes(x = flipper_length_mm, y = body_mass_g, color = species)) + \n  geom_point(alpha = 0.6, size = 3) + \n  geom_smooth(method = \"lm\", se = FALSE, size = 1.5)\nNotice the difference:\n\ncolor = species is inside aes() because it maps data to a visual.\nse = FALSE was added to geom_smooth to remove the shaded confidence intervals for a cleaner look.\n\nWe can now see that Gentoo penguins are generally larger than Adelie or Chinstrap penguins.",
    "crumbs": [
      "Home",
      "Data Visualisation",
      "Introduction to ggplot2: The Grammar of Graphics"
    ]
  },
  {
    "objectID": "Data Visualisation/baseR and ggplot.html#scales-1",
    "href": "Data Visualisation/baseR and ggplot.html#scales-1",
    "title": "Introduction to ggplot2: The Grammar of Graphics",
    "section": "2.4 Scales",
    "text": "2.4 Scales\n“Scales” control how the data values are translated into visual properties (like specific colors or axis ticks). Scale functions always start with scale_.\nLet’s modify the X-axis breaks and manually define the colors for our species to be more distinct.\nquarto-executable-code-5450563D\n# Customize axes and color palette\nggplot(data = penguins, mapping = aes(x = flipper_length_mm, y = body_mass_g, color = species)) + \n  geom_point(alpha = 0.6, size = 3) + \n  geom_smooth(method = \"lm\", se = FALSE, size = 1.5) + \n  scale_x_continuous(breaks = seq(170, 230, 10)) + \n  scale_y_continuous(breaks = seq(2500, 6500, 1000)) +\n  scale_color_manual(values = c(\"darkorange\", \"purple\", \"cyan4\"))",
    "crumbs": [
      "Home",
      "Data Visualisation",
      "Introduction to ggplot2: The Grammar of Graphics"
    ]
  },
  {
    "objectID": "Data Visualisation/baseR and ggplot.html#facets-1",
    "href": "Data Visualisation/baseR and ggplot.html#facets-1",
    "title": "Introduction to ggplot2: The Grammar of Graphics",
    "section": "2.5 Facets",
    "text": "2.5 Facets\nSometimes a plot becomes too cluttered with multiple groups. Faceting solves this by splitting the plot into sub-plots (small multiples) based on a categorical variable.\nLet’s see if the relationship holds true across the different “Weight Classes” we defined earlier.\nquarto-executable-code-5450563D\n# Split the plot by weight class\nggplot(data = penguins, mapping = aes(x = flipper_length_mm, y = body_mass_g, color = species)) + \n  geom_point(alpha = 0.6) + \n  geom_smooth(method = \"lm\", se = FALSE) + \n  scale_color_manual(values = c(\"darkorange\", \"purple\", \"cyan4\")) + \n  facet_wrap(~weight_class)\nFaceting allows us to simultaneously view the data cut by different dimensions without overlapping points obscuring the view.",
    "crumbs": [
      "Home",
      "Data Visualisation",
      "Introduction to ggplot2: The Grammar of Graphics"
    ]
  },
  {
    "objectID": "Data Visualisation/baseR and ggplot.html#labels-1",
    "href": "Data Visualisation/baseR and ggplot.html#labels-1",
    "title": "Introduction to ggplot2: The Grammar of Graphics",
    "section": "2.6 Labels",
    "text": "2.6 Labels\nGood data visualization requires clear communication. The labs() function allows you to customize the title, subtitle, captions, and axis labels so the viewer doesn’t have to guess what “flipper_length_mm” means.\nquarto-executable-code-5450563D\n# Add professional labels\nggplot(data = penguins, mapping = aes(x = flipper_length_mm, y = body_mass_g, color = species)) + \n  geom_point(alpha = 0.6) + \n  geom_smooth(method = \"lm\", se = FALSE) + \n  scale_color_manual(values = c(\"darkorange\", \"purple\", \"cyan4\")) + \n  facet_wrap(~weight_class) + \n  labs(\n    title = \"Penguin Size Characteristics\",\n    subtitle = \"Comparison of Flipper Length vs Body Mass by Species\",\n    caption = \"Source: Palmer Station LTER / palmerpenguins package\",\n    x = \"Flipper Length (mm)\",\n    y = \"Body Mass (g)\",\n    color = \"Penguin Species\"\n  )",
    "crumbs": [
      "Home",
      "Data Visualisation",
      "Introduction to ggplot2: The Grammar of Graphics"
    ]
  },
  {
    "objectID": "Data Visualisation/baseR and ggplot.html#themes-1",
    "href": "Data Visualisation/baseR and ggplot.html#themes-1",
    "title": "Introduction to ggplot2: The Grammar of Graphics",
    "section": "2.7 Themes",
    "text": "2.7 Themes\nFinally, we can polish the overall look using Themes. Theme functions (starting with theme_) control non-data elements like background colors, fonts, and grid lines. theme_minimal() is a popular choice for a clean, modern look.\nquarto-executable-code-5450563D\n# Apply a minimal theme\nggplot(data = penguins, mapping = aes(x = flipper_length_mm, y = body_mass_g, color = species)) + \n  geom_point(alpha = 0.6) + \n  geom_smooth(method = \"lm\", se = FALSE) + \n  scale_color_manual(values = c(\"darkorange\", \"purple\", \"cyan4\")) + \n  facet_wrap(~weight_class) + \n  labs(\n    title = \"Penguin Size Characteristics\",\n    subtitle = \"Comparison of Flipper Length vs Body Mass by Species\",\n    caption = \"Source: Palmer Station LTER\",\n    x = \"Flipper Length (mm)\",\n    y = \"Body Mass (g)\",\n    color = \"Penguin Species\"\n  ) + \n  theme_minimal()\nFrom this final plot, we can conclude:\n\nThere is a positive linear relationship between flipper length and body mass.\nGentoo penguins (cyan) are distinctively larger than the other two species.\nThe relationship between size and mass appears consistent across species (similar slopes).",
    "crumbs": [
      "Home",
      "Data Visualisation",
      "Introduction to ggplot2: The Grammar of Graphics"
    ]
  },
  {
    "objectID": "Data Visualisation/baseR and ggplot.html#global-vs-local-mapping-1",
    "href": "Data Visualisation/baseR and ggplot.html#global-vs-local-mapping-1",
    "title": "Introduction to ggplot2: The Grammar of Graphics",
    "section": "3.1 Global vs Local Mapping",
    "text": "3.1 Global vs Local Mapping\nIn the previous examples, we defined our mapping aes(...) inside the main ggplot() function. This is a Global mapping—it applies to every layer (both points and lines).\nHowever, you can also place mappings inside a specific Geom. This creates a Local mapping that applies only to that layer.\nObserve the difference when we move color = species into the geom_point() function only:\nquarto-executable-code-5450563D\n# Mapping color LOCALLY in geom_point only\nggplot(penguins, aes(x = flipper_length_mm, y = body_mass_g)) + \n  geom_point(aes(color = species), alpha = 0.6, size = 3) + \n  geom_smooth(method = \"lm\", se = FALSE, color = \"black\")\nBecause the color mapping was only inside geom_point, the geom_smooth did not “know” about the species groups. Consequently, it drew a single black trend line for the entire dataset, rather than one line per species.",
    "crumbs": [
      "Home",
      "Data Visualisation",
      "Introduction to ggplot2: The Grammar of Graphics"
    ]
  },
  {
    "objectID": "Data Visualisation/baseR and ggplot.html#graphs-as-objects-1",
    "href": "Data Visualisation/baseR and ggplot.html#graphs-as-objects-1",
    "title": "Introduction to ggplot2: The Grammar of Graphics",
    "section": "3.2 Graphs as Objects",
    "text": "3.2 Graphs as Objects\nIn R, a graph is just an object. You can save it to a variable, modify it later, and print it when ready. This is excellent for keeping your code clean or generating multiple versions of a plot programmatically.\nquarto-executable-code-5450563D\n# 1. Create the base plot object\nmy_plot &lt;- ggplot(data = penguins, aes(x = flipper_length_mm, y = body_mass_g)) + \n  geom_point(aes(color = species))\n\n# 2. Add a theme and labels to the object\nfinal_plot &lt;- my_plot + \n  theme_light() + \n  labs(title = \"Saved Graph Object\")\n\n# 3. Print the final result\nfinal_plot",
    "crumbs": [
      "Home",
      "Data Visualisation",
      "Introduction to ggplot2: The Grammar of Graphics"
    ]
  },
  {
    "objectID": "Data Visualisation/customising graphs.html#numeric-axes",
    "href": "Data Visualisation/customising graphs.html#numeric-axes",
    "title": "Graph Customisation",
    "section": "Numeric Axes",
    "text": "Numeric Axes\nYou can control numeric axes using scale_x_continuous() and scale_y_continuous(). The most useful options are:\n\nbreaks: Where to place tick marks and labels\nlimits: The minimum and maximum values to display\n\n\n\nCode\n```{r}\n#| warning: false\n# Basic plot\nggplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm)) +\n  geom_point() +\n  scale_x_continuous(breaks = seq(30, 60, by = 5),\n                     limits = c(30, 60)) +\n  scale_y_continuous(breaks = seq(13, 22, by = 2),\n                     limits = c(13, 22)) +\n  labs(title = \"Penguin Bill Dimensions\",\n       x = \"Bill Length (mm)\",\n       y = \"Bill Depth (mm)\")\n```\n\n\n\n\n\n\n\n\n\nTip: The seq() function creates a sequence of numbers. For example, seq(30, 60, by = 5) creates: 30, 35, 40, 45, 50, 55, 60.",
    "crumbs": [
      "Home",
      "Data Visualisation",
      "Graph Customisation"
    ]
  },
  {
    "objectID": "Data Visualisation/customising graphs.html#formatting-numbers",
    "href": "Data Visualisation/customising graphs.html#formatting-numbers",
    "title": "Graph Customisation",
    "section": "Formatting Numbers",
    "text": "Formatting Numbers\nThe scales package provides helpful functions for formatting axis labels:\n\ncomma: Adds commas to large numbers (1000 becomes 1,000)\ndollar: Adds currency symbols\npercent: Converts decimals to percentages\n\n\n\nCode\n```{r}\n# Create sample data\nset.seed(42)\npopulation_data &lt;- data.frame(\n  city = paste(\"City\", 1:40),\n  population = rnorm(40, 250000, 80000),\n  employment_rate = runif(40, 0.55, 0.85),\n  median_income = rnorm(40, 65000, 15000)\n)\n\nggplot(population_data, aes(x = population, y = employment_rate)) +\n  geom_point(color = \"steelblue\", size = 3, alpha = 0.6) +\n  scale_x_continuous(labels = scales::comma) +\n  scale_y_continuous(labels = scales::percent) +\n  labs(title = \"Population vs Employment Rate\",\n       x = \"City Population\",\n       y = \"Employment Rate\")\n```",
    "crumbs": [
      "Home",
      "Data Visualisation",
      "Graph Customisation"
    ]
  },
  {
    "objectID": "Data Visualisation/customising graphs.html#categorical-axes",
    "href": "Data Visualisation/customising graphs.html#categorical-axes",
    "title": "Graph Customisation",
    "section": "Categorical Axes",
    "text": "Categorical Axes\nFor categorical variables, use scale_x_discrete() or scale_y_discrete():\n\n\nCode\n```{r}\nggplot(penguins, aes(x = species)) +\n  geom_bar(fill = \"coral\") +\n  scale_x_discrete(labels = c(\"Adélie\\nPenguin\", \n                              \"Chinstrap\\nPenguin\", \n                              \"Gentoo\\nPenguin\")) +\n  labs(title = \"Number of Penguins by Species\",\n       x = \"Species\",\n       y = \"Count\")\n```\n\n\n\n\n\n\n\n\n\nNote: \\n creates a line break in text labels.",
    "crumbs": [
      "Home",
      "Data Visualisation",
      "Graph Customisation"
    ]
  },
  {
    "objectID": "Data Visualisation/customising graphs.html#date-axes",
    "href": "Data Visualisation/customising graphs.html#date-axes",
    "title": "Graph Customisation",
    "section": "Date Axes",
    "text": "Date Axes\nWorking with dates requires scale_x_date() or scale_y_date():\n\n\nCode\n```{r}\n# Using the economics dataset\nggplot(economics, aes(x = date, y = unemploy / 1000)) +\n  geom_line(color = \"darkblue\", linewidth = 1) +\n  scale_x_date(date_breaks = \"10 years\",\n               date_labels = \"%Y\") +\n  labs(title = \"US Unemployment Over Time\",\n       x = \"Year\",\n       y = \"Unemployed (thousands)\")\n```\n\n\n\n\n\n\n\n\n\nCommon date format codes:\n\n\n\nCode\nMeaning\nExample\n\n\n\n\n%d\nDay of month\n01-31\n\n\n%m\nMonth number\n01-12\n\n\n%b\nAbbreviated month\nJan\n\n\n%B\nFull month\nJanuary\n\n\n%y\n2-digit year\n24\n\n\n%Y\n4-digit year\n2024",
    "crumbs": [
      "Home",
      "Data Visualisation",
      "Graph Customisation"
    ]
  },
  {
    "objectID": "Data Visualisation/customising graphs.html#setting-colors-manually",
    "href": "Data Visualisation/customising graphs.html#setting-colors-manually",
    "title": "Graph Customisation",
    "section": "Setting Colors Manually",
    "text": "Setting Colors Manually\nUse color for points and lines, and fill for bars and areas:\n\n\nCode\n```{r}\n#| warning: false\n# Single color\nggplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm)) +\n  geom_point(color = \"darkgreen\", size = 2) +\n  labs(title = \"Penguin Bill Measurements\")\n```\n\n\n\n\n\n\n\n\n\nTo assign specific colors to categories, use scale_color_manual() or scale_fill_manual():\n\n\nCode\n```{r}\n#| warning: false\nggplot(penguins, aes(x = species, fill = species)) +\n  geom_bar() +\n  scale_fill_manual(values = c(\"Adelie\" = \"darkorange\",\n                                \"Chinstrap\" = \"purple\",\n                                \"Gentoo\" = \"cyan4\")) +\n  labs(title = \"Penguin Species Count\",\n       x = \"Species\",\n       y = \"Count\",\n       fill = \"Species\")\n```",
    "crumbs": [
      "Home",
      "Data Visualisation",
      "Graph Customisation"
    ]
  },
  {
    "objectID": "Data Visualisation/customising graphs.html#using-color-palettes",
    "href": "Data Visualisation/customising graphs.html#using-color-palettes",
    "title": "Graph Customisation",
    "section": "Using Color Palettes",
    "text": "Using Color Palettes\nPre-designed color palettes often look more professional than colors you pick yourself.\n\nColorBrewer Palettes\nColorBrewer provides carefully designed color schemes:\n\n\nCode\n```{r}\n#| warning: false\nggplot(penguins, aes(x = species, fill = island)) +\n  geom_bar() +\n  scale_fill_brewer(palette = \"Set2\") +\n  labs(title = \"Penguin Species by Island\",\n       x = \"Species\",\n       y = \"Count\",\n       fill = \"Island\")\n```\n\n\n\n\n\n\n\n\n\n\n\nViridis Palettes\nViridis palettes are colorblind-friendly and print well in grayscale:\n\n\nCode\n```{r}\n#| warning: false\nggplot(penguins, aes(x = species, fill = island)) +\n  geom_bar() +\n  scale_fill_viridis_d() +\n  labs(title = \"Penguin Species by Island\",\n       x = \"Species\",\n       y = \"Count\",\n       fill = \"Island\")\n```\n\n\n\n\n\n\n\n\n\nUse _c for continuous variables (numbers) and _d for discrete variables (categories).",
    "crumbs": [
      "Home",
      "Data Visualisation",
      "Graph Customisation"
    ]
  },
  {
    "objectID": "Data Visualisation/customising graphs.html#point-shapes",
    "href": "Data Visualisation/customising graphs.html#point-shapes",
    "title": "Graph Customisation",
    "section": "Point Shapes",
    "text": "Point Shapes\nChange point shapes with the shape parameter:\n\n\nCode\n```{r}\n#| warning: false\nggplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm, \n                     shape = species)) +\n  geom_point(size = 3) +\n  labs(title = \"Bill Dimensions by Species\",\n       shape = \"Species\")\n```\n\n\n\n\n\n\n\n\n\nShapes 21-25 allow both fill and border colors:\n\n\nCode\n```{r}\n#| warning: false\nggplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm, \n                     fill = species)) +\n  geom_point(shape = 21, size = 3, color = \"black\") +\n  labs(title = \"Bill Dimensions by Species\")\n```",
    "crumbs": [
      "Home",
      "Data Visualisation",
      "Graph Customisation"
    ]
  },
  {
    "objectID": "Data Visualisation/customising graphs.html#line-types",
    "href": "Data Visualisation/customising graphs.html#line-types",
    "title": "Graph Customisation",
    "section": "Line Types",
    "text": "Line Types\nModify line appearance with linetype:\n\n\nCode\n```{r}\nggplot(economics, aes(x = date)) +\n  geom_line(aes(y = unemploy), linetype = \"solid\", color = \"blue\") +\n  geom_line(aes(y = unemploy * 1.1), linetype = \"dashed\", color = \"red\") +\n  labs(title = \"Unemployment Trends\",\n       y = \"Number Unemployed\")\n```",
    "crumbs": [
      "Home",
      "Data Visualisation",
      "Graph Customisation"
    ]
  },
  {
    "objectID": "Data Visualisation/customising graphs.html#adding-labels",
    "href": "Data Visualisation/customising graphs.html#adding-labels",
    "title": "Graph Customisation",
    "section": "Adding Labels",
    "text": "Adding Labels\nUse the labs() function to add or modify all text in your plot:\n\n\nCode\n```{r}\n#| warning: false\nggplot(penguins, aes(x = flipper_length_mm, y = body_mass_g, \n                     color = species)) +\n  geom_point(size = 2, alpha = 0.7) +\n  labs(\n    title = \"Penguin Body Mass vs Flipper Length\",\n    subtitle = \"Measurements from Palmer Station, Antarctica\",\n    caption = \"Data source: palmerpenguins package\",\n    x = \"Flipper Length (mm)\",\n    y = \"Body Mass (g)\",\n    color = \"Penguin Species\"\n  ) +\n  theme_minimal()\n```",
    "crumbs": [
      "Home",
      "Data Visualisation",
      "Graph Customisation"
    ]
  },
  {
    "objectID": "Data Visualisation/customising graphs.html#legend-position",
    "href": "Data Visualisation/customising graphs.html#legend-position",
    "title": "Graph Customisation",
    "section": "Legend Position",
    "text": "Legend Position\nControl legend placement with theme():\n\n\nCode\n```{r}\n#| warning: false\nggplot(penguins, aes(x = flipper_length_mm, y = body_mass_g, \n                     color = species)) +\n  geom_point(size = 2) +\n  labs(title = \"Penguin Measurements\",\n       color = \"Species\") +\n  theme_minimal() +\n  theme(legend.position = \"top\")\n```\n\n\n\n\n\n\n\n\n\nOptions for legend.position: - \"top\", \"bottom\", \"left\", \"right\" - c(x, y) for exact placement (e.g., c(0.9, 0.2) for bottom-right inside plot) - \"none\" to remove the legend",
    "crumbs": [
      "Home",
      "Data Visualisation",
      "Graph Customisation"
    ]
  },
  {
    "objectID": "Data Visualisation/customising graphs.html#text-annotations",
    "href": "Data Visualisation/customising graphs.html#text-annotations",
    "title": "Graph Customisation",
    "section": "Text Annotations",
    "text": "Text Annotations\nUse annotate() to add text anywhere on your plot:\n\n\nCode\n```{r}\n#| warning: false\npenguin_summary &lt;- penguins %&gt;%\n  group_by(species) %&gt;%\n  summarise(mean_mass = mean(body_mass_g, na.rm = TRUE))\n\nggplot(penguins, aes(x = species, y = body_mass_g)) +\n  geom_boxplot(fill = \"lightblue\") +\n  annotate(\"text\", x = 2, y = 6000, \n           label = \"Gentoo penguins are\\nthe heaviest species\",\n           color = \"darkred\", size = 4) +\n  labs(title = \"Body Mass Distribution by Species\",\n       x = \"Species\",\n       y = \"Body Mass (g)\")\n```",
    "crumbs": [
      "Home",
      "Data Visualisation",
      "Graph Customisation"
    ]
  },
  {
    "objectID": "Data Visualisation/customising graphs.html#adding-reference-lines",
    "href": "Data Visualisation/customising graphs.html#adding-reference-lines",
    "title": "Graph Customisation",
    "section": "Adding Reference Lines",
    "text": "Adding Reference Lines\nUse geom_hline() and geom_vline() for horizontal and vertical lines:\n\n\nCode\n```{r}\n#| warning: false\nmean_mass &lt;- mean(penguins$body_mass_g, na.rm = TRUE)\n\nggplot(penguins, aes(x = flipper_length_mm, y = body_mass_g, \n                     color = species)) +\n  geom_point(alpha = 0.6) +\n  geom_hline(yintercept = mean_mass, \n             linetype = \"dashed\", color = \"darkred\") +\n  annotate(\"text\", x = 175, y = mean_mass + 200,\n           label = \"Overall Mean\", color = \"darkred\") +\n  labs(title = \"Penguin Measurements with Mean Body Mass\",\n       x = \"Flipper Length (mm)\",\n       y = \"Body Mass (g)\")\n```",
    "crumbs": [
      "Home",
      "Data Visualisation",
      "Graph Customisation"
    ]
  },
  {
    "objectID": "Data Visualisation/customising graphs.html#highlighting-specific-groups",
    "href": "Data Visualisation/customising graphs.html#highlighting-specific-groups",
    "title": "Graph Customisation",
    "section": "Highlighting Specific Groups",
    "text": "Highlighting Specific Groups\nThe gghighlight package makes it easy to emphasize particular data:\n\n\nCode\n```{r}\n#| warning: false\nlibrary(gghighlight)\n\nggplot(penguins, aes(x = flipper_length_mm, y = body_mass_g)) +\n  geom_point(size = 2, color = \"coral\") +\n  gghighlight(species == \"Gentoo\") +\n  labs(title = \"Highlighting Gentoo Penguins\",\n       x = \"Flipper Length (mm)\",\n       y = \"Body Mass (g)\")\n```",
    "crumbs": [
      "Home",
      "Data Visualisation",
      "Graph Customisation"
    ]
  },
  {
    "objectID": "Data Visualisation/customising graphs.html#built-in-themes",
    "href": "Data Visualisation/customising graphs.html#built-in-themes",
    "title": "Graph Customisation",
    "section": "Built-in Themes",
    "text": "Built-in Themes\nggplot2 includes several pre-made themes:\n\n\nCode\n```{r}\n#| warning: false\np &lt;- ggplot(penguins, aes(x = species, fill = island)) +\n  geom_bar() +\n  labs(title = \"Penguins by Species and Island\")\n\n# Try different themes\np + theme_minimal()  # Clean and simple\n```\n\n\n\n\n\n\n\n\n\n\n\nCode\n```{r}\n#| warning: false\np + theme_classic()  # Traditional look\n```\n\n\n\n\n\n\n\n\n\n\n\nCode\n```{r}\n#| warning: false\np + theme_dark()  # Dark background\n```",
    "crumbs": [
      "Home",
      "Data Visualisation",
      "Graph Customisation"
    ]
  },
  {
    "objectID": "Data Visualisation/customising graphs.html#custom-themes-with-ggthemes",
    "href": "Data Visualisation/customising graphs.html#custom-themes-with-ggthemes",
    "title": "Graph Customisation",
    "section": "Custom Themes with ggthemes",
    "text": "Custom Themes with ggthemes\nThe ggthemes package offers many professional themes:\n\n\nCode\n```{r}\n#| warning: false\nlibrary(ggthemes)\n\nbase_plot &lt;- ggplot(penguins, aes(x = flipper_length_mm, \n                                   y = body_mass_g, \n                                   color = species)) +\n  geom_point(size = 2) +\n  labs(title = \"Penguin Physical Measurements\",\n       x = \"Flipper Length (mm)\",\n       y = \"Body Mass (g)\")\n\n# Economist style\nbase_plot + theme_economist() + scale_color_economist()\n```\n\n\n\n\n\n\n\n\n\n\n\nCode\n```{r}\n#| warning: false\n# FiveThirtyEight style\nbase_plot + theme_fivethirtyeight()\n```",
    "crumbs": [
      "Home",
      "Data Visualisation",
      "Graph Customisation"
    ]
  }
]