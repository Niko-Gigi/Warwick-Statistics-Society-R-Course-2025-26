[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Warwick Statistics Society R Course 2024-2025",
    "section": "",
    "text": "R is a very popular coding language, primarily used by statisticians around the world. As such, it is important for new statisticians (or those who will require substantial statistics in their degrees/jobs) to get to grips with the language. This website and the attached Github aim to cover the key steps from first lines of code after you have installed R, to how to fit linear models and perform Explanatory Data Analysis (EDA).\nThis Github was created for the Warwick Statistics Society’s R course. It accompanies the 2 core Warwick R modules: ST117 Introduction to Statistical Modelling and ST221 Linear Statistical Modelling. While I (Maria-Louiza) have compiled this Github, it builds off of the work by previous R course coordinators: Neel Shah, Mia Carla Chapman, and Viresh Shah.\nIf you find any corrections, or believe a section would benefit from more explanations, please do reach out and email me 1.\n\n\n\nQR code for website",
    "crumbs": [
      "Home",
      "Welcome"
    ]
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Using R",
    "section": "",
    "text": "Accessing R\nPlease ensure that you have access to R. This can be a local version on your computer (Warwick download link) or online.\nIf you have a local version, it is also worth downloading an IDE (integrated development envrionment). I personally use RStudio.\n\n\nCreating a new document\nThere are many possible files that you can create in R. The simplest is to create an R script. This allows you to write code, run code and produce output. You can also annotate your code through comments by writing # and then adding any relevant text.\nAlternatively, you can create an R Markdown file. This combines chunks of R code with normal text. Thus, you can create lovely reports that blend code output (e.g. figures and tables) with analysis. RStudio has created a detailed guide available here on how to use an R Markdown file.\n\n\nR Studio and R Markdown\nThe following are two cheatsheets produced by R Studio on using their software.\n(If the files are not loading, there also available on the GitHub under the Cheatsheets folder link.)"
  },
  {
    "objectID": "index.html#general-structure",
    "href": "index.html#general-structure",
    "title": "Warwick Statistics Society R Course 2024-2025",
    "section": "",
    "text": "Each section begins with a Welcome that indicates what will be covered by the section. There are then several subsections that cover theory and code examples.\nKey functions appear in purple text like this function(). Longer passages of code appear inside grey boxes with comments denoted using ###| and #. For some code examples, you are able to scroll left and right to see the entire code (this is typically for comments). The code can be hidden or shown by clicking on the triangle (\\(\\triangleright\\)). By default, all code examples are shown and any answers are hidden.\nThe entire code can be copied to the clipboard using the icon in the right corner. Please note that the ```{r} and ``` are used to create code chunks. These are not needed in an R Script or if the code is being copied into an already existing code chunk in an R Markdown or Quarto document.\nFinally, there will be several ‘Check you understanding’ subsections. Answers to these questions (and the code used to produce them) are available just below the questions. However, I strongly recommend you attempt to answer them before reviewing the solutions!\nThe sections of this github cover the following material:\n\n\nThis first section, titled “R-course - Introduction to R”, covers operations, variables, data types and data structures.\nThe second section, titled “R-course - Control structures and functions”, covers if, while and for loops. It also teaches you how to write your own functions.\nThe third section, titled “R-course - Random variables and Plotting”, covers how to generate a random number and how to plot various graphs using base R commands.\nThe fourth and fifth sections, titled “R-course - Linear modelling” and “R-course - Linear modelling assumptions” respectively, cover what a linear model is, how to fit a linear model on categorical and numerical data and how to ensure a linear model meets the necessary assumptions.\n\n\nThe necessary data for this github can be found in the Datasets folder. There is guidance in the relevant sections on how to load in data.\nPlease note that future sections aim to include: model selection; time series modelling; generalised linear modelling; exploratory data analysis; using the ggplot2 package to produce figures; and using the kableExtra and dplyr packages to produce tables. Time permitting, these will be created for the 2024/25 R course and aim to go alongside ST404 Applied Statistical Modelling and provide additional support for ST346 Generalised Linear Models."
  },
  {
    "objectID": "index.html#accessing-r",
    "href": "index.html#accessing-r",
    "title": "Warwick Statistics Society R Course 2024-2025",
    "section": "",
    "text": "Please ensure that you have access to R. This can be a local version on your computer (Warwick download link) or online.\nIf you have a local version, it is also worth downloading an IDE (integrated development envrionment). I personally use RStudio."
  },
  {
    "objectID": "index.html#creating-a-new-document",
    "href": "index.html#creating-a-new-document",
    "title": "Warwick Statistics Society R Course 2024-2025",
    "section": "",
    "text": "There are many possible files that you can create in R. The simplest is to create an R script. This allows you to write code, run code and produce output. You can also annotate your code through comments by writing # and then adding any relevant text.\nAlternatively, you can create an R Markdown file. This combines chunks of R code with normal text. Thus, you can create lovely reports that blend code output (e.g. figures and tables) with analysis. RStudio has created a detailed guide available here on how to use an R Markdown file."
  },
  {
    "objectID": "index.html#footnotes",
    "href": "index.html#footnotes",
    "title": "Warwick Statistics Society R Course 2024-2025",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nMy University of Warwick email is: maria-louiza.van-den-bergh@warwick.ac.uk.↩︎",
    "crumbs": [
      "Home",
      "Welcome"
    ]
  },
  {
    "objectID": "about.html#creating-a-new-document",
    "href": "about.html#creating-a-new-document",
    "title": "Using R",
    "section": "",
    "text": "There are many possible files that you can create in R. The simplest is to create an R script. This allows you to write code, run code and produce output. You can also annotate your code through comments by writing # and then adding any relevant text.\nAlternatively, you can create an R Markdown file. This combines chunks of R code with normal text. Thus, you can create lovely reports that blend code output (e.g. figures and tables) with analysis. RStudio has created a detailed guide available here on how to use an R Markdown file."
  },
  {
    "objectID": "Intro.html",
    "href": "Intro.html",
    "title": "Intro to R",
    "section": "",
    "text": "These pages will cover will introduce some key theory about how R operates and the basic building blocks of coding. It ends with generating plots using inbuilt R commands.\nThis section covers: :::{} * how R stores data/values (data types, data structures and variables), * how to perform operations (arithmetic, comparison and logical), * how to control the structure of your code (if, else, for and while), * how to write your own functions, * random numbers, and * plotting graphs."
  },
  {
    "objectID": "Intro.html#what-data-type-is-this-variable",
    "href": "Intro.html#what-data-type-is-this-variable",
    "title": "Intro to R",
    "section": "What data type is this variable?",
    "text": "What data type is this variable?\nWe can check what data type a variable is using class(). Alternatively, we can confirm if a variable is an integer, logical or a character using is.integer(), is.logical() and is.character() respectively.\n\n\nCode\n```{r}\n###| Character\ncharacter &lt;- \"a banana\"\n\nclass(character)\nis.character(character)\n\n###| Numeric v integer\nnumber &lt;- 5\ninteger &lt;- as.integer(5)\n\nclass(number)\nis.integer(number)\n\nclass(integer)\nis.integer(integer)\n\n###| Decimal value\ndecimal &lt;- 0.5\n\nclass(decimal)\nis.integer(decimal)\n\n###| Logical value\nis.logical(TRUE)\nis.logical(FALSE)\n```\n\n\n[1] \"character\"\n[1] TRUE\n[1] \"numeric\"\n[1] FALSE\n[1] \"integer\"\n[1] TRUE\n[1] \"numeric\"\n[1] FALSE\n[1] TRUE\n[1] TRUE"
  },
  {
    "objectID": "Intro.html#coercion-changing-data-type",
    "href": "Intro.html#coercion-changing-data-type",
    "title": "Intro to R",
    "section": "Coercion (changing data type)",
    "text": "Coercion (changing data type)\nWe can force a variable to switch data type using as.numeric(), as.logical(), as.character() and as.integer().\n\n\nCode\n```{r}\n###| Coercing a boolean variable\nas.numeric(TRUE)\nas.numeric(FALSE)\nas.character(TRUE)\nas.character(FALSE)\n```\n\n\n[1] 1\n[1] 0\n[1] \"TRUE\"\n[1] \"FALSE\"\n\n\n\n\nCode\n```{r}\n###| Coercing a character variable\nas.numeric(\"a\") # this will produce an error!\n```\n\n\nWarning: NAs introduced by coercion\n\n\n[1] NA\n\n\n\n\nCode\n```{r}\n###| Coercing a character variable\nas.character(\"a\")\n\n###| Coercing a numeric variable\nas.numeric(2) \nas.character(2)\n\n###| Coercing to a logic variable\nas.logical(1)\nas.logical(0)\n\nas.logical(\"TRUE\")\nas.logical(\"FALSE\")\n```\n\n\n[1] \"a\"\n[1] 2\n[1] \"2\"\n[1] TRUE\n[1] FALSE\n[1] TRUE\n[1] FALSE"
  },
  {
    "objectID": "Intro.html#check-your-understanding",
    "href": "Intro.html#check-your-understanding",
    "title": "Intro to R",
    "section": "Check your understanding",
    "text": "Check your understanding\nThe following will test your understanding of all of the main data structures in R.\nQuestion 1\n\n\nCreate a nums vector which contains the numbers from 50 to 100 inclusive. Now create a new vector, numsEven, which indicates which elements are even using nums.\n\n\n\n\nCode\n```{r}\n#| code-fold: true\n###| Answer\n\nnums &lt;- c(50:100)\nnums\n\nnumsEven &lt;- nums[seq(from = 1, to = 51, by = 2)]\nnumsEven\n```\n\n\n [1]  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68\n[20]  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87\n[39]  88  89  90  91  92  93  94  95  96  97  98  99 100\n [1]  50  52  54  56  58  60  62  64  66  68  70  72  74  76  78  80  82  84  86\n[20]  88  90  92  94  96  98 100\n\n\nQuestion 2 :::{} * Consider a gambler, with casino winnings from Monday to Friday defined as: + poker_vector &lt;- c(140,-50,20,-120,240) + roulette_vector &lt;- c(-24,-50,100,-350,10) + days_vector &lt;- c(“Monday”,“Tuesday”,“Wednesday”,“Thursday”,“Friday”) + names(poker_vector) &lt;- days_vector + names(roulette_vector) &lt;- days_vector * Calculate the following statistics and print total_daily and total_week: + daily earnings: total_daily + total poker winnings: total_poker + total roulette winnings: total_roulette + total winnings overall: total_week :::\n\n\nCode\n```{r}\n#| code-fold: true\n###| Answer\npoker_vector &lt;- c(140,-50,20,-120,240)\nroulette_vector &lt;- c(-24,-50,100,-350,10)\ndays_vector &lt;- c(\"Monday\",\"Tuesday\",\"Wednesday\",\"Thursday\",\"Friday\")\nnames(poker_vector) &lt;- days_vector\nnames(roulette_vector) &lt;- days_vector\n\ntotal_daily &lt;- poker_vector + roulette_vector\ntotal_poker &lt;- sum(poker_vector)\ntotal_roulette &lt;- sum(roulette_vector)\n\ntotal_week &lt;- total_poker + total_roulette\ntotal_week_2 &lt;- sum(total_daily)\n\ntotal_daily\ntotal_week\ntotal_week_2\n```\n\n\n   Monday   Tuesday Wednesday  Thursday    Friday \n      116      -100       120      -470       250 \n[1] -84\n[1] -84\n\n\nQuestion 3 :::{} * The sum of squares of the first ten natural numbers is \\(385\\). The square of the sum of the first ten natural numbers is \\(55^2 = 3025\\). Hence the difference between the sum of the squares of the first ten natural numbers and the square of the sum of the first ten natural numbers is \\(3025 - 385 = 2640\\). * Write R code to check this. * Find the difference between the sum of the squares of the first 100 natural numbers and the square of the sum of the first 100 natural numbers. :::\n\n\nCode\n```{r}\n#| code-fold: true\n###| Answer\nten &lt;- c(1:10)\nsum_of_squares_10 &lt;- sum(ten^2)\nsquare_of_sums_10 &lt;- sum(ten)^2\n\ndifference_10 &lt;- square_of_sums_10 - sum_of_squares_10\ndifference_10\n\nhundred &lt;- c(1:100)\nsum_of_squares &lt;- sum(hundred^2)\nsquare_of_sums &lt;- sum(hundred)^2\n\ndifference &lt;- square_of_sums - sum_of_squares\ndifference\n```\n\n\n[1] 2640\n[1] 25164150\n\n\nQuestion 4\n\n\nThe following vectors represent the box office numbers from the first three Star Wars movies. The first element for each vector corresponds to the US box office revenue and the second element represent the non-US box office revenue.\n\nNew_hope &lt;- c(460.998, 314.4)\nEmpire_strikes &lt;- c(290.475, 247.900)\nReturn_jedi &lt;- c(309.306, 165.8)\n\nConstruct a matrix, star_wars_matrix, with one row for each movie. The first column should be the US revenue and the second the non-US revenue.\nCalculate the US and non-US revenue.\nWhich movie generated the most revenue?\n\n\n\n\nCode\n```{r}\n#| code-fold: true\n###| Answer\nNew_hope &lt;- c(460.998, 314.4)\nEmpire_strikes &lt;- c(290.475, 247.900)\nReturn_jedi &lt;- c(309.306, 165.8)\n\nstar_wars_matrix &lt;- matrix(data = c(New_hope, Empire_strikes,Return_jedi), ncol = 2, nrow = 3, byrow = TRUE)\n\nUS_revenue &lt;- sum(star_wars_matrix[,1])\nnon_US_revenue &lt;- sum(star_wars_matrix[,2])\n\nUS_revenue\nnon_US_revenue\n```\n\n\n[1] 1060.779\n[1] 728.1\n\n\nQuestion 5\n\n\nDefine the following vectors\n\nplanets &lt;- c(“Mercury”,“Venus”,“Earth”,“Mars”,“Jupiter”,“Saturn”,“Uranus”,“Neptune”)\ntype &lt;- c(“Terrestrial planet”,“Terrestrial planet”,“Terrestrial planet”,“Terrestrial planet”,“Gas giant”,“Gas giant”,“Gas giant”,“Gas giant”)\ndiameter &lt;- c(0.382,0.949,1,0.532,11.209,9.449,4.007,3.883)\nrings &lt;- c(FALSE,FALSE,FALSE,FALSE,TRUE,TRUE,TRUE,TRUE)\n\nCreate a dataframe from these vectors\nThe dataframe is unclear. Add the units to the diameter header.\nPrint the information of the planets who have rings.\nAdd additional column to indicate which planet has humans.\n\n\n\n\nCode\n```{r}\n#| code-fold: true\n###| Answer\nplanets &lt;- c(\"Mercury\",\"Venus\",\"Earth\",\"Mars\",\"Jupiter\",\"Saturn\",\"Uranus\",\"Neptune\")\ntype &lt;- c(\"Terrestrial planet\",\"Terrestrial planet\",\"Terrestrial planet\",\"Terrestrial planet\",\"Gas giant\",\"Gas giant\",\"Gas giant\",\"Gas giant\")\ndiameter &lt;- c(0.382,0.949,1,0.532,11.209,9.449,4.007,3.883)\nrings &lt;- c(FALSE,FALSE,FALSE,FALSE,TRUE,TRUE,TRUE,TRUE)\n\ndf &lt;- data.frame(\"planets\" = planets,\n                 \"type\" = type,\n                 \"diameter\" = diameter,\n                 \"rings\" = rings)\n\nnames(df$diameter) &lt;- \"diameter, as a fraction of Earth's\"\n\ndf[which(df$type == \"Gas giant\"),]\n\ndf$humans &lt;- c(0,0,1,0,0,0,0,0)\n```\n\n\n  planets      type diameter rings\n5 Jupiter Gas giant   11.209  TRUE\n6  Saturn Gas giant    9.449  TRUE\n7  Uranus Gas giant    4.007  TRUE\n8 Neptune Gas giant    3.883  TRUE"
  },
  {
    "objectID": "Intro.html#vectors",
    "href": "Intro.html#vectors",
    "title": "Intro to R",
    "section": "Vectors",
    "text": "Vectors\nA vector is a one-dimensional sequence of data elements of the same type. We create a vector using c().\n\n\nCode\n```{r}\n###| Examples of vectors\nc(\"S\",\"T\",\"A\",\"T\",\"S\")\nc(1,2,3,4,5)\nc(1:5) # will output the same as before!\nc(1,2,\"A\")\n```\n\n\n[1] \"S\" \"T\" \"A\" \"T\" \"S\"\n[1] 1 2 3 4 5\n[1] 1 2 3 4 5\n[1] \"1\" \"2\" \"A\"\n\n\n\n\n\n\n\n\nNote\n\n\n\nAs we see in the last example, if we mix data types, the vector will default to storing all entries as characters!\n\n\n\nVectors: Arithmetic\nWe can apply arithmetic to vectors. We can multiple, add and subtract vectors.\n\n\nCode\n```{r}\n###| Vector arithmetic\nx &lt;- c(1,2,3)\n\nx + 3\nx * 3\nx * x\n```\n\n\n[1] 4 5 6\n[1] 3 6 9\n[1] 1 4 9\n\n\n\n\nVectors: Sequences and repetition\nWe can generate vectors using seq() and rep() to generate a sequence or repeat a value.\n\n\nCode\n```{r}\n###| Sequence 1\n\n# by will create a vector where each subsequent value is 0.1 larger than the previous\nseq(from = 0, to = 1, by = 0.1) \n\n# length.out will ensure 4 values are stored in the vector\nseq(from = 0, to = 1, length.out = 4) \n```\n\n\n [1] 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0\n[1] 0.0000000 0.3333333 0.6666667 1.0000000\n\n\n\n\nCode\n```{r}\n###| Sequence 2\n\nseq(from = 0, to = 10, by = 2.7) # note that 10 is not in this vector!\n\nseq(from = 0, to = 10, length.out = 4) \n```\n\n\n[1] 0.0 2.7 5.4 8.1\n[1]  0.000000  3.333333  6.666667 10.000000\n\n\n\n\nCode\n```{r}\n###| Repeat\nrep(1,6)\n\nrep(1:3,each = 2) # will repeat each value twice\n\nrep(1:3,2) # will repeat the entire 1:3 twice\n\nrep(1:3,length.out=6) # will repeat 1:3 until it reaches the length.out\n\nrep(1:3,length.out=5) # note that this is only 5 long and so only has one 3!\n```\n\n\n[1] 1 1 1 1 1 1\n[1] 1 1 2 2 3 3\n[1] 1 2 3 1 2 3\n[1] 1 2 3 1 2 3\n[1] 1 2 3 1 2\n\n\n\n\nVectors: Indexing\nYou can extract data from a vector if you know it’s index (for example, you can extract the 5th value of a vector) using [].\nWe can extract 1 element at a time (see the first example) or we can extract multiple elements at once using vectors (see the second and third examples). We can also extract using a variable (fourth example).\n\n\nCode\n```{r}\n###| Indexing\nx &lt;- c(1,2,3,4,5)\n\nx[3] # extracts the 3rd element\nx[1:3] # extracts elements 1, 2 and 3\nx[c(1,3,5)] # extracts elements 1, 3 and 5\n\n###| Indexing with a named vector\ny &lt;- c(2,4)\nx[y] # extracts elements 2 and 4\n```\n\n\n[1] 3\n[1] 1 2 3\n[1] 1 3 5\n[1] 2 4\n\n\nYou can change the values of a vector using indexes as well.\n\n\nCode\n```{r}\n###| Changing an element\nx &lt;- c(1,2,3,4,5)\n\nx[1] &lt;- 7\nx\n```\n\n\n[1] 7 2 3 4 5\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe number of replacing values must match the number of replaced values, otherwise there is an error (see next example)!\n\n\n\n\nCode\n```{r}\n###| Mismatch in replacement length\nx[2] &lt;- c(1,3)\n```\n\n\nWarning in x[2] &lt;- c(1, 3): number of items to replace is not a multiple of\nreplacement length\n\n\nCode\n```{r}\nx # only the 1st element is used to replace the 2nd value\n```\n\n\n[1] 7 1 3 4 5\n\n\nYou can also remove an element from a vector using [- ].\n\n\nCode\n```{r}\n###| Changing an element\nx &lt;- c(1,2,3,4,5)\nx[-1] \n```\n\n\n[1] 2 3 4 5\n\n\n\n\nVectors: Check your understanding\nTo practise sequences and repetition, do the following exercises.\n\n\nCreate a vector from 0 to 100.\nCreate a vector from 100 to 0.\nCreate a vector containing all strictly positive even numbers up to and including 100.\nCreate a vector containing 1 once, 2 twice and 3 thrice, in that order.\n\n\n\n\nCode\n```{r}\n#| code-fold: true\n\n###| Answers\nseq(from = 0, to = 100)\nseq(from = 100, to = 0)\nseq(from = 0, to = 100, by = 2)\n\nrep(1:3,1:3)\n```\n\n\n  [1]   0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n [19]  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n [37]  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n [55]  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n [73]  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n [91]  90  91  92  93  94  95  96  97  98  99 100\n  [1] 100  99  98  97  96  95  94  93  92  91  90  89  88  87  86  85  84  83\n [19]  82  81  80  79  78  77  76  75  74  73  72  71  70  69  68  67  66  65\n [37]  64  63  62  61  60  59  58  57  56  55  54  53  52  51  50  49  48  47\n [55]  46  45  44  43  42  41  40  39  38  37  36  35  34  33  32  31  30  29\n [73]  28  27  26  25  24  23  22  21  20  19  18  17  16  15  14  13  12  11\n [91]  10   9   8   7   6   5   4   3   2   1   0\n [1]   0   2   4   6   8  10  12  14  16  18  20  22  24  26  28  30  32  34  36\n[20]  38  40  42  44  46  48  50  52  54  56  58  60  62  64  66  68  70  72  74\n[39]  76  78  80  82  84  86  88  90  92  94  96  98 100\n[1] 1 2 2 3 3 3"
  },
  {
    "objectID": "Intro.html#lists",
    "href": "Intro.html#lists",
    "title": "Intro to R",
    "section": "Lists",
    "text": "Lists\nA list is a one-dimensional sequence of data of different types. Each element of a list can be of different dimensions and types.\nWe start a list using the list() command.\n\n\n\n\n\n\nNote\n\n\n\nIt is important to be careful with indexing for lists. As lists can contain multiple levels, we use [[]] for the first index and then [] for the second.\n\n\n\n\nCode\n```{r}\n###| Example list\nx &lt;- list(c(1,2,3),\n          100,\n          c(TRUE,FALSE,TRUE),\n          list(\"a\",\"b\",\"c\"))\n\nx[3] # Returns the 3rd element of the list\nx[[3]] # Returns the 3rd element of the list\nx[[3]][2] # Returns 2nd element of the 3rd element of the list\nx[3][2] # Empty!\n```\n\n\n[[1]]\n[1]  TRUE FALSE  TRUE\n\n[1]  TRUE FALSE  TRUE\n[1] FALSE\n[[1]]\nNULL\n\n\nWe can also replace elements in a list and and elements to a list using append().\n\n\nCode\n```{r}\n###| Replacing \nx &lt;- list(c(1,2,3),\n          100,\n          c(TRUE,FALSE,TRUE),\n          list(\"a\",\"b\",\"c\"))\n\nx[[2]] &lt;- c(27,29)\nx\n```\n\n\n[[1]]\n[1] 1 2 3\n\n[[2]]\n[1] 27 29\n\n[[3]]\n[1]  TRUE FALSE  TRUE\n\n[[4]]\n[[4]][[1]]\n[1] \"a\"\n\n[[4]][[2]]\n[1] \"b\"\n\n[[4]][[3]]\n[1] \"c\"\n\n\n\n\nCode\n```{r}\n###| Append\nappend(x, values = c(\"m\",\"n\"))\n```\n\n\n[[1]]\n[1] 1 2 3\n\n[[2]]\n[1] 27 29\n\n[[3]]\n[1]  TRUE FALSE  TRUE\n\n[[4]]\n[[4]][[1]]\n[1] \"a\"\n\n[[4]][[2]]\n[1] \"b\"\n\n[[4]][[3]]\n[1] \"c\"\n\n\n[[5]]\n[1] \"m\"\n\n[[6]]\n[1] \"n\"\n\n\nHowever, it is again important that we make these changes very carefully to avoid errors as there are 2 layers in indexing.\n\n\n\n\n\n\nNote\n\n\n\nWe can find the number of elements in the first level of the list using length() (i.e. how many different things are in the list). We can find the total number of elements within each first level element of the list using lengths().\n\n\n\n\nCode\n```{r}\n###| Lengths of a list\nx &lt;- list(c(1,2,3),\n          100,\n          c(TRUE,FALSE,TRUE),\n          list(\"a\",\"b\",\"c\"))\n\nlength(x)\nlengths(x)\n```\n\n\n[1] 4\n[1] 3 1 3 3"
  },
  {
    "objectID": "Intro.html#matrix",
    "href": "Intro.html#matrix",
    "title": "Intro to R",
    "section": "Matrix",
    "text": "Matrix\nA matrix is a 2 dimensional storage of data of the same type. We create a matrix using the matrix() command.\n\n\nCode\n```{r}\n###| Example matrix\nmatrix(data = c(1:9), nrow = 3, ncol = 3)\n```\n\n\n     [,1] [,2] [,3]\n[1,]    1    4    7\n[2,]    2    5    8\n[3,]    3    6    9\n\n\n\n\n\n\n\n\nNote\n\n\n\nBy default, a matrix is filled column-wise first, then row. Using byrow=TRUE inside the matrix() function will switch this to filling row-wise first.\n\n\n\n\nCode\n```{r}\n###| Example matrix\nmatrix(data = c(1:9), nrow = 3, ncol = 3, byrow=TRUE)\n```\n\n\n     [,1] [,2] [,3]\n[1,]    1    2    3\n[2,]    4    5    6\n[3,]    7    8    9\n\n\n\n\n\n\n\n\nNote\n\n\n\nIt is very important to ensure the number of columns and rows is correct!\n\n\n\n\nCode\n```{r}\n###| Errors in matrix \nmatrix(c(1,2,3), nrow = 1, ncol=2) \n```\n\n\nWarning in matrix(c(1, 2, 3), nrow = 1, ncol = 2): data length [3] is not a\nsub-multiple or multiple of the number of columns [2]\n\n\n     [,1] [,2]\n[1,]    1    2\n\n\nAs with vectors and lists, we can select only some elements of a matrix using indexing.\n\n\nCode\n```{r}\n###| Matrix indexing\nx &lt;- matrix(data = c(1:9), nrow = 3, ncol = 3)\n\nx[1,]\nx[1,2]\nx[6]\n```\n\n\n[1] 1 4 7\n[1] 4\n[1] 6\n\n\nAs with vectors, we can perform arithmetic operations of matrices, assuming that the dimensions are correct. Not that for matrix multiplication, we use %\\*%.\n\n\nCode\n```{r}\n###| Matrix arithmetic\nx &lt;- x &lt;- matrix(data = c(1:9), nrow = 3, ncol = 3)\n\nx + 3\nx * 3\nx * x     # entry wise multiplication\nx %*% x   # matrix multiplication\n```\n\n\n     [,1] [,2] [,3]\n[1,]    4    7   10\n[2,]    5    8   11\n[3,]    6    9   12\n     [,1] [,2] [,3]\n[1,]    3   12   21\n[2,]    6   15   24\n[3,]    9   18   27\n     [,1] [,2] [,3]\n[1,]    1   16   49\n[2,]    4   25   64\n[3,]    9   36   81\n     [,1] [,2] [,3]\n[1,]   30   66  102\n[2,]   36   81  126\n[3,]   42   96  150"
  },
  {
    "objectID": "Intro.html#dataframes",
    "href": "Intro.html#dataframes",
    "title": "Intro to R",
    "section": "Dataframes",
    "text": "Dataframes\nA dataframe is a 2 dimensional storage of data of different types. It is always filled vertically - i.e. the first list or vector specified is the first column of the dataframe.\nDataframes can have named columns, allowing us to have more control.\n\n\nCode\n```{r}\n###| Example dataframe\ndf &lt;- data.frame(name = c(\"Harry\",\"Ron\",\"Hermione\"),\n                 age = c(17,18,19),\n                 smoker = c(FALSE,TRUE,FALSE))\n\ndf\n\n###| Indexing a dataframe\n\ndf[3,2]\ndf[,\"smoker\"]\ndf[1:2,\"name\"]\ndf$smoker # we can use $ sign to pull named columns\n\n###| Named columns\n\ncolnames(df)\nnames(df)\n```\n\n\n      name age smoker\n1    Harry  17  FALSE\n2      Ron  18   TRUE\n3 Hermione  19  FALSE\n[1] 19\n[1] FALSE  TRUE FALSE\n[1] \"Harry\" \"Ron\"  \n[1] FALSE  TRUE FALSE\n[1] \"name\"   \"age\"    \"smoker\"\n[1] \"name\"   \"age\"    \"smoker\""
  },
  {
    "objectID": "Intro.html#array",
    "href": "Intro.html#array",
    "title": "Intro to R",
    "section": "Array",
    "text": "Array\nAn array is an n-dimensional storage of data of the same type.\n\n\nCode\n```{r}\n###| Example array\narray(data = c(1:6),dim = c(2,2,2))\narray(data = c(1:12),dim = c(2,3,2))\n```\n\n\n, , 1\n\n     [,1] [,2]\n[1,]    1    3\n[2,]    2    4\n\n, , 2\n\n     [,1] [,2]\n[1,]    5    1\n[2,]    6    2\n\n, , 1\n\n     [,1] [,2] [,3]\n[1,]    1    3    5\n[2,]    2    4    6\n\n, , 2\n\n     [,1] [,2] [,3]\n[1,]    7    9   11\n[2,]    8   10   12"
  },
  {
    "objectID": "Intro.html#check-your-understanding-1",
    "href": "Intro.html#check-your-understanding-1",
    "title": "Intro to R",
    "section": "Check your understanding",
    "text": "Check your understanding\nThe following are some extercises to test your understanding about operations.\n\n\nUse R to determine the area of a circle with diameter of 20cm.\n\nHint: pi is recognised in R.\n\nCalculate the cube root of 14 \\(\\times\\) 0.51.\n\nHint: think carefully about the order of operations.\n\nTest the following statement in R: Not (4 squared is greater than or equal to 15, or (the sum of 7 and 10 is less than 16)).\n\nHint: the output should be FALSE.\n\n\n\n(The code is hidden to give you a chance to practise. However, if you toggle the &gt;, example code will appear.)\n\n\nCode\n```{r}\n#| code-fold: true\n\n###| Answers\n(10^2)*pi\n(14 * 0.51)^(3)\n!( 4&lt;=15 | 7+10 &lt; 16)\n```\n\n\n[1] 314.1593\n[1] 363.9943\n[1] FALSE"
  },
  {
    "objectID": "Intro.html#arithmetic-operators",
    "href": "Intro.html#arithmetic-operators",
    "title": "Intro to R",
    "section": "Arithmetic operators",
    "text": "Arithmetic operators\nThe 4 base arithmetic operators are addition (+), subtraction (-), multiplication (*) and division (/). The following are some base examples of how these can be used.\n\n\nCode\n```{r}\n###| Addition\n3+10\n\n###| Subtraction\n6-2\n\n###| Multiplication\n5*15\n\n###| Division\n23/7\n```\n\n\n[1] 13\n[1] 4\n[1] 75\n[1] 3.285714\n\n\n\n\n\n\n\n\nNote\n\n\n\nIt is important to note that R follows the traditional BODMASS order of operations. As such, we can use brackets to control the order in which operations are performed.\n\n\n\n\nCode\n```{r}\n###| BODMASS\n(1+7)/2\n1 + 7/2\n3*5+2/3\n3*(5+2)/3\n```\n\n\n[1] 4\n[1] 4.5\n[1] 15.66667\n[1] 7\n\n\nWe can also do exponents (to the power of) using ^ or **, and we can find the modulo using %% and %/%\n\n\nCode\n```{r}\n###| Exponents \n5^2\n5**2\n\n4^(1/2)\n4**0.5\n```\n\n\n[1] 25\n[1] 25\n[1] 2\n[1] 2\n\n\n\n\nCode\n```{r}\n###| Modulo\n10 %% 2 # remainder of 10 divided by 2\n10 %% 4\n\n10 %/% 2 # how many times 2 goes into 10\n10 %/% 4\n```\n\n\n[1] 0\n[1] 2\n[1] 5\n[1] 2"
  },
  {
    "objectID": "Intro.html#comparison-operators",
    "href": "Intro.html#comparison-operators",
    "title": "Intro to R",
    "section": "Comparison operators",
    "text": "Comparison operators\nComparison operators compare 2 values to one another and will return TRUE or FALSE.\nThe 2 operators that can be used for any data type are equal to == and not equal to !=.\nWe can also compare two numbers using less than &lt;, less than or equal to &lt;=, greater than &gt;, and greater than or equal to &gt;=.\n\n\nCode\n```{r}\n###| Equal to\n\"a banana\" == \"a banana\"\n\"a banana\" == \"a fruit\"\n\n7 == 5\n5 == 5\n\n###| Not wqual to\n\"a banana\" != \"a banana\"\n\"a banana\" != \"a fruit\"\n\n7 != 5\n5 != 5\n```\n\n\n[1] TRUE\n[1] FALSE\n[1] FALSE\n[1] TRUE\n[1] FALSE\n[1] TRUE\n[1] TRUE\n[1] FALSE\n\n\n\n\nCode\n```{r}\n###| Less than\n5 &lt; 7 \n7 &lt; 5\n5 &lt; 5 # note that this will return FALSE!\n\n###| Greater than\n5 &gt; 7 \n7 &gt; 5\n5 &gt; 5 # note that this will return FALSE!\n\n###| Less than or equal to\n5 &lt;= 7 \n7 &lt;= 5\n5 &lt;= 5 # note that this will return TRUE!\n\n###| Greater than or equal to\n5 &gt;= 7 \n7 &gt;= 5\n5 &gt;= 5 # note that this will return TRUE!\n```\n\n\n[1] TRUE\n[1] FALSE\n[1] FALSE\n[1] FALSE\n[1] TRUE\n[1] FALSE\n[1] TRUE\n[1] FALSE\n[1] TRUE\n[1] FALSE\n[1] TRUE\n[1] TRUE"
  },
  {
    "objectID": "Intro.html#logical-operators",
    "href": "Intro.html#logical-operators",
    "title": "Intro to R",
    "section": "Logical operators",
    "text": "Logical operators\nLogical operators allow us to combine things or negate something.\nIf we want to find the negative, we use the ! operator. For example, we may want to say something is not true. we do this with !TRUE. Or we may want to check if 5 is not less than 7, !(5&lt;7).\n\n\nCode\n```{r}\n###| Negation of TRUE FALSE\nTRUE\n!(TRUE)\n\nFALSE\n!(TRUE)\n```\n\n\n[1] TRUE\n[1] FALSE\n[1] FALSE\n[1] FALSE\n\n\n\n\nCode\n```{r}\n###| Example of negation on relational operators\n5&lt;7\n!(5&lt;7)\n\n5==7\n!(5==7)\n```\n\n\n[1] TRUE\n[1] FALSE\n[1] FALSE\n[1] TRUE\n\n\nWe can also combine operators using AND, &. For example, we may want to check that 5&lt;7 and 10&lt;12. Alternatively, we may want to allow A or B to be true. We do this with |.\n\n\nCode\n```{r}\n###| And on TRUE FALSE\nTRUE & TRUE\nFALSE & FALSE\nTRUE & FALSE\n\n###| And on relational operators example\n(7&gt;5) & (10&lt;12)\n(7&lt;5) & (10&gt;12)\n(7&lt;5) & (10&lt;12)\n```\n\n\n[1] TRUE\n[1] FALSE\n[1] FALSE\n[1] TRUE\n[1] FALSE\n[1] FALSE\n\n\n\n\nCode\n```{r}\n###| OR on TRUE FALSE\nTRUE | TRUE\nFALSE | FALSE\nTRUE | FALSE\n\n###| OR on relational operators example\n(7&gt;5) | (10&lt;12)\n(7&lt;5) | (10&gt;12)\n(7&lt;5) | (10&lt;12)\n```\n\n\n[1] TRUE\n[1] FALSE\n[1] TRUE\n[1] TRUE\n[1] FALSE\n[1] TRUE"
  },
  {
    "objectID": "Intro.html#check-your-understanding-2",
    "href": "Intro.html#check-your-understanding-2",
    "title": "Intro to R",
    "section": "Check your understanding",
    "text": "Check your understanding\nThe following are some extercises to test your understanding about variables.\n\n\nDefine variables called velocity, time and acceleration with 5, 10 and 9.8 respectively. Calculate the displacement.\n\nHint: \\(s = ut+0.5at^2\\).\n\nDefine variables height and width of a rectangle with initial values 5 and 10. Calculate the area of the rectangle.\nExtension: given \\(f(x)=\\frac{1}{\\sqrt{2\\pi}}\\exp{(-\\frac{1}{2}x^2)}\\), find \\(f(5)\\).\n\nHint: look at sqrt() and exp().\n\n\n\n\n\nCode\n```{r}\n#| code-fold: true\n\n###| Answers\nvecolity &lt;- 5\ntime &lt;- 10\nacceleration &lt;- 9.8\ndisplacement &lt;- vecolity * time + 0.5 * acceleration * time^2\ndisplacement\n\nheight &lt;- 5\nwidth &lt;- 10\narea &lt;- height * width\narea\n\n###| Extension question\nx &lt;- 5\nf_x &lt;- 1/sqrt(2*pi)*exp(-0.5*x^2)\nf_x\n```\n\n\n[1] 540\n[1] 50\n[1] 1.48672e-06"
  },
  {
    "objectID": "Intro.html#check-your-understanding-3",
    "href": "Intro.html#check-your-understanding-3",
    "title": "Intro to R",
    "section": "Check your understanding",
    "text": "Check your understanding\nAnswer the following questions using if(), for() and while() loops.\n\n\nGiven a number, print “Positive” or “Negative” depending on if the number is positive or negative. If the number is 0, print both.\nGiven a vector, find the maximum and minimum value. Thus find out the range.\n\n\n\n\nCode\n```{r}\n#| code-fold: true\n###| Answers\nx=-1\nif (x &gt; 0) {\n  print(\"positive\")\n} else if (x &lt; 0) {\n  print(\"negative\")\n} else {print(\"both\")}\n```\n\n\n[1] \"negative\"\n\n\n\n\nCode\n```{r}\n#| code-fold: true\n###| Answers\nx &lt;- c(0,1,2,7,-5)\nn &lt;- length(x)\nmin &lt;- x[1]\nmax &lt;- x[1]\n\nfor(i in 1:n){\n  if (x[i] &lt; min) {\n    min &lt;- x[i]\n  }\n  if (x[i] &gt; max) {\n    max &lt;- x[i]\n  }\n}\n\nprint(paste(\"Range is\",max-min))\n```\n\n\n[1] \"Range is 12\""
  },
  {
    "objectID": "Linear Modelling.html",
    "href": "Linear Modelling.html",
    "title": "Linear Modelling",
    "section": "",
    "text": "Test"
  },
  {
    "objectID": "Intro.html#if-statements",
    "href": "Intro.html#if-statements",
    "title": "Intro to R",
    "section": "If statements",
    "text": "If statements\nThe code of code after an if statement is only exectued if the conditoin within the if statement is met.\nIf statements are of the following form:\n\n\nif (condition with TRUE/FALSE answer) {code to be executed if true}\n\n\nWe have several examples:\n\n\nCode\n```{r}\n###| Example of if()\nif (5&lt;7) {\n  print(\"Hello world.\")\n}\n\n###| Example of if() and else()\nif (5 &gt; 7) {\n  print(\"Not it.\")\n} else {\n    print(\"It.\")\n}\n```\n\n\n[1] \"Hello world.\"\n[1] \"It.\""
  },
  {
    "objectID": "Intro.html#for-loops",
    "href": "Intro.html#for-loops",
    "title": "Intro to R",
    "section": "For loops",
    "text": "For loops\nThe for loop allows code to be exectured repeatedly until a given iteration.\nIf follows the general structure:\n\n\nfor (variable in condition) {exectute code}\n\n\n\n\nCode\n```{r}\n###| For loop example\nfor (x in c(1:4)) {\n  print(x)\n}\n\n###| Nested loop\nfor (x in c(1:4)) {\n  print(x)\n  for (y in c(1:3)) {\n    print(y)\n  }\n}\n```\n\n\n[1] 1\n[1] 2\n[1] 3\n[1] 4\n[1] 1\n[1] 1\n[1] 2\n[1] 3\n[1] 2\n[1] 1\n[1] 2\n[1] 3\n[1] 3\n[1] 1\n[1] 2\n[1] 3\n[1] 4\n[1] 1\n[1] 2\n[1] 3"
  },
  {
    "objectID": "Intro.html#while-loops",
    "href": "Intro.html#while-loops",
    "title": "Intro to R",
    "section": "While loops",
    "text": "While loops\nWhile loop tests if a condition is true and will continue running the code until the condition is false.\nThey follow the general structure:\n\n\nwhile (condition) {execute code}\n\n\nIt is very important to avoid infinite loops!!\n\n\nCode\n```{r}\n###| While loop example\ni &lt;- 1\nwhile (i &lt;= 5){\n  print(i)\n  i &lt;- i + 1\n}\n```\n\n\n[1] 1\n[1] 2\n[1] 3\n[1] 4\n[1] 5"
  },
  {
    "objectID": "Intro.html#check-your-understanding-4",
    "href": "Intro.html#check-your-understanding-4",
    "title": "Intro to R",
    "section": "Check your understanding",
    "text": "Check your understanding\nWrite functions that do the following things:\n\n\nCreate a function which returns integer division of x by y and the remainder\nCreate a function which finds the area and circumference of a circle given a radius r.\nCreate a function that calculates the factorial of some number n.\n\nHint: make sure that n is an integer!\n\n\n\n\n\nCode\n```{r}\n#| code-fold: true\n###| Answer\n\nmodulus &lt;- function(x,y) {\n  remainder &lt;- x %% y\n  multiple &lt;- x %/% y\n  print(paste(\"x modulo y is\", multiple, \"with remainder\", remainder))\n}\n\nmodulus(6,3)\n```\n\n\n[1] \"x modulo y is 2 with remainder 0\"\n\n\n\n\nCode\n```{r}\n#| code-fold: true\n###| Answer\n\ncircle &lt;- function(r){\n  area &lt;- r^2 * pi\n  circumference &lt;- 2*r*pi\n  print(paste(\"Area is\",area, \"and the circumference is\",circumference))\n}\n\ncircle(5)\n```\n\n\n[1] \"Area is 78.5398163397448 and the circumference is 31.4159265358979\"\n\n\n\n\nCode\n```{r}\n#| code-fold: true\n###| Answer\n\nfactorial &lt;- function(x) {\n  \n  if (x%%1 == 0) {\n    \n    factorial &lt;- 1\n    \n    while (x &gt;= 1) {\n      factorial &lt;- factorial * x\n      x &lt;- x - 1\n    }\n    \n    print(factorial)\n  } else {\n    print(paste(x,\" is not a positive integer\"))\n  }\n}\n\nfactorial(2) \n```\n\n\n[1] 2"
  },
  {
    "objectID": "Intro.html#check-your-understanding-5",
    "href": "Intro.html#check-your-understanding-5",
    "title": "Intro to R",
    "section": "Check your understanding",
    "text": "Check your understanding\nWrite functions that do the following things:\n\n\nCreate a function which returns integer division of x by y and the remainder\nCreate a function which finds the area and circumference of a circle given a radius r.\nCreate a function that calculates the factorial of some number n.\n\nHint: make sure that n is an integer!\n\n\n\n\n\nCode\n```{r}\n#| code-fold: true\n###| Answer\n\nmodulus &lt;- function(x,y) {\n  remainder &lt;- x %% y\n  multiple &lt;- x %/% y\n  print(paste(\"x modulo y is\", multiple, \"with remainder\", remainder))\n}\n\nmodulus(6,3)\n```\n\n\n[1] \"x modulo y is 2 with remainder 0\"\n\n\n\n\nCode\n```{r}\n#| code-fold: true\n###| Answer\n\ncircle &lt;- function(r){\n  area &lt;- r^2 * pi\n  circumference &lt;- 2*r*pi\n  print(paste(\"Area is\",area, \"and the circumference is\",circumference))\n}\n\ncircle(5)\n```\n\n\n[1] \"Area is 78.5398163397448 and the circumference is 31.4159265358979\"\n\n\n\n\nCode\n```{r}\n#| code-fold: true\n###| Answer\n\nfactorial &lt;- function(x) {\n  \n  if (x%%1 == 0) {\n    \n    factorial &lt;- 1\n    \n    while (x &gt;= 1) {\n      factorial &lt;- factorial * x\n      x &lt;- x - 1\n    }\n    \n    print(factorial)\n  } else {\n    print(paste(x,\" is not a positive integer\"))\n  }\n}\n\nfactorial(2) \n```\n\n\n[1] 2"
  },
  {
    "objectID": "figures.html",
    "href": "figures.html",
    "title": "Figures",
    "section": "",
    "text": "In R, it is very easy to create scatter plots, line graphs, histograms and box plots. We will cover how to do all 4 using base R commands.\nOther sections will cover how to do these in other packages (namely ‘ggplot2’) to get more control over formatting.\n\n\nWe will start by generating a sample from a \\(\\text{Uniform}[0,1]\\) distribution and plotting a scatter plot.\n\n\nCode\n```{r}\n##| Generating a sample\nsample &lt;- runif(n = 100, min = 0, max = 1)\n\n###| Scatterplot\nplot(sample)\n```\n\n\n\n\n\n\n\n\n\nIf we sort the sample by size, we can create a plot that increases from left to right.\n\n\nCode\n```{r}\n###| Ordered sample scatter plot\nplot(sort(sample))\n```\n\n\n\n\n\n\n\n\n\nThe x and y labs are not clear. We should change these by adding in the xlab and ylab arguments. We should also add a title for clarity!\n\n\nCode\n```{r}\n###| x and y labels and title (called main) \nplot(sort(sample), xlab = \"Ordered index\", ylab = \"Sample\", main = \"Title\")\n```\n\n\n\n\n\n\n\n\n\nWe observe a linear relationship between the ordered samples. Let us test this by adding a line to this graph using ‘abline()’.\n\n\nCode\n```{r}\n###| Using abline\nplot(sort(sample), xlab = \"Ordered index\", ylab = \"Sample\", main = \"Title\")\nabline(a = 0,b=0.01)\n```\n\n\n\n\n\n\n\n\n\nIt is quite hard to see both the points and the line at the same time. We can change the aesthetics (colour, shape and size) to make this easier to see. Additional point shapes are available here.\n\n\nCode\n```{r}\n###| Aesthetics - colour and points\nplot(sort(sample), xlab = \"Ordered index\", ylab = \"Sample\", main = \"Title\", \n     col = \"red\", pch = 3)        # we start a new line for readability :)\nabline(a = 0,b=0.01, col = \"blue\")\n```\n\n\n\n\n\n\n\n\n\nSuppose we wanted to add additional lines, at the Sample = 0.5 and at the 50th index. We can add these using ‘abline()’. We can also distinguish them by changing colour, line thickness and line type. Additional details are available here.\n\n\nCode\n```{r}\n###| Aesthetics - line\nplot(sort(sample), xlab = \"Ordered index\", ylab = \"Sample\", main = \"Title\", \n     col = \"red\", pch = 3)\nabline(a = 0,b=0.01, col = \"blue\") \nabline(h=0.5, col = \"black\", lwd = 1, lty = 3) # Note that h here is a horizontal line at sample = 0.5\nabline(v=50, col = \"black\", lwd = 1, lty = 4)  # v here is a vertical line at index = 50\n```\n\n\n\n\n\n\n\n\n\n\n\n\nNow, we move to generating a line graph. We will generate a new sample, this time from a \\(\\text{Normal}(0,1)\\) distribution.\n\n\nCode\n```{r}\n###| Generate sample\nsample &lt;- rnorm(n = 30, mean = 0, sd = 1)\n\n###| Line graph\nplot(sample, type = \"l\")\n```\n\n\n\n\n\n\n\n\n\nSuppose we also want to show the points. We change the type from “l” to “b”.\n\n\nCode\n```{r}\n###| Line graph with points\nplot(sample, type = \"b\")\n```\n\n\n\n\n\n\n\n\n\nAgain, we can play with the aesthetics of these graphs.\n\n\nCode\n```{r}\n###| Line graph aesthetics\nplot(sample, type = \"l\", lwd = 2, lty = 3)\nplot(sample, type = \"b\", lwd = 1, lty = 5, pch = 17, col = 3)\n```\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSuppose we have another sample generated from a \\(\\text{Normal}(0,2)\\). We can show both lines on the same graph.\n\n\nCode\n```{r}\n###| For reproducibility\nset.seed(68)\n\n###| Generate 2 samples\nsample1 &lt;- rnorm(n=30, mean = 0, sd = 1)\nsample2 &lt;- rnorm(n=30, mean = 0, sd = 2)\n\n###| Line plot with multiple lines\nplot(sample1, type = \"l\")\nlines(sample2)\n```\n\n\n\n\n\n\n\n\n\nWe have something, but it appears the top is cut off the graph (this is beacuse we are adding sample 2 onto sample 1 and sample 2 has a larger range). We can change the y axis limits.\n\n\nCode\n```{r}\n###| Line plot with multiple lines with limits\nplot(sample1, type = \"l\", ylim = c(-4,4))\nlines(sample2)\n```\n\n\n\n\n\n\n\n\n\nWe should also change the colours for readability.\n\n\nCode\n```{r}\n###| Line plot with multiple lines with limits\nplot(sample1, type = \"l\", ylim = c(-4,4), col = \"blue\")\nlines(sample2)\n```\n\n\n\n\n\n\n\n\n\nWe can have different types of lines in the same graph as well.\n\n\nCode\n```{r}\n###| Line plot with multiple line types\nplot(sample1, type = \"l\", ylim = c(-4,4), col = \"blue\")\nlines(sample2, lty = 4, type = \"b\")\n```\n\n\n\n\n\n\n\n\n\n\n\n\nSuppose instead we want to look at the distribution of the sample, and test if it aligns with the distribution we expect. To do this, we will up the number of samples (200) and will look at the histogram graph.\n\n\nCode\n```{r}\n###| Sample\nsample &lt;- rnorm(n=200, mean = 0, sd =1)\n\n###| Histogram\nhist(sample)\n```\n\n\n\n\n\n\n\n\n\nIf we want to have the probability on the y axis instead, we need to change the freq argument to FALSE or we change the prob argument to TRUE.\n\n\nCode\n```{r}\n###| Density graph\nhist(sample, freq = FALSE)\nhist(sample, prob = TRUE)\n```\n\n\n\n\n\n\n\n\n\nThe widths of the boxes are quite large. We can change this with the breaks argument.\n\n\nCode\n```{r}\n###| Set number of breaks\nhist(sample, breaks = 10) # 10 boxes\nhist(sample, breaks = 20) # 20 boxes\n\n###| Different size boxes\nhist(sample, breaks = c(min(sample),-1.5,0,0.5,1,max(sample))) \n      # need min and max to ensure range works\n```\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe can also change the labels and add a title.\n\n\nCode\n```{r}\n###| Labels and title\nhist(sample, breaks = 20, xlab = \"Sample\", main = \"Title\")  \n```\n\n\n\n\n\n\n\n\n\nNow, lets compare this to the normal distribution. First, we can add the density curve of the sample.\n\n\nCode\n```{r}\nsample &lt;- rnorm(n = 1000, mean = 0, sd = 1) # Increasing sample count\n\n###| Density curve\nhist(sample, prob = TRUE)\nlines(density(sample))\n```\n\n\n\n\n\n\n\n\n\nWe can then add the normal distribution curve on top to allow comparison.\n\n\nCode\n```{r}\n###| Normal\nseq &lt;- seq(from = -3, to = 3, length = 1000)\nnorm_seq &lt;- dnorm(seq(from = -3, to = 3, length = 1000), mean = 0, sd = 1)\n\n###| Density curve\nhist(sample, prob = TRUE, ylim = c(0,max(norm_seq)))\nlines(density(sample))\nlines(seq,norm_seq, col = \"red\",lwd = 2)\n```\n\n\n\n\n\n\n\n\n\nThe sample distribution is very similar to the normal distribution curve (although the sample has 2 peaks rather than 1). However, it is confusing to have 2 lines without any labels. So, let us add a legend. Additional details appear here.\n\n\nCode\n```{r}\n###| Normal\nseq &lt;- seq(from = -3, to = 3, length = 1000)\nnorm_seq &lt;- dnorm(seq(from = -3, to = 3, length = 1000), mean = 0, sd = 1)\n\n###| Density curve\nhist(sample, prob = TRUE, ylim = c(0,max(norm_seq)))\nlines(density(sample))\nlines(seq,norm_seq, col = \"red\",lwd = 2)\nlegend(x = \"topright\", # position\n       legend = c(\"Sample curve\",\"Normal curve\"),\n       col = c(\"black\",\"red\"),\n       lwd = c(1,2))\n```\n\n\n\n\n\n\n\n\n\n\n\n\nFinally, we will consider box plots. We can plot the box plot of a single sample.\n\n\nCode\n```{r}\n###| Generating a sample\nsample &lt;- rnorm(n = 100, mean = 5, sd = 2)\n\n###| Boxplot\nboxplot(sample)\n```\n\n\n\n\n\n\n\n\n\nFor multiple boxplots, we can construct a data frame and plot accordingly.\n\n\nCode\n```{r}\n###| Data frame\ndf &lt;- data.frame(\"A\" = rnorm(n = 10, mean = 0, sd = 1),\n                 \"B\" = rnorm(n = 10, mean = 0, sd = 1),\n                 \"C\" = rnorm(n = 10, mean = 0, sd = 1))\n\n###| Box plot\nboxplot(df)\n```\n\n\n\n\n\n\n\n\n\nWe can add labels and titles.\n\n\nCode\n```{r}\n###| Box plot with labels\nboxplot(df, main = \"Title\", ylab = \"Sample values\", xlab = \"Categories\")\n```\n\n\n\n\n\n\n\n\n\n\n\n\nGenerate scatterplots, line graphs, histograms and box plots with samples from Poisson and Binomial distributions. Add legends and appropriate titles to each graph."
  },
  {
    "objectID": "figures.html#scatterplots",
    "href": "figures.html#scatterplots",
    "title": "Figures",
    "section": "",
    "text": "We will start by generating a sample from a \\(\\text{Uniform}[0,1]\\) distribution and plotting a scatter plot.\n\n\nCode\n```{r}\n##| Generating a sample\nsample &lt;- runif(n = 100, min = 0, max = 1)\n\n###| Scatterplot\nplot(sample)\n```\n\n\n\n\n\n\n\n\n\nIf we sort the sample by size, we can create a plot that increases from left to right.\n\n\nCode\n```{r}\n###| Ordered sample scatter plot\nplot(sort(sample))\n```\n\n\n\n\n\n\n\n\n\nThe x and y labs are not clear. We should change these by adding in the xlab and ylab arguments. We should also add a title for clarity!\n\n\nCode\n```{r}\n###| x and y labels and title (called main) \nplot(sort(sample), xlab = \"Ordered index\", ylab = \"Sample\", main = \"Title\")\n```\n\n\n\n\n\n\n\n\n\nWe observe a linear relationship between the ordered samples. Let us test this by adding a line to this graph using ‘abline()’.\n\n\nCode\n```{r}\n###| Using abline\nplot(sort(sample), xlab = \"Ordered index\", ylab = \"Sample\", main = \"Title\")\nabline(a = 0,b=0.01)\n```\n\n\n\n\n\n\n\n\n\nIt is quite hard to see both the points and the line at the same time. We can change the aesthetics (colour, shape and size) to make this easier to see. Additional point shapes are available here.\n\n\nCode\n```{r}\n###| Aesthetics - colour and points\nplot(sort(sample), xlab = \"Ordered index\", ylab = \"Sample\", main = \"Title\", \n     col = \"red\", pch = 3)        # we start a new line for readability :)\nabline(a = 0,b=0.01, col = \"blue\")\n```\n\n\n\n\n\n\n\n\n\nSuppose we wanted to add additional lines, at the Sample = 0.5 and at the 50th index. We can add these using ‘abline()’. We can also distinguish them by changing colour, line thickness and line type. Additional details are available here.\n\n\nCode\n```{r}\n###| Aesthetics - line\nplot(sort(sample), xlab = \"Ordered index\", ylab = \"Sample\", main = \"Title\", \n     col = \"red\", pch = 3)\nabline(a = 0,b=0.01, col = \"blue\") \nabline(h=0.5, col = \"black\", lwd = 1, lty = 3) # Note that h here is a horizontal line at sample = 0.5\nabline(v=50, col = \"black\", lwd = 1, lty = 4)  # v here is a vertical line at index = 50\n```"
  },
  {
    "objectID": "figures.html#line-graphs",
    "href": "figures.html#line-graphs",
    "title": "Figures",
    "section": "",
    "text": "Now, we move to generating a line graph. We will generate a new sample, this time from a \\(\\text{Normal}(0,1)\\) distribution.\n\n\nCode\n```{r}\n###| Generate sample\nsample &lt;- rnorm(n = 30, mean = 0, sd = 1)\n\n###| Line graph\nplot(sample, type = \"l\")\n```\n\n\n\n\n\n\n\n\n\nSuppose we also want to show the points. We change the type from “l” to “b”.\n\n\nCode\n```{r}\n###| Line graph with points\nplot(sample, type = \"b\")\n```\n\n\n\n\n\n\n\n\n\nAgain, we can play with the aesthetics of these graphs.\n\n\nCode\n```{r}\n###| Line graph aesthetics\nplot(sample, type = \"l\", lwd = 2, lty = 3)\nplot(sample, type = \"b\", lwd = 1, lty = 5, pch = 17, col = 3)\n```\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSuppose we have another sample generated from a \\(\\text{Normal}(0,2)\\). We can show both lines on the same graph.\n\n\nCode\n```{r}\n###| For reproducibility\nset.seed(68)\n\n###| Generate 2 samples\nsample1 &lt;- rnorm(n=30, mean = 0, sd = 1)\nsample2 &lt;- rnorm(n=30, mean = 0, sd = 2)\n\n###| Line plot with multiple lines\nplot(sample1, type = \"l\")\nlines(sample2)\n```\n\n\n\n\n\n\n\n\n\nWe have something, but it appears the top is cut off the graph (this is beacuse we are adding sample 2 onto sample 1 and sample 2 has a larger range). We can change the y axis limits.\n\n\nCode\n```{r}\n###| Line plot with multiple lines with limits\nplot(sample1, type = \"l\", ylim = c(-4,4))\nlines(sample2)\n```\n\n\n\n\n\n\n\n\n\nWe should also change the colours for readability.\n\n\nCode\n```{r}\n###| Line plot with multiple lines with limits\nplot(sample1, type = \"l\", ylim = c(-4,4), col = \"blue\")\nlines(sample2)\n```\n\n\n\n\n\n\n\n\n\nWe can have different types of lines in the same graph as well.\n\n\nCode\n```{r}\n###| Line plot with multiple line types\nplot(sample1, type = \"l\", ylim = c(-4,4), col = \"blue\")\nlines(sample2, lty = 4, type = \"b\")\n```"
  },
  {
    "objectID": "figures.html#histograms",
    "href": "figures.html#histograms",
    "title": "Figures",
    "section": "",
    "text": "Suppose instead we want to look at the distribution of the sample, and test if it aligns with the distribution we expect. To do this, we will up the number of samples (200) and will look at the histogram graph.\n\n\nCode\n```{r}\n###| Sample\nsample &lt;- rnorm(n=200, mean = 0, sd =1)\n\n###| Histogram\nhist(sample)\n```\n\n\n\n\n\n\n\n\n\nIf we want to have the probability on the y axis instead, we need to change the freq argument to FALSE or we change the prob argument to TRUE.\n\n\nCode\n```{r}\n###| Density graph\nhist(sample, freq = FALSE)\nhist(sample, prob = TRUE)\n```\n\n\n\n\n\n\n\n\n\nThe widths of the boxes are quite large. We can change this with the breaks argument.\n\n\nCode\n```{r}\n###| Set number of breaks\nhist(sample, breaks = 10) # 10 boxes\nhist(sample, breaks = 20) # 20 boxes\n\n###| Different size boxes\nhist(sample, breaks = c(min(sample),-1.5,0,0.5,1,max(sample))) \n      # need min and max to ensure range works\n```\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe can also change the labels and add a title.\n\n\nCode\n```{r}\n###| Labels and title\nhist(sample, breaks = 20, xlab = \"Sample\", main = \"Title\")  \n```\n\n\n\n\n\n\n\n\n\nNow, lets compare this to the normal distribution. First, we can add the density curve of the sample.\n\n\nCode\n```{r}\nsample &lt;- rnorm(n = 1000, mean = 0, sd = 1) # Increasing sample count\n\n###| Density curve\nhist(sample, prob = TRUE)\nlines(density(sample))\n```\n\n\n\n\n\n\n\n\n\nWe can then add the normal distribution curve on top to allow comparison.\n\n\nCode\n```{r}\n###| Normal\nseq &lt;- seq(from = -3, to = 3, length = 1000)\nnorm_seq &lt;- dnorm(seq(from = -3, to = 3, length = 1000), mean = 0, sd = 1)\n\n###| Density curve\nhist(sample, prob = TRUE, ylim = c(0,max(norm_seq)))\nlines(density(sample))\nlines(seq,norm_seq, col = \"red\",lwd = 2)\n```\n\n\n\n\n\n\n\n\n\nThe sample distribution is very similar to the normal distribution curve (although the sample has 2 peaks rather than 1). However, it is confusing to have 2 lines without any labels. So, let us add a legend. Additional details appear here.\n\n\nCode\n```{r}\n###| Normal\nseq &lt;- seq(from = -3, to = 3, length = 1000)\nnorm_seq &lt;- dnorm(seq(from = -3, to = 3, length = 1000), mean = 0, sd = 1)\n\n###| Density curve\nhist(sample, prob = TRUE, ylim = c(0,max(norm_seq)))\nlines(density(sample))\nlines(seq,norm_seq, col = \"red\",lwd = 2)\nlegend(x = \"topright\", # position\n       legend = c(\"Sample curve\",\"Normal curve\"),\n       col = c(\"black\",\"red\"),\n       lwd = c(1,2))\n```"
  },
  {
    "objectID": "figures.html#box-plots",
    "href": "figures.html#box-plots",
    "title": "Figures",
    "section": "",
    "text": "Finally, we will consider box plots. We can plot the box plot of a single sample.\n\n\nCode\n```{r}\n###| Generating a sample\nsample &lt;- rnorm(n = 100, mean = 5, sd = 2)\n\n###| Boxplot\nboxplot(sample)\n```\n\n\n\n\n\n\n\n\n\nFor multiple boxplots, we can construct a data frame and plot accordingly.\n\n\nCode\n```{r}\n###| Data frame\ndf &lt;- data.frame(\"A\" = rnorm(n = 10, mean = 0, sd = 1),\n                 \"B\" = rnorm(n = 10, mean = 0, sd = 1),\n                 \"C\" = rnorm(n = 10, mean = 0, sd = 1))\n\n###| Box plot\nboxplot(df)\n```\n\n\n\n\n\n\n\n\n\nWe can add labels and titles.\n\n\nCode\n```{r}\n###| Box plot with labels\nboxplot(df, main = \"Title\", ylab = \"Sample values\", xlab = \"Categories\")\n```"
  },
  {
    "objectID": "figures.html#check-your-understanding",
    "href": "figures.html#check-your-understanding",
    "title": "Figures",
    "section": "",
    "text": "Generate scatterplots, line graphs, histograms and box plots with samples from Poisson and Binomial distributions. Add legends and appropriate titles to each graph."
  },
  {
    "objectID": "Introduction to R/Random numbers.html",
    "href": "Introduction to R/Random numbers.html",
    "title": "Random numbers",
    "section": "",
    "text": "Inbuilt into R, there are many functions focused on statistical distributions. These are all stored in the ‘stats’ package, which is loaded in by default in R. However, for practise, (and to ensure everything will work), we will load in the package directly.\n\n\nCode\n```{r}\n###| Loading in stats package\nlibrary(stats)\n```\n\n\nWe will begin by looking at generating a uniform number before doing on to look at continuous and discrete random variables.\n\nRandom uniform numbers\nTo generate a random number, we are going to use the uniform distribution. Let \\(X\\sim \\text{Uniform}[a,b]\\). Then, the probability mass function of X is\n\\[\nf(x) = \\begin{cases}\n\\frac{1}{b-a} & \\text{for } a\\leq x\\leq b, \\\\\n0 & \\text{for } x&lt;a \\text{ or } x&gt;b\n\\end{cases}\n\\]\nWe are going to use the inbuilt R functions to generate a random number, x, in the interval \\([a,b]\\) and find the probability we generated x.\nFor simplicity, we will demonstrate this with 2 uniform random variables: \\(X\\sim \\text{Uniform}[0,1]\\) and \\(Y\\sim \\text{Uniform}[1,5]\\).\n\n\nCode\n```{r}\n###| Generate a random number, x\nx &lt;- runif(n = 1, min = 0, max = 1)\nx\n\n###| Probability we generated x\nprob_x &lt;- punif(x, min = 0, max = 1)\nprob_x\n\n###| Generate a random number, y\ny &lt;- runif(n = 1, min = 1, max = 5)\ny\n\n###| Probability we generated y\nprob_y &lt;- punif(y, min = 1, max = 5)\nprob_y\n```\n\n\n[1] 0.9805846\n[1] 0.9805846\n[1] 3.822689\n[1] 0.7056722\n\n\nWe can also find the value, \\(x\\), that corresponds to the probability \\(P(X\\leq x) = a\\).\n\n\nCode\n```{r}\n###| a = 0.5, X ~ Uniform[0,1]\nqunif(0.5, min = 0, max = 1)\n\n###| a = 0.5, X ~ Uniform[0,5]\nqunif(0.5, min = 0, max = 5)\n\n###| a = 0.75, X ~ Uniform[0,5]\nqunif(0.75, min = 0, max = 5)\n```\n\n\n[1] 0.5\n[1] 2.5\n[1] 3.75\n\n\nWe can also find the density of values \\(x\\) and \\(y\\).\n\n\nCode\n```{r}\n###| Density of x, X ~ Uniform[0,1]\nx &lt;- runif(n = 1, min = 0, max = 1)\ndunif(x, min = 0,max = 1)\n\n###| Density of y, Y ~ Uniform[1,5]\ny &lt;- runif(n = 1, min = 1, max = 5)\ndunif(y, min = 1,max = 5)\n```\n\n\n[1] 1\n[1] 0.25\n\n\nUp until now, we have only generated 1 number at a time. However, we can generate several numbers at once by changing the $n = $ argument. However, this only works for the ‘runif()’ function!\n\n\nCode\n```{r}\n###| Multiple values at once\nrunif(n = 5, min = 0, max = 1)\nrunif(n = 3, min = -1, max = 1)\n```\n\n\n[1] 0.3304437 0.5607250 0.5797799 0.9419879 0.6397729\n[1] -0.6708021 -0.1787737 -0.1669490\n\n\n\n\nBinomial distribution\nNow, suppose we want to sample from a binomial distribution, i.e. we want to generate a random number so that the probability \\(X=x\\) is the same as the probability \\(Y=x\\), where \\(Y \\sim \\text{Binomial}(m,p)\\). We do this using ‘rbinom()’, ‘dbinom()’, ‘pbinom()’ and ‘qbinom()’. Note that \\(n\\) refers to the number of samples while size refers to the number of trials!\n\n\nCode\n```{r}\n###| Generate a random value from X ~ Binom(m = 5, p = 0.2)\nx &lt;- rbinom(n=1, size = 5, prob = 0.2)\nx\n\n###| Probability generated x\nprob_x &lt;- pbinom(x, size = 5, prob = 0.2)\nprob_x\n\n###| f(x), density of x\ndensity_x &lt;- dbinom(x, size = 5, prob = 0.2)\ndensity_x\n\n###| Quantile of 0.75\nqbinom(p = 0.75, size = 5, prob = 0.2)\n```\n\n\n[1] 2\n[1] 0.94208\n[1] 0.2048\n[1] 2\n\n\n\n\nCheck your understanding - Normal and Poisson distribution\nIn the above sections, we have gone over how to sample from Uniform and Binomial distribution. To check your understanding, try the following:\n\n\nSample 5 values from a Poisson distribution with rate \\(\\lambda = 5\\) and find the probability and density of each value. Return this as a dataframe.\n\nHint: type ?rpois into the command line or into the help section.\n\nSample 5 values from a Normal distribution with mean 0 and variance 4. Find the density of each value, to 3 significant figures.\n\nHint: type ?rnorm and ?round into the command line or into the help section.\n\n\n\n\n\nCode\n```{r}\n#| code-fold: true\n###| Generate and store 5 values from Poisson\nsample &lt;- rpois(n = 5, lambda = 5)\nsample\n\n###| Find probability, density and quantile\ndf &lt;- data.frame(\"sample\" = sample,\n                 \"prob\" = rep(NA,length(sample)),\n                 \"density\" = rep(NA,length(sample)))\n\n\nfor (i in 1:length(sample)) {\n  df$prob[i] &lt;- ppois(df$sample[i], lambda = 5)\n  df$density[i] &lt;- dpois(df$sample[i], lambda = 5)\n}\n\ndf\n```\n\n\n[1] 10  8  3  2  4\n  sample      prob    density\n1     10 0.9863047 0.01813279\n2      8 0.9319064 0.06527804\n3      3 0.2650259 0.14037390\n4      2 0.1246520 0.08422434\n5      4 0.4404933 0.17546737\n\n\n\n\nCode\n```{r}\n#| code-fold: true\n###| Generate Normal distribution\nnorm &lt;- rnorm(n = 5, mean = 0, sd = 2)\nnorm\n\n###| Find density of each variable\nfor (i in 1:length(norm)){\n  print(paste(round(norm[i],3),\" has density \", round(dnorm(norm[i],mean = 0, sd = 2),3)))\n}\n\n# Alternatively, we can do this in one step without the loop as dnorm() \n# allows vector input\ndnorm(norm, mean=0,sd=2) \n```\n\n\n[1] -0.33344264 -0.08099315 -1.41945430  0.80238623  0.03565988\n[1] \"-0.333  has density  0.197\"\n[1] \"-0.081  has density  0.199\"\n[1] \"-1.419  has density  0.155\"\n[1] \"0.802  has density  0.184\"\n[1] \"0.036  has density  0.199\"\n[1] 0.1967181 0.1993076 0.1550602 0.1840471 0.1994394",
    "crumbs": [
      "Home",
      "Introduction to R",
      "Random numbers"
    ]
  },
  {
    "objectID": "Introduction to R/figures.html",
    "href": "Introduction to R/figures.html",
    "title": "Figures",
    "section": "",
    "text": "In R, it is very easy to create scatter plots, line graphs, histograms and box plots. We will cover how to do all 4 using base R commands.\nOther sections will cover how to do these in other packages (namely ‘ggplot2’) to get more control over formatting.\n\nScatterplots\nWe will start by generating a sample from a \\(\\text{Uniform}[0,1]\\) distribution and plotting a scatter plot.\n\n\nCode\n```{r}\n##| Generating a sample\nsample &lt;- runif(n = 100, min = 0, max = 1)\n\n###| Scatterplot\nplot(sample)\n```\n\n\n\n\n\n\n\n\n\nIf we sort the sample by size, we can create a plot that increases from left to right.\n\n\nCode\n```{r}\n###| Ordered sample scatter plot\nplot(sort(sample))\n```\n\n\n\n\n\n\n\n\n\nThe x and y labs are not clear. We should change these by adding in the xlab and ylab arguments. We should also add a title for clarity!\n\n\nCode\n```{r}\n###| x and y labels and title (called main) \nplot(sort(sample), xlab = \"Ordered index\", ylab = \"Sample\", main = \"Title\")\n```\n\n\n\n\n\n\n\n\n\nWe observe a linear relationship between the ordered samples. Let us test this by adding a line to this graph using ‘abline()’.\n\n\nCode\n```{r}\n###| Using abline\nplot(sort(sample), xlab = \"Ordered index\", ylab = \"Sample\", main = \"Title\")\nabline(a = 0,b=0.01)\n```\n\n\n\n\n\n\n\n\n\nIt is quite hard to see both the points and the line at the same time. We can change the aesthetics (colour, shape and size) to make this easier to see. Additional point shapes are available here.\n\n\nCode\n```{r}\n###| Aesthetics - colour and points\nplot(sort(sample), xlab = \"Ordered index\", ylab = \"Sample\", main = \"Title\", \n     col = \"red\", pch = 3)        # we start a new line for readability :)\nabline(a = 0,b=0.01, col = \"blue\")\n```\n\n\n\n\n\n\n\n\n\nSuppose we wanted to add additional lines, at the Sample = 0.5 and at the 50th index. We can add these using ‘abline()’. We can also distinguish them by changing colour, line thickness and line type. Additional details are available here.\n\n\nCode\n```{r}\n###| Aesthetics - line\nplot(sort(sample), xlab = \"Ordered index\", ylab = \"Sample\", main = \"Title\", \n     col = \"red\", pch = 3)\nabline(a = 0,b=0.01, col = \"blue\") \nabline(h=0.5, col = \"black\", lwd = 1, lty = 3) # Note that h here is a horizontal line at sample = 0.5\nabline(v=50, col = \"black\", lwd = 1, lty = 4)  # v here is a vertical line at index = 50\n```\n\n\n\n\n\n\n\n\n\n\n\nLine graphs\nNow, we move to generating a line graph. We will generate a new sample, this time from a \\(\\text{Normal}(0,1)\\) distribution.\n\n\nCode\n```{r}\n###| Generate sample\nsample &lt;- rnorm(n = 30, mean = 0, sd = 1)\n\n###| Line graph\nplot(sample, type = \"l\")\n```\n\n\n\n\n\n\n\n\n\nSuppose we also want to show the points. We change the type from “l” to “b”.\n\n\nCode\n```{r}\n###| Line graph with points\nplot(sample, type = \"b\")\n```\n\n\n\n\n\n\n\n\n\nAgain, we can play with the aesthetics of these graphs.\n\n\nCode\n```{r}\n###| Line graph aesthetics\nplot(sample, type = \"l\", lwd = 2, lty = 3)\nplot(sample, type = \"b\", lwd = 1, lty = 5, pch = 17, col = 3)\n```\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSuppose we have another sample generated from a \\(\\text{Normal}(0,2)\\). We can show both lines on the same graph.\n\n\nCode\n```{r}\n###| For reproducibility\nset.seed(68)\n\n###| Generate 2 samples\nsample1 &lt;- rnorm(n=30, mean = 0, sd = 1)\nsample2 &lt;- rnorm(n=30, mean = 0, sd = 2)\n\n###| Line plot with multiple lines\nplot(sample1, type = \"l\")\nlines(sample2)\n```\n\n\n\n\n\n\n\n\n\nWe have something, but it appears the top is cut off the graph (this is beacuse we are adding sample 2 onto sample 1 and sample 2 has a larger range). We can change the y axis limits.\n\n\nCode\n```{r}\n###| Line plot with multiple lines with limits\nplot(sample1, type = \"l\", ylim = c(-4,4))\nlines(sample2)\n```\n\n\n\n\n\n\n\n\n\nWe should also change the colours for readability.\n\n\nCode\n```{r}\n###| Line plot with multiple lines with limits\nplot(sample1, type = \"l\", ylim = c(-4,4), col = \"blue\")\nlines(sample2)\n```\n\n\n\n\n\n\n\n\n\nWe can have different types of lines in the same graph as well.\n\n\nCode\n```{r}\n###| Line plot with multiple line types\nplot(sample1, type = \"l\", ylim = c(-4,4), col = \"blue\")\nlines(sample2, lty = 4, type = \"b\")\n```\n\n\n\n\n\n\n\n\n\n\n\nHistograms\nSuppose instead we want to look at the distribution of the sample, and test if it aligns with the distribution we expect. To do this, we will up the number of samples (200) and will look at the histogram graph.\n\n\nCode\n```{r}\n###| Sample\nsample &lt;- rnorm(n=200, mean = 0, sd =1)\n\n###| Histogram\nhist(sample)\n```\n\n\n\n\n\n\n\n\n\nIf we want to have the probability on the y axis instead, we need to change the freq argument to FALSE or we change the prob argument to TRUE.\n\n\nCode\n```{r}\n###| Density graph\nhist(sample, freq = FALSE)\nhist(sample, prob = TRUE)\n```\n\n\n\n\n\n\n\n\n\nThe widths of the boxes are quite large. We can change this with the breaks argument.\n\n\nCode\n```{r}\n###| Set number of breaks\nhist(sample, breaks = 10) # 10 boxes\nhist(sample, breaks = 20) # 20 boxes\n\n###| Different size boxes\nhist(sample, breaks = c(min(sample),-1.5,0,0.5,1,max(sample))) \n      # need min and max to ensure range works\n```\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe can also change the labels and add a title.\n\n\nCode\n```{r}\n###| Labels and title\nhist(sample, breaks = 20, xlab = \"Sample\", main = \"Title\")  \n```\n\n\n\n\n\n\n\n\n\nNow, lets compare this to the normal distribution. First, we can add the density curve of the sample.\n\n\nCode\n```{r}\nsample &lt;- rnorm(n = 1000, mean = 0, sd = 1) # Increasing sample count\n\n###| Density curve\nhist(sample, prob = TRUE)\nlines(density(sample))\n```\n\n\n\n\n\n\n\n\n\nWe can then add the normal distribution curve on top to allow comparison.\n\n\nCode\n```{r}\n###| Normal\nseq &lt;- seq(from = -3, to = 3, length = 1000)\nnorm_seq &lt;- dnorm(seq(from = -3, to = 3, length = 1000), mean = 0, sd = 1)\n\n###| Density curve\nhist(sample, prob = TRUE, ylim = c(0,max(norm_seq)))\nlines(density(sample))\nlines(seq,norm_seq, col = \"red\",lwd = 2)\n```\n\n\n\n\n\n\n\n\n\nThe sample distribution is very similar to the normal distribution curve (although the sample has 2 peaks rather than 1). However, it is confusing to have 2 lines without any labels. So, let us add a legend. Additional details appear here.\n\n\nCode\n```{r}\n###| Normal\nseq &lt;- seq(from = -3, to = 3, length = 1000)\nnorm_seq &lt;- dnorm(seq(from = -3, to = 3, length = 1000), mean = 0, sd = 1)\n\n###| Density curve\nhist(sample, prob = TRUE, ylim = c(0,max(norm_seq)))\nlines(density(sample))\nlines(seq,norm_seq, col = \"red\",lwd = 2)\nlegend(x = \"topright\", # position\n       legend = c(\"Sample curve\",\"Normal curve\"),\n       col = c(\"black\",\"red\"),\n       lwd = c(1,2))\n```\n\n\n\n\n\n\n\n\n\n\n\nBox plots\nFinally, we will consider box plots. We can plot the box plot of a single sample.\n\n\nCode\n```{r}\n###| Generating a sample\nsample &lt;- rnorm(n = 100, mean = 5, sd = 2)\n\n###| Boxplot\nboxplot(sample)\n```\n\n\n\n\n\n\n\n\n\nFor multiple boxplots, we can construct a data frame and plot accordingly.\n\n\nCode\n```{r}\n###| Data frame\ndf &lt;- data.frame(\"A\" = rnorm(n = 10, mean = 0, sd = 1),\n                 \"B\" = rnorm(n = 10, mean = 0, sd = 1),\n                 \"C\" = rnorm(n = 10, mean = 0, sd = 1))\n\n###| Box plot\nboxplot(df)\n```\n\n\n\n\n\n\n\n\n\nWe can add labels and titles.\n\n\nCode\n```{r}\n###| Box plot with labels\nboxplot(df, main = \"Title\", ylab = \"Sample values\", xlab = \"Categories\")\n```\n\n\n\n\n\n\n\n\n\n\n\nCheck your understanding\nGenerate scatterplots, line graphs, histograms and box plots with samples from Poisson and Binomial distributions. Add legends and appropriate titles to each graph.",
    "crumbs": [
      "Home",
      "Introduction to R",
      "Figures"
    ]
  },
  {
    "objectID": "Introduction to R/figures.html#scatterplots",
    "href": "Introduction to R/figures.html#scatterplots",
    "title": "Figures",
    "section": "Scatterplots",
    "text": "Scatterplots\nWe will start by generating a sample from a \\(\\text{Uniform}[0,1]\\) distribution and plotting a scatter plot.\n\n\nCode\n```{r}\n##| Generating a sample\nsample &lt;- runif(n = 100, min = 0, max = 1)\n\n###| Scatterplot\nplot(sample)\n```\n\n\n\n\n\n\n\n\n\nIf we sort the sample by size, we can create a plot that increases from left to right.\n\n\nCode\n```{r}\n###| Ordered sample scatter plot\nplot(sort(sample))\n```\n\n\n\n\n\n\n\n\n\nThe x and y labs are not clear. We should change these by adding in the xlab and ylab arguments. We should also add a title for clarity!\n\n\nCode\n```{r}\n###| x and y labels and title (called main) \nplot(sort(sample), xlab = \"Ordered index\", ylab = \"Sample\", main = \"Title\")\n```\n\n\n\n\n\n\n\n\n\nWe observe a linear relationship between the ordered samples. Let us test this by adding a line to this graph using ‘abline()’.\n\n\nCode\n```{r}\n###| Using abline\nplot(sort(sample), xlab = \"Ordered index\", ylab = \"Sample\", main = \"Title\")\nabline(a = 0,b=0.01)\n```\n\n\n\n\n\n\n\n\n\nIt is quite hard to see both the points and the line at the same time. We can change the aesthetics (colour, shape and size) to make this easier to see. Additional point shapes are available here.\n\n\nCode\n```{r}\n###| Aesthetics - colour and points\nplot(sort(sample), xlab = \"Ordered index\", ylab = \"Sample\", main = \"Title\", \n     col = \"red\", pch = 3)        # we start a new line for readability :)\nabline(a = 0,b=0.01, col = \"blue\")\n```\n\n\n\n\n\n\n\n\n\nSuppose we wanted to add additional lines, at the Sample = 0.5 and at the 50th index. We can add these using ‘abline()’. We can also distinguish them by changing colour, line thickness and line type. Additional details are available here.\n\n\nCode\n```{r}\n###| Aesthetics - line\nplot(sort(sample), xlab = \"Ordered index\", ylab = \"Sample\", main = \"Title\", \n     col = \"red\", pch = 3)\nabline(a = 0,b=0.01, col = \"blue\") \nabline(h=0.5, col = \"black\", lwd = 1, lty = 3) # Note that h here is a horizontal line at sample = 0.5\nabline(v=50, col = \"black\", lwd = 1, lty = 4)  # v here is a vertical line at index = 50\n```",
    "crumbs": [
      "Home",
      "Introduction to R",
      "Figures"
    ]
  },
  {
    "objectID": "Introduction to R/figures.html#line-graphs",
    "href": "Introduction to R/figures.html#line-graphs",
    "title": "Figures",
    "section": "Line graphs",
    "text": "Line graphs\nNow, we move to generating a line graph. We will generate a new sample, this time from a \\(\\text{Normal}(0,1)\\) distribution.\n\n\nCode\n```{r}\n###| Generate sample\nsample &lt;- rnorm(n = 30, mean = 0, sd = 1)\n\n###| Line graph\nplot(sample, type = \"l\")\n```\n\n\n\n\n\n\n\n\n\nSuppose we also want to show the points. We change the type from “l” to “b”.\n\n\nCode\n```{r}\n###| Line graph with points\nplot(sample, type = \"b\")\n```\n\n\n\n\n\n\n\n\n\nAgain, we can play with the aesthetics of these graphs.\n\n\nCode\n```{r}\n###| Line graph aesthetics\nplot(sample, type = \"l\", lwd = 2, lty = 3)\nplot(sample, type = \"b\", lwd = 1, lty = 5, pch = 17, col = 3)\n```\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSuppose we have another sample generated from a \\(\\text{Normal}(0,2)\\). We can show both lines on the same graph.\n\n\nCode\n```{r}\n###| For reproducibility\nset.seed(68)\n\n###| Generate 2 samples\nsample1 &lt;- rnorm(n=30, mean = 0, sd = 1)\nsample2 &lt;- rnorm(n=30, mean = 0, sd = 2)\n\n###| Line plot with multiple lines\nplot(sample1, type = \"l\")\nlines(sample2)\n```\n\n\n\n\n\n\n\n\n\nWe have something, but it appears the top is cut off the graph (this is beacuse we are adding sample 2 onto sample 1 and sample 2 has a larger range). We can change the y axis limits.\n\n\nCode\n```{r}\n###| Line plot with multiple lines with limits\nplot(sample1, type = \"l\", ylim = c(-4,4))\nlines(sample2)\n```\n\n\n\n\n\n\n\n\n\nWe should also change the colours for readability.\n\n\nCode\n```{r}\n###| Line plot with multiple lines with limits\nplot(sample1, type = \"l\", ylim = c(-4,4), col = \"blue\")\nlines(sample2)\n```\n\n\n\n\n\n\n\n\n\nWe can have different types of lines in the same graph as well.\n\n\nCode\n```{r}\n###| Line plot with multiple line types\nplot(sample1, type = \"l\", ylim = c(-4,4), col = \"blue\")\nlines(sample2, lty = 4, type = \"b\")\n```",
    "crumbs": [
      "Home",
      "Introduction to R",
      "Figures"
    ]
  },
  {
    "objectID": "Introduction to R/figures.html#histograms",
    "href": "Introduction to R/figures.html#histograms",
    "title": "Figures",
    "section": "Histograms",
    "text": "Histograms\nSuppose instead we want to look at the distribution of the sample, and test if it aligns with the distribution we expect. To do this, we will up the number of samples (200) and will look at the histogram graph.\n\n\nCode\n```{r}\n###| Sample\nsample &lt;- rnorm(n=200, mean = 0, sd =1)\n\n###| Histogram\nhist(sample)\n```\n\n\n\n\n\n\n\n\n\nIf we want to have the probability on the y axis instead, we need to change the freq argument to FALSE or we change the prob argument to TRUE.\n\n\nCode\n```{r}\n###| Density graph\nhist(sample, freq = FALSE)\nhist(sample, prob = TRUE)\n```\n\n\n\n\n\n\n\n\n\nThe widths of the boxes are quite large. We can change this with the breaks argument.\n\n\nCode\n```{r}\n###| Set number of breaks\nhist(sample, breaks = 10) # 10 boxes\nhist(sample, breaks = 20) # 20 boxes\n\n###| Different size boxes\nhist(sample, breaks = c(min(sample),-1.5,0,0.5,1,max(sample))) \n      # need min and max to ensure range works\n```\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe can also change the labels and add a title.\n\n\nCode\n```{r}\n###| Labels and title\nhist(sample, breaks = 20, xlab = \"Sample\", main = \"Title\")  \n```\n\n\n\n\n\n\n\n\n\nNow, lets compare this to the normal distribution. First, we can add the density curve of the sample.\n\n\nCode\n```{r}\nsample &lt;- rnorm(n = 1000, mean = 0, sd = 1) # Increasing sample count\n\n###| Density curve\nhist(sample, prob = TRUE)\nlines(density(sample))\n```\n\n\n\n\n\n\n\n\n\nWe can then add the normal distribution curve on top to allow comparison.\n\n\nCode\n```{r}\n###| Normal\nseq &lt;- seq(from = -3, to = 3, length = 1000)\nnorm_seq &lt;- dnorm(seq(from = -3, to = 3, length = 1000), mean = 0, sd = 1)\n\n###| Density curve\nhist(sample, prob = TRUE, ylim = c(0,max(norm_seq)))\nlines(density(sample))\nlines(seq,norm_seq, col = \"red\",lwd = 2)\n```\n\n\n\n\n\n\n\n\n\nThe sample distribution is very similar to the normal distribution curve (although the sample has 2 peaks rather than 1). However, it is confusing to have 2 lines without any labels. So, let us add a legend. Additional details appear here.\n\n\nCode\n```{r}\n###| Normal\nseq &lt;- seq(from = -3, to = 3, length = 1000)\nnorm_seq &lt;- dnorm(seq(from = -3, to = 3, length = 1000), mean = 0, sd = 1)\n\n###| Density curve\nhist(sample, prob = TRUE, ylim = c(0,max(norm_seq)))\nlines(density(sample))\nlines(seq,norm_seq, col = \"red\",lwd = 2)\nlegend(x = \"topright\", # position\n       legend = c(\"Sample curve\",\"Normal curve\"),\n       col = c(\"black\",\"red\"),\n       lwd = c(1,2))\n```",
    "crumbs": [
      "Home",
      "Introduction to R",
      "Figures"
    ]
  },
  {
    "objectID": "Introduction to R/figures.html#box-plots",
    "href": "Introduction to R/figures.html#box-plots",
    "title": "Figures",
    "section": "Box plots",
    "text": "Box plots\nFinally, we will consider box plots. We can plot the box plot of a single sample.\n\n\nCode\n```{r}\n###| Generating a sample\nsample &lt;- rnorm(n = 100, mean = 5, sd = 2)\n\n###| Boxplot\nboxplot(sample)\n```\n\n\n\n\n\n\n\n\n\nFor multiple boxplots, we can construct a data frame and plot accordingly.\n\n\nCode\n```{r}\n###| Data frame\ndf &lt;- data.frame(\"A\" = rnorm(n = 10, mean = 0, sd = 1),\n                 \"B\" = rnorm(n = 10, mean = 0, sd = 1),\n                 \"C\" = rnorm(n = 10, mean = 0, sd = 1))\n\n###| Box plot\nboxplot(df)\n```\n\n\n\n\n\n\n\n\n\nWe can add labels and titles.\n\n\nCode\n```{r}\n###| Box plot with labels\nboxplot(df, main = \"Title\", ylab = \"Sample values\", xlab = \"Categories\")\n```",
    "crumbs": [
      "Home",
      "Introduction to R",
      "Figures"
    ]
  },
  {
    "objectID": "Introduction to R/figures.html#check-your-understanding",
    "href": "Introduction to R/figures.html#check-your-understanding",
    "title": "Figures",
    "section": "Check your understanding",
    "text": "Check your understanding\nGenerate scatterplots, line graphs, histograms and box plots with samples from Poisson and Binomial distributions. Add legends and appropriate titles to each graph.",
    "crumbs": [
      "Home",
      "Introduction to R",
      "Figures"
    ]
  },
  {
    "objectID": "Introduction to R/data types.html",
    "href": "Introduction to R/data types.html",
    "title": "Data types",
    "section": "",
    "text": "Before we start coding in R, we need to be familiar with how R stores data - i.e. we need to review the data types in R. The following table states the 6 data types and what they store.\n\nData types\n\n\n\n\n\n\nData type name\nStores\n\n\n\n\nLogical or Boolean\nTRUE or FALSE\n\n\nNumeric\na real number, including decimal values\n\n\nInteger\nan integer number (i.e. no decimal values)\n\n\nComplex\nan imaginary value\n\n\nCharacter\ncharacter or string values, for example a letter ‘A’, typically surrounded by '' or \"\"\n\n\nRaw\nraw bytes (0 or 1s)\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nNumeric and integer are different data types! When inputting data, any integer value will be stored as a numeric data type unless we add an L to the end. For example, 5 will be stored as a numeric data type but 5L will be stored as a integer.\n\n\n\nWhat data type is this variable?\nWe can check what data type a variable is using class(). Alternatively, we can confirm if a variable is an integer, logical or a character using is.integer(), is.logical() and is.character() respectively.\n\n\nCode\n```{r}\n###| Character\ncharacter &lt;- \"a banana\"\n\nclass(character)\nis.character(character)\n\n###| Numeric v integer\nnumber &lt;- 5\ninteger &lt;- as.integer(5)\n\nclass(number)\nis.integer(number)\n\nclass(integer)\nis.integer(integer)\n\n###| Decimal value\ndecimal &lt;- 0.5\n\nclass(decimal)\nis.integer(decimal)\n\n###| Logical value\nis.logical(TRUE)\nis.logical(FALSE)\n```\n\n\n[1] \"character\"\n[1] TRUE\n[1] \"numeric\"\n[1] FALSE\n[1] \"integer\"\n[1] TRUE\n[1] \"numeric\"\n[1] FALSE\n[1] TRUE\n[1] TRUE\n\n\n\n\nCoercion (changing data type)\nWe can force a variable to switch data type using as.numeric(), as.logical(), as.character() and as.integer().\n\n\nCode\n```{r}\n###| Coercing a boolean variable\nas.numeric(TRUE)\nas.numeric(FALSE)\nas.character(TRUE)\nas.character(FALSE)\n```\n\n\n[1] 1\n[1] 0\n[1] \"TRUE\"\n[1] \"FALSE\"\n\n\n\n\nCode\n```{r}\n###| Coercing a character variable\nas.numeric(\"a\") # this will produce an error!\n```\n\n\nWarning: NAs introduced by coercion\n\n\n[1] NA\n\n\n\n\nCode\n```{r}\n###| Coercing a character variable\nas.character(\"a\")\n\n###| Coercing a numeric variable\nas.numeric(2) \nas.character(2)\n\n###| Coercing to a logic variable\nas.logical(1)\nas.logical(0)\n\nas.logical(\"TRUE\")\nas.logical(\"FALSE\")\n```\n\n\n[1] \"a\"\n[1] 2\n[1] \"2\"\n[1] TRUE\n[1] FALSE\n[1] TRUE\n[1] FALSE\n\n\n\n\nCheck your understanding\nIdentify the following variable’s data type with and without using R:\n\n\na = 2025\nb = “3.14”\nc = pi\nd = TRUE\ne = c(1,0)\nf = 2022L\n\n\n\n\nCode\n```{r}\n#| code-fold: true\n\n###| Answers\nclass(2025)\nclass(\"3.14\")\nclass(pi)\nclass(TRUE)\nclass(c(1,0))\nclass(2022L)\n```\n\n\n[1] \"numeric\"\n[1] \"character\"\n[1] \"numeric\"\n[1] \"logical\"\n[1] \"numeric\"\n[1] \"integer\"",
    "crumbs": [
      "Home",
      "Introduction to R",
      "Data types"
    ]
  },
  {
    "objectID": "Introduction to R/control structures.html",
    "href": "Introduction to R/control structures.html",
    "title": "Control structures",
    "section": "",
    "text": "Control structures allow us to influence the order in which lines of code are executed. It allows for repetition and conditional arguments and more.\nThe main 2 are:\n\n\nConditional:\n\nif()\nif() else()\n\nRepeat:\n\nfor()\nwhile()\n\n\n\nThese are not always efficient as they can take a relatively long processing time compared to other code. However, for now, do not worry about computation time.\n\nIf statements\nThe code of code after an if statement is only executed if the condition within the if statement is met.\n\n\n\n\n\nflowchart LR\n  A{statement A} --&gt; B[Do this if true.]\n  A --&gt; C[Do nothing.]\n\n\n\n\n\n\nFor example, we can check ‘if 5 \\(&lt;\\) 7’ and ask the computer to output “Hello world.” if it is true.\n\n\nCode\n```{r}\n###| Example of if()\nif (5&lt;7) {\n  print(\"Hello world.\")\n}\n```\n\n\n[1] \"Hello world.\"\n\n\nMoreover, we can add an additional condition. If ‘if 5 \\(&lt;\\) 7’ is false, we can specify what we would like the computer to do instead using an else() command. (In this case, we output “It.”. )\n\n\nCode\n```{r}\n###| Example of if() and else()\nif (5 &gt; 7) {\n  print(\"Not it.\")\n} else {\n    print(\"It.\")\n}\n```\n\n\n[1] \"It.\"\n\n\nNow, our flow diagram looks like this.\n\n\n\n\n\nflowchart LR\n  A{statement A} --&gt; B[Do X if true.]\n  A --&gt; C[Do Y if false]\n\n\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nWe can nest if statements inside of each other.\n\n\nOne such example is the following function that checks if a number is a multiple of \\(2\\), \\(3\\), \\(5\\) or \\(7\\).\n\n\nCode\n```{r}\n###| Nested if statement example\n\n# Function to check divisibility by 2, 3, 5, or 7\ncheck_divisibility &lt;- function(num) {\n  # Ensure the input is numeric\n  if (!is.numeric(num)) {\n    return(\"Please provide a numeric input.\")\n  }\n  \n  # Check divisibility by 2\n  if (num %% 2 == 0) {\n    return(\"The number is divisible by 2.\")\n  } else if (num %% 3 == 0) { # Check divisibility by 3\n    return(\"The number is divisible by 3.\")\n  } else if (num %% 5 == 0) { # Check divisibility by 5\n    return(\"The number is divisible by 5.\")\n  } else if (num %% 7 == 0) { # Check divisibility by 7\n    return(\"The number is divisible by 7.\")\n  } else { # If none of the above conditions are true\n    return(\"The number is not divisible by 2, 3, 5, or 7.\")\n  }\n}\n\n# Example usage:\ncheck_divisibility(14) # Output: \"The number is divisible by 2.\"\ncheck_divisibility(21) # Output: \"The number is divisible by 3.\"\ncheck_divisibility(25) # Output: \"The number is divisible by 5.\"\ncheck_divisibility(49) # Output: \"The number is divisible by 7.\"\ncheck_divisibility(11) # Output: \"The number is not divisible by 2, 3, 5, or 7.\"\n```\n\n\n[1] \"The number is divisible by 2.\"\n[1] \"The number is divisible by 3.\"\n[1] \"The number is divisible by 5.\"\n[1] \"The number is divisible by 7.\"\n[1] \"The number is not divisible by 2, 3, 5, or 7.\"\n\n\nThe following illustrates this as a flow diagram:\n\n\n\n\n\ngraph TD\n    A[Start] --&gt; B{Is input numeric?}\n    B -- No --&gt; C[\"Please provide a numeric input.\"]\n    B -- Yes --&gt; D{Is the number divisible by 2?}\n    D -- Yes --&gt; E[\"The number is divisible by 2.\"]\n    D -- No --&gt; F{Is the number divisible by 3?}\n    F -- Yes --&gt; G[\"The number is divisible by 3.\"]\n    F -- No --&gt; H{Is the number divisible by 5?}\n    H -- Yes --&gt; I[\"The number is divisible by 5.\"]\n    H -- No --&gt; J{Is the number divisible by 7?}\n    J -- Yes --&gt; K[\"The number is divisible by 7.\"]\n    J -- No --&gt; L[\"The number is not divisible by 2, 3, 5, or 7.\"]\n\n\n\n\n\n\nIn this instance, we can stop when we find the smallest number that is a factor of the input. However, we may want to check every case.\n\n\nFor loops\nThe for loop allows code to be executed repeatedly until a given iteration.\n\n\n\n\n\ngraph TD\n    A[Start] --&gt; B[Initialize loop variable]\n    B --&gt; C{Condition met?}\n    C -- No --&gt; D[Exit loop]\n    C -- Yes --&gt; E[Execute loop body]\n    E --&gt; F[Update loop variable]\n    F --&gt; C\n    D --&gt; G[End]\n\n\n\n\n\n\nSuppose we want to print the numbers 1, 2, 3 and 4. We can use a for loop for this:\n\n\nCode\n```{r}\n###| For loop example\nfor (x in c(1:4)) {\n  print(x)\n}\n```\n\n\n[1] 1\n[1] 2\n[1] 3\n[1] 4\n\n\n\n\n\n\n\n\nImportant\n\n\n\nR will automatically increase the counter. We do not need to include x&lt;-x+1 as we do in Python.\n\n\nAlternatively, suppose we wanted to print the number 1, then the numbers 1 to 3, then the number 2, then 1 to 3 again, then 3 … . We can use nested for loops for this:\n\n\nCode\n```{r}\n###| Nested loop\nfor (x in c(1:4)) {\n  print(x)\n  for (y in c(1:3)) {\n    print(y)\n  }\n}\n```\n\n\n[1] 1\n[1] 1\n[1] 2\n[1] 3\n[1] 2\n[1] 1\n[1] 2\n[1] 3\n[1] 3\n[1] 1\n[1] 2\n[1] 3\n[1] 4\n[1] 1\n[1] 2\n[1] 3\n\n\n\n\nWhile loops\nWhile loop tests if a condition is true and will continue running the code until the condition is false.\n\n\n\n\n\ngraph TD\n    A[Start] --&gt; B{Condition met?}\n    B -- No --&gt; C[Exit loop]\n    B -- Yes --&gt; D[Execute loop body]\n    D --&gt; B\n    C --&gt; E[End]\n\n\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nIt is very important to avoid infinite loops!!\n\n\n\n\nCode\n```{r}\n###| While loop example\ni &lt;- 1\nwhile (i &lt;= 5){\n  print(i)\n  i &lt;- i + 1\n}\n```\n\n\n[1] 1\n[1] 2\n[1] 3\n[1] 4\n[1] 5\n\n\n\n\nExample combining if, for and while loops\n\n\nCode\n```{r}\n# Initialize variables\nx &lt;- 1    # Start value for while loop\nresults &lt;- c()  # Empty vector to store results\n\n# While loop: Run while x is less than or equal to 10\nwhile (x &lt;= 10) {\n  # For loop: Iterate through numbers 1 to 5\n  for (y in 1:5) {\n    # If statement: Check if the product of x and y is even\n    if ((x * y) %% 2 == 0) {\n      # Add the product to the results vector if even\n      results &lt;- c(results, x * y)\n    }\n  }\n  # Increment x to avoid infinite loop\n  x &lt;- x + 1\n}\n\n# Print the results\nprint(\"Results of even products:\")\nprint(results)\n```\n\n\n[1] \"Results of even products:\"\n [1]  2  4  2  4  6  8 10  6 12  4  8 12 16 20 10 20  6 12 18 24 30 14 28  8 16\n[26] 24 32 40 18 36 10 20 30 40 50\n\n\n\n\nCheck your understanding\nAnswer the following questions using if(), for() and while() loops.\n\n\nGiven a number, print “Positive” or “Negative” depending on if the number is positive or negative. If the number is 0, print both.\nGiven a vector, find the maximum and minimum value. Thus find out the range.\n\n\n\n\nCode\n```{r}\n#| code-fold: true\n###| Answers\nx=-1\nif (x &gt; 0) {\n  print(\"positive\")\n} else if (x &lt; 0) {\n  print(\"negative\")\n} else {print(\"both\")}\n```\n\n\n[1] \"negative\"\n\n\n\n\nCode\n```{r}\n#| code-fold: true\n###| Answers\nx &lt;- c(0,1,2,7,-5)\nn &lt;- length(x)\nmin &lt;- x[1]\nmax &lt;- x[1]\n\nfor(i in 1:n){\n  if (x[i] &lt; min) {\n    min &lt;- x[i]\n  }\n  if (x[i] &gt; max) {\n    max &lt;- x[i]\n  }\n}\n\nprint(paste(\"Range is\",max-min))\n```\n\n\n[1] \"Range is 12\"",
    "crumbs": [
      "Home",
      "Introduction to R",
      "Control structures"
    ]
  },
  {
    "objectID": "Introduction to R/operators.html",
    "href": "Introduction to R/operators.html",
    "title": "Operations",
    "section": "",
    "text": "We will begin by familiarising ourselves with the operations in R, where\n\n“an operator is a character, or characters, that determine what action is to be performed or considered”,\n\naccording to the BBC Bitesize website. These will form the base building blocks of everything we will do in the future.\nWe will start with arithmetic operators (\\(+\\),\\(-\\),\\(\\times\\),\\(\\div\\)), then go to comparison operators (\\(=\\),\\(\\ne\\),\\(\\geq\\),\\(\\leq\\)) and finally logical operators (and, or).\n\nArithmetic operators\nThe 4 base arithmetic operators are addition (+), subtraction (-), multiplication (*) and division (/). The following are some base examples of how these can be used.\n\n\nCode\n```{r}\n###| Addition\n3+10\n\n###| Subtraction\n6-2\n\n###| Multiplication\n5*15\n\n###| Division\n23/7\n```\n\n\n[1] 13\n[1] 4\n[1] 75\n[1] 3.285714\n\n\n\n\n\n\n\n\nNote\n\n\n\nIt is important to note that R follows the traditional BODMASS order of operations. As such, we can use brackets to control the order in which operations are performed.\n\n\n\n\nCode\n```{r}\n###| BODMASS\n(1+7)/2\n1 + 7/2\n3*5+2/3\n3*(5+2)/3\n```\n\n\n[1] 4\n[1] 4.5\n[1] 15.66667\n[1] 7\n\n\nWe can also do exponents (to the power of) using ^ or **, and we can find the modulo using %% and %/%\n\n\nCode\n```{r}\n###| Exponents \n5^2\n5**2\n\n4^(1/2)\n4**0.5\n```\n\n\n[1] 25\n[1] 25\n[1] 2\n[1] 2\n\n\n\n\nCode\n```{r}\n###| Modulo\n10 %% 2 # remainder of 10 divided by 2\n10 %% 4\n\n10 %/% 2 # how many times 2 goes into 10\n10 %/% 4\n```\n\n\n[1] 0\n[1] 2\n[1] 5\n[1] 2\n\n\n\n\nComparison operators\nComparison operators compare 2 values to one another and will return TRUE or FALSE.\nThe 2 operators that can be used for any data type are equal to == and not equal to !=.\nWe can also compare two numbers using less than &lt;, less than or equal to &lt;=, greater than &gt;, and greater than or equal to &gt;=.\n\n\nCode\n```{r}\n###| Equal to\n\"a banana\" == \"a banana\"\n\"a banana\" == \"a fruit\"\n\n7 == 5\n5 == 5\n\n###| Not wqual to\n\"a banana\" != \"a banana\"\n\"a banana\" != \"a fruit\"\n\n7 != 5\n5 != 5\n```\n\n\n[1] TRUE\n[1] FALSE\n[1] FALSE\n[1] TRUE\n[1] FALSE\n[1] TRUE\n[1] TRUE\n[1] FALSE\n\n\n\n\nCode\n```{r}\n###| Less than\n5 &lt; 7 \n7 &lt; 5\n5 &lt; 5 # note that this will return FALSE!\n\n###| Greater than\n5 &gt; 7 \n7 &gt; 5\n5 &gt; 5 # note that this will return FALSE!\n\n###| Less than or equal to\n5 &lt;= 7 \n7 &lt;= 5\n5 &lt;= 5 # note that this will return TRUE!\n\n###| Greater than or equal to\n5 &gt;= 7 \n7 &gt;= 5\n5 &gt;= 5 # note that this will return TRUE!\n```\n\n\n[1] TRUE\n[1] FALSE\n[1] FALSE\n[1] FALSE\n[1] TRUE\n[1] FALSE\n[1] TRUE\n[1] FALSE\n[1] TRUE\n[1] FALSE\n[1] TRUE\n[1] TRUE\n\n\n\n\nLogical operators\nLogical operators allow us to combine things or negate something.\nIf we want to find the negative, we use the ! operator. For example, we may want to say something is not true. we do this with !TRUE. Or we may want to check if 5 is not less than 7, !(5&lt;7).\n\n\nCode\n```{r}\n###| Negation of TRUE FALSE\nTRUE\n!(TRUE)\n\nFALSE\n!(TRUE)\n```\n\n\n[1] TRUE\n[1] FALSE\n[1] FALSE\n[1] FALSE\n\n\n\n\nCode\n```{r}\n###| Example of negation on relational operators\n5&lt;7\n!(5&lt;7)\n\n5==7\n!(5==7)\n```\n\n\n[1] TRUE\n[1] FALSE\n[1] FALSE\n[1] TRUE\n\n\nWe can also combine operators using AND, &. For example, we may want to check that 5&lt;7 and 10&lt;12. Alternatively, we may want to allow A or B to be true. We do this with |.\n\n\nCode\n```{r}\n###| And on TRUE FALSE\nTRUE & TRUE\nFALSE & FALSE\nTRUE & FALSE\n\n###| And on relational operators example\n(7&gt;5) & (10&lt;12)\n(7&lt;5) & (10&gt;12)\n(7&lt;5) & (10&lt;12)\n```\n\n\n[1] TRUE\n[1] FALSE\n[1] FALSE\n[1] TRUE\n[1] FALSE\n[1] FALSE\n\n\n\n\nCode\n```{r}\n###| OR on TRUE FALSE\nTRUE | TRUE\nFALSE | FALSE\nTRUE | FALSE\n\n###| OR on relational operators example\n(7&gt;5) | (10&lt;12)\n(7&lt;5) | (10&gt;12)\n(7&lt;5) | (10&lt;12)\n```\n\n\n[1] TRUE\n[1] FALSE\n[1] TRUE\n[1] TRUE\n[1] FALSE\n[1] TRUE\n\n\n\n\nCheck your understanding\nThe following are some extercises to test your understanding about operations.\n\n\nUse R to determine the area of a circle with diameter of 20cm.\n\nHint: pi is recognised in R.\n\nCalculate the cube root of 14 \\(\\times\\) 0.51.\n\nHint: think carefully about the order of operations.\n\nTest the following statement in R: Not (4 squared is greater than or equal to 15, or (the sum of 7 and 10 is less than 16)).\n\nHint: the output should be FALSE.\n\n\n\n(The code is hidden to give you a chance to practise. However, if you toggle the &gt;, example code will appear.)\n\n\nCode\n```{r}\n#| code-fold: true\n\n###| Answers\n(10^2)*pi\n(14 * 0.51)^(3)\n!( 4&lt;=15 | 7+10 &lt; 16)\n```\n\n\n[1] 314.1593\n[1] 363.9943\n[1] FALSE",
    "crumbs": [
      "Home",
      "Introduction to R",
      "Operations"
    ]
  },
  {
    "objectID": "Introduction to R/functions.html",
    "href": "Introduction to R/functions.html",
    "title": "Custom functions",
    "section": "",
    "text": "A function is a piece of code written to carry out a specific task. It can take in inputs and may return one or more values.\nThe 3 main components are:\n\n\nThe formals(): the list of arguments/inputs of the function\nThe body(): the code in the function\nThe environment(): the map of the location of the function’s variable\n\n\nA function follows the following general structure:\n\n\nfunction_name &lt;- function(arguments) {function body}\n\n\nCustom functions are used to incorporate sets of instructions that you want to use repeatedly, or that are easier to store so they can be called when needed.\nFunctions are created using function() and are stored as R objects. They can also be passed to other functions as arguments (as input) and can be nested (functions can be inside other functions).\n\n\nCode\n```{r}\n###| Function example 1\nadd &lt;- function(x,y){\n  x + y\n}\n\nadd(2,4)\n\n###| Function example 2\nsquare &lt;- function(x){\n  x^2\n}\n\nsquare(7)\n```\n\n\n[1] 6\n[1] 49\n\n\n\nCheck your understanding\nWrite functions that do the following things:\n\n\nCreate a function which returns integer division of x by y and the remainder\nCreate a function which finds the area and circumference of a circle given a radius r.\nCreate a function that calculates the factorial of some number n.\n\nHint: make sure that n is an integer!\n\n\n\n\n\nCode\n```{r}\n#| code-fold: true\n###| Answer\n\nmodulus &lt;- function(x,y) {\n  remainder &lt;- x %% y\n  multiple &lt;- x %/% y\n  print(paste(\"x modulo y is\", multiple, \"with remainder\", remainder))\n}\n\nmodulus(6,3)\n```\n\n\n[1] \"x modulo y is 2 with remainder 0\"\n\n\n\n\nCode\n```{r}\n#| code-fold: true\n###| Answer\n\ncircle &lt;- function(r){\n  area &lt;- r^2 * pi\n  circumference &lt;- 2*r*pi\n  print(paste(\"Area is\",area, \"and the circumference is\",circumference))\n}\n\ncircle(5)\n```\n\n\n[1] \"Area is 78.5398163397448 and the circumference is 31.4159265358979\"\n\n\n\n\nCode\n```{r}\n#| code-fold: true\n###| Answer\n\nfactorial &lt;- function(x) {\n  \n  if (x%%1 == 0) {\n    \n    factorial &lt;- 1\n    \n    while (x &gt;= 1) {\n      factorial &lt;- factorial * x\n      x &lt;- x - 1\n    }\n    \n    print(factorial)\n  } else {\n    print(paste(x,\" is not a positive integer\"))\n  }\n}\n\nfactorial(2) \n```\n\n\n[1] 2",
    "crumbs": [
      "Home",
      "Introduction to R",
      "Custom functions"
    ]
  },
  {
    "objectID": "Introduction to R/variables.html",
    "href": "Introduction to R/variables.html",
    "title": "Variables",
    "section": "",
    "text": "Thus far, we have covered some very important content. However, it is not in a practical, useable form. Instead of having to rewrite values each time, we want to be able to have the computer remember them (store them) so that we can recall them. We do this using variables.\nWe can assign a value to a named variable using = or -\\&gt;. (Note that we use = for assigning variables and == for check if equal!) We can check what our variable is by outputting it.\n\n\nCode\n```{r}\n###| Assigning a variable\nx &lt;- 5\ny = TRUE\n\n###| Outputting a variable\nx\ny\n```\n\n\n[1] 5\n[1] TRUE\n\n\nWe can use all our previous operators on variables. The following are just some examples of how we can do this.\n\n\nCode\n```{r}\n###| Assigning variables\na = 1\nb = 2\nc = 3\nd = 4\ne = 5\n\n###| Arithmetic operators\nd %% b\nc + d\na * e - d\n\n###| Relational operators\nd &lt; b\nc &gt; d\nc == d\n\n###| Logical operators \n(d &lt; b) & (c &gt; d)\n(d &lt; b) | (c &gt; d)\n!(d &lt; b)\n```\n\n\n[1] 0\n[1] 7\n[1] 1\n[1] FALSE\n[1] FALSE\n[1] FALSE\n[1] FALSE\n[1] FALSE\n[1] TRUE\n\n\n\nCheck your understanding\nThe following are some extercises to test your understanding about variables.\n\n\nDefine variables called velocity, time and acceleration with 5, 10 and 9.8 respectively. Calculate the displacement.\n\nHint: \\(s = ut+0.5at^2\\).\n\nDefine variables height and width of a rectangle with initial values 5 and 10. Calculate the area of the rectangle.\nExtension: given \\(f(x)=\\frac{1}{\\sqrt{2\\pi}}\\exp{(-\\frac{1}{2}x^2)}\\), find \\(f(5)\\).\n\nHint: look at sqrt() and exp().\n\n\n\n\n\nCode\n```{r}\n#| code-fold: true\n\n###| Answers\nvecolity &lt;- 5\ntime &lt;- 10\nacceleration &lt;- 9.8\ndisplacement &lt;- vecolity * time + 0.5 * acceleration * time^2\ndisplacement\n\nheight &lt;- 5\nwidth &lt;- 10\narea &lt;- height * width\narea\n\n###| Extension question\nx &lt;- 5\nf_x &lt;- 1/sqrt(2*pi)*exp(-0.5*x^2)\nf_x\n```\n\n\n[1] 540\n[1] 50\n[1] 1.48672e-06",
    "crumbs": [
      "Home",
      "Introduction to R",
      "Variables"
    ]
  },
  {
    "objectID": "Introduction to R/data structures.html",
    "href": "Introduction to R/data structures.html",
    "title": "Data structures",
    "section": "",
    "text": "Data structures are the ways in which data is stored. The following table indicates the main 5 ways.",
    "crumbs": [
      "Home",
      "Introduction to R",
      "Data structures"
    ]
  },
  {
    "objectID": "Introduction to R/data structures.html#vectors-arithmetic",
    "href": "Introduction to R/data structures.html#vectors-arithmetic",
    "title": "Data structures",
    "section": "Vectors: Arithmetic",
    "text": "Vectors: Arithmetic\nWe can apply arithmetic to vectors. We can multiple, add and subtract vectors.\n\n\nCode\n```{r}\n###| Vector arithmetic\nx &lt;- c(1,2,3)\n\nx + 3\nx * 3\nx * x\n```\n\n\n[1] 4 5 6\n[1] 3 6 9\n[1] 1 4 9",
    "crumbs": [
      "Home",
      "Introduction to R",
      "Data structures"
    ]
  },
  {
    "objectID": "Introduction to R/data structures.html#vectors-sequences-and-repetition",
    "href": "Introduction to R/data structures.html#vectors-sequences-and-repetition",
    "title": "Data structures",
    "section": "Vectors: Sequences and repetition",
    "text": "Vectors: Sequences and repetition\nWe can generate vectors using seq() and rep() to generate a sequence or repeat a value.\n\n\nCode\n```{r}\n###| Sequence 1\n\n# by will create a vector where each subsequent value is 0.1 larger than the previous\nseq(from = 0, to = 1, by = 0.1) \n\n# length.out will ensure 4 values are stored in the vector\nseq(from = 0, to = 1, length.out = 4) \n```\n\n\n [1] 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0\n[1] 0.0000000 0.3333333 0.6666667 1.0000000\n\n\n\n\nCode\n```{r}\n###| Sequence 2\n\nseq(from = 0, to = 10, by = 2.7) # note that 10 is not in this vector!\n\nseq(from = 0, to = 10, length.out = 4) \n```\n\n\n[1] 0.0 2.7 5.4 8.1\n[1]  0.000000  3.333333  6.666667 10.000000\n\n\n\n\nCode\n```{r}\n###| Repeat\nrep(1,6)\n\nrep(1:3,each = 2) # will repeat each value twice\n\nrep(1:3,2) # will repeat the entire 1:3 twice\n\nrep(1:3,length.out=6) # will repeat 1:3 until it reaches the length.out\n\nrep(1:3,length.out=5) # note that this is only 5 long and so only has one 3!\n```\n\n\n[1] 1 1 1 1 1 1\n[1] 1 1 2 2 3 3\n[1] 1 2 3 1 2 3\n[1] 1 2 3 1 2 3\n[1] 1 2 3 1 2",
    "crumbs": [
      "Home",
      "Introduction to R",
      "Data structures"
    ]
  },
  {
    "objectID": "Introduction to R/data structures.html#vectors-indexing",
    "href": "Introduction to R/data structures.html#vectors-indexing",
    "title": "Data structures",
    "section": "Vectors: Indexing",
    "text": "Vectors: Indexing\nYou can extract data from a vector if you know it’s index (for example, you can extract the 5th value of a vector) using [].\nWe can extract 1 element at a time (see the first example) or we can extract multiple elements at once using vectors (see the second and third examples). We can also extract using a variable (fourth example).\n\n\nCode\n```{r}\n###| Indexing\nx &lt;- c(1,2,3,4,5)\n\nx[3] # extracts the 3rd element\nx[1:3] # extracts elements 1, 2 and 3\nx[c(1,3,5)] # extracts elements 1, 3 and 5\n\n###| Indexing with a named vector\ny &lt;- c(2,4)\nx[y] # extracts elements 2 and 4\n```\n\n\n[1] 3\n[1] 1 2 3\n[1] 1 3 5\n[1] 2 4\n\n\nYou can change the values of a vector using indexes as well.\n\n\nCode\n```{r}\n###| Changing an element\nx &lt;- c(1,2,3,4,5)\n\nx[1] &lt;- 7\nx\n```\n\n\n[1] 7 2 3 4 5\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe number of replacing values must match the number of replaced values, otherwise there is an error (see next example)!\n\n\n\n\nCode\n```{r}\n###| Mismatch in replacement length\nx[2] &lt;- c(1,3)\n```\n\n\nWarning in x[2] &lt;- c(1, 3): number of items to replace is not a multiple of\nreplacement length\n\n\nCode\n```{r}\nx # only the 1st element is used to replace the 2nd value\n```\n\n\n[1] 7 1 3 4 5\n\n\nYou can also remove an element from a vector using [- ].\n\n\nCode\n```{r}\n###| Changing an element\nx &lt;- c(1,2,3,4,5)\nx[-1] \n```\n\n\n[1] 2 3 4 5",
    "crumbs": [
      "Home",
      "Introduction to R",
      "Data structures"
    ]
  },
  {
    "objectID": "Introduction to R/data structures.html#vectors-check-your-understanding",
    "href": "Introduction to R/data structures.html#vectors-check-your-understanding",
    "title": "Data structures",
    "section": "Vectors: Check your understanding",
    "text": "Vectors: Check your understanding\nTo practise sequences and repetition, do the following exercises.\n\n\nCreate a vector from 0 to 100.\nCreate a vector from 100 to 0.\nCreate a vector containing all strictly positive even numbers up to and including 100.\nCreate a vector containing 1 once, 2 twice and 3 thrice, in that order.\n\n\n\n\nCode\n```{r}\n#| code-fold: true\n\n###| Answers\nseq(from = 0, to = 100)\nseq(from = 100, to = 0)\nseq(from = 0, to = 100, by = 2)\n\nrep(1:3,1:3)\n```\n\n\n  [1]   0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n [19]  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n [37]  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n [55]  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n [73]  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n [91]  90  91  92  93  94  95  96  97  98  99 100\n  [1] 100  99  98  97  96  95  94  93  92  91  90  89  88  87  86  85  84  83\n [19]  82  81  80  79  78  77  76  75  74  73  72  71  70  69  68  67  66  65\n [37]  64  63  62  61  60  59  58  57  56  55  54  53  52  51  50  49  48  47\n [55]  46  45  44  43  42  41  40  39  38  37  36  35  34  33  32  31  30  29\n [73]  28  27  26  25  24  23  22  21  20  19  18  17  16  15  14  13  12  11\n [91]  10   9   8   7   6   5   4   3   2   1   0\n [1]   0   2   4   6   8  10  12  14  16  18  20  22  24  26  28  30  32  34  36\n[20]  38  40  42  44  46  48  50  52  54  56  58  60  62  64  66  68  70  72  74\n[39]  76  78  80  82  84  86  88  90  92  94  96  98 100\n[1] 1 2 2 3 3 3",
    "crumbs": [
      "Home",
      "Introduction to R",
      "Data structures"
    ]
  },
  {
    "objectID": "Introduction to R/introduction to r.html",
    "href": "Introduction to R/introduction to r.html",
    "title": "Introduction",
    "section": "",
    "text": "These pages will cover will introduce some key theory about how R operates and the basic building blocks of coding. It ends with generating plots using inbuilt R commands.\nThis section covers:\n\n\nhow R stores data/values (data types, data structures and variables),\nhow to perform operations (arithmetic, comparison and logical),\nhow to control the structure of your code (if, else, for and while),\nhow to write your own functions,\nrandom numbers, and\nplotting graphs.",
    "crumbs": [
      "Home",
      "Introduction to R",
      "Introduction"
    ]
  },
  {
    "objectID": "cheatsheets.html",
    "href": "cheatsheets.html",
    "title": "Cheatsheets",
    "section": "",
    "text": "There is a lot to learn to create beautiful and informative reports using R. In this section, there are several cheatsheets that will hopefully make this learning curve a little easier.\n(If the files are not loading, there also available on the GitHub under the Cheatsheets folder link.)\n\nLatex\nLatex is a language that allows for additional control over figures, tables and maths. The following is a cheatsheet created by Winston Chang, with the original version available here.\n\n\n\nggplot2\nA very popular package for figures is the ggplot2 package. It can be installed and loaded with the following code (although it is included in the tidyverse package).\n\n\nCode\n```{r}\n###| ggplot2 package\n\n#install.packages(\"ggplot2\")\nlibrary(ggplot2)\n```"
  },
  {
    "objectID": "Modelling/What is a linear model.html",
    "href": "Modelling/What is a linear model.html",
    "title": "What is a linear model?",
    "section": "",
    "text": "Important\n\n\n\nA linear model aims predict or explain the relationship between a single outcome variable and one (or more) explanatory variables. It is the simplest form of a regression model.\n\n\nIn this case, a variable is a quantifiable quantity. The observed data is a realisation of the variable, obtained by conducting tests (observations). Variables can be numerical (continuous or discrete) or categorical.\nThe most basic linear model has a single response and explanatory variable. It is of the form:\n\\[y_i = \\alpha + \\beta x_i + \\epsilon_i,\\]\nwhere \\(y_i\\) is the ith observation of the response variable, \\(x_i\\) is the ith observation of the explanatory variable, \\(\\alpha\\) is the intercept, \\(\\beta\\) is the gradient and \\(\\epsilon_i\\) is the error.\n\n\n\n\n\n\nImportant\n\n\n\nRegardless of whether we are fitting a model to predict or explain, our aim is to estimate the parameters.\n\n\n\nDeterministic with error\nIt is important to note that the relationship between explanatory and outcome variables is not deterministic - that is to say, knowing the values of the explanatory variables does not allow you to predict the outcome variable exactly. We can decompose the relationship into the deterministic/systemic component (\\(X\\beta\\)) and random error (\\(\\epsilon\\)):\n\\[\nY = X \\beta + \\epsilon,\n\\] where \\(Y\\in \\mathbb{R}^{n\\times 1}\\) is the outcome/response variable, \\(X \\in \\mathbb{R}^{n\\times p+1}\\) is the design matrix, \\(\\beta \\in \\mathbb{R}^{p+1 \\times 1}\\) is the parameter vector and \\(\\epsilon \\in \\mathbb{R}^{n\\times 1}\\) is the vector of errors.\nHere, we assume we have \\(n\\) data points and \\(p\\) explanatory variables. We have \\(p+1\\) in the dimensions to account for the intercept term.\n\n\nAssumptions\nTo use a linear model, we need to make 4 key assumptions. We will see in later sections how we can relax some of these assumptions to fit a generalised linear model. However, for now, we must make sure our model meets these assumptions:\n\n\nLinearity - the systemic component is linear in parameters, that is, \\[\\mathbb{E}[Y] = \\mathbb{E}[X\\beta].\\] Note that the explanatory variables do not have to be linear. They can be polynomials, log and more!\nHomoscedasticity - the errors must have constant variance, i.e. \\[Var(\\epsilon_1) = Var(\\epsilon_2) = \\; ... \\; = Var(\\epsilon_{n+1}) = \\sigma^2.\\]\nThe errors are independent of each other.\nThe errors are normally distributed, \\[\\epsilon_i \\sim \\text{Normal}(0,\\sigma^2).\\]\n\n\nThere are several things we should note about the response variable as a consequence of these assumptions.\n\n\nIt is univariate.\nIt is continuous.\nIt is stochastic (i.e. has a random element).\nIt has equal variance.\nResponses from different observations are assumed to be uncorrelated. (We will revisit this for time series later.)\n\n\n\n\nLinearity assumption - can we have \\(x^2\\)?\nIt is very important to be careful with the linearity assumption.\nSuppose we are given a dataset. Let \\(y_i\\) denote the ith observation of the response variable. Let \\(x_{i1}\\) denote the ith observation of the first explanatory variable and \\(x_{i2}\\) denote the ith observation of the second explanatory variable.Let \\(\\beta = (a,b,c)^{T}\\).\nThen, which of the following are linear models - i.e. when does \\(\\mathbb{E}[y_i] = \\mathbb{E}[X_i\\beta]\\)?\n\n\n\\(y_i = b x_{i1} + \\epsilon_i\\)\n\\(y_i = a + b x_{i1} + \\epsilon_i\\)\n\\(y_i = a + b^3 x_{i1} + c x_{i2} + \\epsilon_i\\)\n\\(y_i = a + b (x_{i1}-x_{i2})^2 + \\epsilon_i\\)\n\\(y_i = a + b x_{i1} + c \\log(x_{i2}) + \\epsilon_i\\)\n\n\nIn this case, all are linear models except for 3. This is because the parameters are not linear in point 3 as we have \\(b^3\\)!\n\n\nPrinciple of parsimony - simplest is best\nAfter we have checked that our model meets the 4 key assumptions, we must decide what variables to include in our model. We need to balance accuracy and complexity.\nFor example, a model with loads of explanatory variables may give more accurate predictions. However, the more parameters (explanatory variables) we have in a model, the higher the computational cost to fit a linear model.\nThe principle of parsimony states that “given 2 models that behave similarly, we should pick the simpler model”.\nThe exact boundaries of ‘similarly’ are difficult to quantify. Model creation and selection is an art form, and something that requires practise to learn.\n\n\n\n\n\n\nImportant\n\n\n\nImportant exceptions to the ‘pick the simpler model’ principle are the following:\n\n\nIf \\(x^2\\) appears in the model, \\(x\\) must also appear. Similarly, if \\(x^3\\) appears, \\(x\\) and \\(x^2\\) must also appear.\nIf there is an interaction term between explanatory variables \\(x_1\\) and \\(x_2\\), then \\(x_1\\) and \\(x_2\\) must also appear. (We will revisit this when we cover categorical data.)\n\n\n\n\nMore information about this principle can be found here.",
    "crumbs": [
      "Home",
      "Linear modelling",
      "What is a linear model?"
    ]
  },
  {
    "objectID": "Modelling/What is a linear model.html#what-is-a-linear-model",
    "href": "Modelling/What is a linear model.html#what-is-a-linear-model",
    "title": "What is a linear model?",
    "section": "",
    "text": "A linear model aims predict or explain the relationship between a single outcome variable and one (or more) explanatory variables. It is the simplest form of a regression model.\nIn this case, a variable is a quantifiable quantity. The observed data is a realisation of the variable, obtained by conducting tests (observations). Variables can be numerical (continuous or discrete) or categorical.\nThe most basic linear model has a single response and explanatory variable. It is of the form:\n\\[y_i = \\alpha + \\beta x_i + \\epsilon_i,\\]\nwhere \\(y_i\\) is the ith observation of the response variable, \\(x_i\\) is the ith observation of the explanatory variable, \\(\\alpha\\) is the intercept, \\(\\beta\\) is the gradient and \\(\\epsilon_i\\) is the error.\nRegardless of whether we are fitting a model to predict or explain, our aim is to estimate the parameters.\n\n\nIt is important to note that the relationship between explanatory and outcome variables is not deterministic - that is to say, knowing the values of the explanatory variables does not allow you to predict the outcome variable exactly. We can decompose the relationsihp into the deterministic/systemic component and random error:\n\\[\nY = X \\beta + \\epsilon,\n\\] where \\(Y\\in \\mathbb{R}^{n\\times 1}\\) is the outcome/response variable, \\(X \\in \\mathbb{R}^{n\\times p+1}\\) is the design matrix, \\(\\beta \\in \\mathbb{R}^{p+1 \\times 1}\\) is the parameter vector and \\(\\epsilon \\in \\mathbb{R}^{n\\times 1}\\) is the vector of errors. Here, we assume we have \\(n\\) data points and \\(p\\) explanatory variables. We have \\(p+1\\) in the dimensions to account for the intercept term.\n\n\n\nTo use a linear model, we need to make 4 key assumptions. We will see in later pages how we can relax some of these assumptions to fit a generalised linear model. However, for now, we must make sure our model meets these assumptions:\n\n\nLinearity - the systemic component is linear in parameters, that is, \\[\\mathbb{E}[Y] = \\mathbb{E}[X\\beta].\\] Note that the explanatory variables do not have to be linear. They can be polynomials, log and more!\nHomoscedasticity - the errors must have constant variance, i.e. \\[Var(\\epsilon_1) = Var(\\epsilon_2) = \\; ... \\; = Var(\\epsilon_{n+1}) = \\sigma^2.\\]\nThe errors are independent of each other.\nThe errors are normally distributed, \\[\\epsilon \\sim \\text{Normal}(0,\\sigma^2 I_n).\\]\n\n\nThere are several things we should note about the response variable as a consequence of these assumptions.\n\n\nIt is univariate.\nIt is continuous.\nIt is stochastic (i.e. has a random element).\nIt has equal variance.\nResponses from different observations are assumed to be uncorrelated. (We will revisit this for time series later.)\n\n\n\n\n\nIt is very important to be careful with the linearity assumption.\nSuppose we are given a dataset. Let \\(y_i\\) denote the ith observation of the response variable. Let \\(x_{i1}\\) denote the ith observation of the first explanatory variable and \\(x_{i2}\\) denote the ith observation of the second explanatory variable.Let \\(\\beta = (a,b,c)^{T}\\).\nThen, which of the following are linear models - i.e. when does \\(\\mathbb{E}[y_i] = \\mathbb{E}[X_i\\beta]\\)?\n\n\n\\(y_i = b x_{i1} + \\epsilon_i\\)\n\\(y_i = a + b x_{i1} + \\epsilon_i\\)\n\\(y_i = a + b^3 x_{i1} + c x_{i2} + \\epsilon_i\\)\n\\(y_i = a + b (x_{i1}-x_{i2})^2 + \\epsilon_i\\)\n\\(y_i = a + b x_{i1} + c \\log(x_{i2}) + \\epsilon_i\\)\n\n\nIn this case, all are linear models except for 3. This is because the parameters are not linear in 3 (\\(b^3\\))!\n\n\n\nAfter we have checked that our model meets the 4 key assumptions, we must decide what explanatory variables to include in our model. We need to balance accuracy and complexity.\nFor example, a model with loads of explanatory variables may give more accurate predictions. However, the more parameters (explanatory variables) we have in a model, the higher the computational cost to fit a linear model.\nThe principle of parsimony states that “given 2 models that behave similarly, we should pick the simpler model”.\nThe exact boundaries of ‘similarly’ are difficult to quantify. Model creation and selection is an art form, and something that requires practise to learn.\nImportant exceptions to the ‘pick the simpler model’ principle are the following:\n\n\nIf \\(x^2\\) appears in the model, \\(x\\) must also appear. Similarly, if \\(x^3\\) appears, \\(x\\) and \\(x^2\\) must also appear.\nIf there is an interaction term between explanatory variables \\(x_1\\) and \\(x_2\\), then \\(x_1\\) and \\(x_2\\) must also appear. (We will revisit this when we cover categorical data.)"
  },
  {
    "objectID": "Data/Raw data.html",
    "href": "Data/Raw data.html",
    "title": "Data",
    "section": "",
    "text": "To begin, download the data and save it to a folder in your documents. Then, you can use the following commands to call in the data:"
  },
  {
    "objectID": "Data/Raw data.html#leaf-data",
    "href": "Data/Raw data.html#leaf-data",
    "title": "Data",
    "section": "Leaf data",
    "text": "Leaf data\n\n\nCode\n```{r}\n###| Leaf data \n\nleaf &lt;- data.frame(\"Nitrogen\" = c(3.05,4.22,3.34,3.77,3.52,3.54,3.74, 3.78, 2.92, 3.10, 2.86, 2.78, 2.22, 2.67, 3.12, 3.03, 2.45, 4.12, 4.61, 3.94, 4.12, 2.93, 2.66, 3.17, 2.79, 2.61, 3.74, 3.13, 3.49, 2.94),\n                   \"Chlorine\" = c(1.45, 1.35, 0.26, 0.23, 1.10, 0.76, 1.59, 0.39, 0.39, 0.64, 0.82, 0.64, 0.85, 0.90, 0.92, 0.97, 0.18, 0.62, 0.51, 0.45, 1.79, 0.25, 0.31, 0.20, 0.24, 0.20, 2.27, 1.48, 0.25, 2.22),\n                   \"Potassium\" = c(5.67, 4.86, 4.19, 4.42, 3.17, 2.76, 3.81, 3.23, 5.44, 6.16, 5.48, 4.62, 4.49, 5.59, 5.86, 6.60, 4.51, 5.31, 5.16, 4.45, 6.17, 3.38, 3.51, 3.08, 3.98, 3.64, 6.50, 4.28, 4.71, 4.58),\n                   \"lburn\" = c(0.34, 0.11, 0.38, 0.68, 0.18, 0.00, 0.08, 0.11, 1.53, 0.77, 1.17, 1.01, 0.89, 1.40, 1.05, 1.15, 1.49, 0.51, 0.18, 0.34, 0.36, 0.89, 0.91, 0.92, 1.35, 1.33, 0.23, 0.26, 0.73, 0.23))\n```"
  },
  {
    "objectID": "Modelling/Continuous data.html",
    "href": "Modelling/Continuous data.html",
    "title": "Fitting a model with continuous data",
    "section": "",
    "text": "Suppose we are contacted by a group of scientists who are conducting experiments on leaf burn times. They have provided us with the leaf dataset and want to know what the relationship between the elements in the soil and burn time.\nThey tell us that the ‘lburn’ variable is the log of the leaf burn time. They also tell us that the ‘Nitrogen’, ‘Chlorine’ and ‘Potassium’ variables are the percentage of prevalant in soil.\nTo answer their question, and find the relationship between the elements and burn time, we are going to fit a linear model on the leaf dataset. However, before we fit the model, it is important to review the dataset carefully.\n\nA quick look at the data\nWe can load in the data and inspect the first 6 rows as follows.\n\n\n\n\n\n\nNote\n\n\n\nThe data can be found on the associated github here. Please download this to your computer and save it to your documents.\nYou will need to change the location of the file path. You can find this by clicking the file and reading the pop up window.\n\n\n(If you cannot load in the data, a version appears in the Data tab at the top of the website. You should be able to copy and paste that version into your R script and run it directly.)\n\n\nCode\n```{r}\n###| Loading in data\nleaf &lt;- read.csv(\"~/Documents/GitHub/Warwick Statistics Society R Course 2024-2025/Data/leaf.csv\")\n\n###| First 6 rows\nhead(leaf)\n```\n\n\n  Nitrogen Chlorine Potassium lburn\n1     3.05     1.45      5.67  0.34\n2     4.22     1.35      4.86  0.11\n3     3.34     0.26      4.19  0.38\n4     3.77     0.23      4.42  0.68\n5     3.52     1.10      3.17  0.18\n6     3.54     0.76      2.76  0.00\n\n\n\n\nSet up\nFrom the previous section, we observe 4 variables: Nitrogen, Chlorine, Potassium and lburn. We note that all 4 are continuous (as we would expect given what we have been told).\nNow, we want to fit a linear model of the form: \\[\\text{lburn} = \\alpha + \\beta \\times \\text{Nitrogen}+ \\gamma \\times \\text{Chlorine} + \\delta \\times \\text{Potassium} + \\epsilon.\\] Expressing this as a matrix, by reading off the first 2 rows of the dataframe,\n\\[\n\\begin{pmatrix} 0.34 \\\\ 0.11 \\\\ ... \\end{pmatrix} = \\begin{pmatrix} 1 & 3.05 & 1.45 & 5.67 \\\\ 1 & 4.22 & 1.35 & 4.86 \\\\ ... & ... & ... & ... \\end{pmatrix} \\times \\begin{pmatrix} \\alpha \\\\ \\beta \\\\ \\gamma \\\\ \\delta \\end{pmatrix} + \\epsilon.\n\\]\nThus, our goal is to estimate the \\(\\alpha\\),\\(\\beta\\),\\(\\gamma\\) and \\(\\delta\\) that best captures the relationship between the response variable (lburn) and the explanatory variables (Nitrogen, Chlorine and Potassium).\n\n\nUsing ‘lm()’\nIn R, the command ‘lm()’ will fit a linear model for you. We will begin by fitting a model where we only use the Nitrogen soil percentage to predict the burn time. That is, we fit the following model:\n\\[\ny_i = \\alpha + \\beta x_{i,\\text{Nitrogen}} + \\epsilon_i,\n\\]\nwhere \\(x_{i,\\text{Nitrogen}}\\) represents the Nitrogen percentage of the ith observation. We fit this using the lm() command with lburn ~ Nitrogen formula and setting the data=leaf.\n\n\nCode\n```{r}\n###| lburn ~ nitrogen model\nm1 &lt;- lm(lburn ~ Nitrogen, data = leaf) \n\n###| output\nm1\n```\n\n\n\nCall:\nlm(formula = lburn ~ Nitrogen, data = leaf)\n\nCoefficients:\n(Intercept)     Nitrogen  \n     2.6257      -0.5916  \n\n\nFrom the output, we obtain an estimate for \\(\\alpha = 2.6257\\) and an estimate for \\(\\beta = -0.5916\\). We interpret this as follows:\n\n\nIf there is no Nitrogen in the soil, the expected log leaf burn time is 2.6.\nFor every increase of 1% of Nitrogren in the soil, we expect a 0.6 decrease in the log leaf burn time.\n\n(Alternatively, we expect the leaf burn time to decrease by $(0.6).)\n\n\n\nHowever, if we want to get more information about the model, we can use the summary() command on a model, rather than looking at the raw output.\n\n\nCode\n```{r}\n###| Summary output of a model\nsummary(m1)\n```\n\n\n\nCall:\nlm(formula = lburn ~ Nitrogen, data = leaf)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.65636 -0.27698  0.03712  0.27876  0.63181 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   2.6257     0.3610   7.273 6.44e-08 ***\nNitrogen     -0.5916     0.1085  -5.454 8.03e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.3404 on 28 degrees of freedom\nMultiple R-squared:  0.5151,    Adjusted R-squared:  0.4978 \nF-statistic: 29.75 on 1 and 28 DF,  p-value: 8.025e-06\n\n\nNow, the estimates of \\(\\alpha\\) and \\(\\beta\\) are reported in the Estimate column. The rest of the output consists of useful information about the performance of the model. A detailed blogpost of information was created by Felipe Rego and is available here. I have pulled out 2 key values that you need to be very comfortable with calculating and using:\n\n\nPr(&gt;|t|) is the p-value after performing a hypothesis test.\n\nThe asterics (*) indicate the significance. Depending on the context, different significance levels are suitable. In most cases \\(0.05\\) is a ‘good’ level.\n\nThe \\(R^2\\) and adjusted \\(R^2\\) describe how much variance is accounted for by the model (the closer to 1 the better)\n\n\nWe can also get information using ‘anova()’.\n\n\nCode\n```{r}\n###| Anova output\nanova(m1)\n```\n\n\nAnalysis of Variance Table\n\nResponse: lburn\n          Df Sum Sq Mean Sq F value    Pr(&gt;F)    \nNitrogen   1 3.4460  3.4460  29.748 8.025e-06 ***\nResiduals 28 3.2435  0.1158                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nThis no longer gives the \\(R^2\\) values. However, it will perform consecutive hypothesis tests.\n\n\nUsing ‘anova()’\nTo explore anova further, let us fit a different linear model: \\[\ny_i = \\alpha + \\beta x_{i,\\text{Nitrogen}} + \\gamma x_{i,\\text{Chlorine}}+ \\epsilon_i.\\]\n\n\nCode\n```{r}\n###| lburn ~ Nitrogen + Chlorine\nm2 &lt;- lm(lburn ~ Nitrogen + Chlorine, data = leaf)\n\n###| anova on larger model\nanova(m2)\n```\n\n\nAnalysis of Variance Table\n\nResponse: lburn\n          Df Sum Sq Mean Sq F value    Pr(&gt;F)    \nNitrogen   1 3.4460  3.4460 38.9352 1.127e-06 ***\nChlorine   1 0.8538  0.8538  9.6473  0.004424 ** \nResiduals 27 2.3897  0.0885                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nThe first row of the anova output is: \\[ Nitrogen \\quad  1 \\quad 3.4460 \\quad 3.4460 \\quad 38.9352 \\quad 1.127e-06 \\text{***}.\\]\nThe p-value \\(1.127e-06\\) comes from a hypothesis test with null hypothsis \\(\\beta = 0\\). That is to say, we compare the following 2 models, one where \\(\\beta =0\\) and one where \\(\\beta \\neq 0\\):\n\n\n\\(y_i = \\alpha + \\epsilon_i\\)\n\\(y_i = \\alpha + \\beta x_{i,\\text{Nitrogen}} + \\epsilon_i\\)\n\n\nAs the p-value is \\(&lt;0.05\\), we say that there is sufficient evidence to reject the null hypothesis.\nThe second row of the anova output is: \\[Chlorine \\quad  1 \\quad 0.8538 \\quad 0.8538 \\quad 9.6473 \\quad 0.004424 \\text{**}.\\]\nThe p-value \\(0.004424\\) comes from a hypothesis test with null hypothesis \\(\\gamma = 0\\). That is to say, we compare the following 2 models, one where \\(\\beta =0\\) and one where \\(\\beta \\neq 0\\):\n\n\n\\(y_i = \\alpha + \\beta x_{i,\\text{Nitrogen}} + \\epsilon_i\\)\n\\(y_i = \\alpha + \\beta x_{i,\\text{Nitrogen}} + \\gamma x_{i,\\text{Chlorine}} + \\epsilon_i\\)\n\n\nAs the p-value is \\(&lt;0.05\\), we say that there is sufficient evidence to reject the null hypothesis.\nMore information about interpreting anova can be found here.\n\n\nFitting a model with all 3 explanatory variables\nNow that we have some familiarity with the outputs, let us fit the model with all possible terms (i.e. the fully saturated model). That is, we fit\n\\[\ny_i = \\alpha + \\beta x_{i,\\text{Nitrogen}} + \\gamma x_{i,\\text{Chlorine}} + \\delta x_{i,\\text{Potassium}} + \\epsilon_i.\n\\]\n\n\nCode\n```{r}\n###| Saturated model\nm3 &lt;- lm(lburn ~ Nitrogen + Chlorine + Potassium, data = leaf)\n\n###| Output\nm3\n```\n\n\n\nCall:\nlm(formula = lburn ~ Nitrogen + Chlorine + Potassium, data = leaf)\n\nCoefficients:\n(Intercept)     Nitrogen     Chlorine    Potassium  \n     1.8110      -0.5315      -0.4396       0.2090  \n\n\nFrom fitting this model, we obtain estimates for \\(\\alpha\\),\\(\\beta\\),\\(\\gamma\\) and \\(\\delta\\). We interpret these as follows:\n\nFor a leaf with no Nitrogen, Chlorine and Potassium in the soil, we expect the log burning time to be \\(1.8\\). Thus, the burning time is \\(\\exp(1.8)\\approx 6\\).\nHolding all other element concentrations, an increase of \\(1\\%\\) in Nitrogen concentration corresponds to a decrease of 0.5 in the log burning time.\nHolding all other element concentrations, an increase of \\(1\\%\\) in Chlorine concentration corresponds to a decrease of 0.4 in the log burning time.\nHolding all other element concentrations, an increase of \\(1\\%\\) in Potassium concentration corresponds to an increase of 0.2 in the log burning time.\n\n\n\n\n\n\n\nImportant\n\n\n\nIt is very important that we state that the other explanatory variables are held constant when interpreting the estimates! The estimate only explains the relationship when that specific explanatory variable is altered.\n\n\nNow, we can consider if we need all of these variables in our model. We do this by using ‘anova()’.\n\n\nCode\n```{r}\n###| Saturated model anova\nanova(m3)\n```\n\n\nAnalysis of Variance Table\n\nResponse: lburn\n          Df Sum Sq Mean Sq F value    Pr(&gt;F)    \nNitrogen   1 3.4460  3.4460  75.622 3.573e-09 ***\nChlorine   1 0.8538  0.8538  18.738 0.0001976 ***\nPotassium  1 1.2049  1.2049  26.441 2.311e-05 ***\nResiduals 26 1.1848  0.0456                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nIn all 3 consecutive tests (\\(\\beta=0\\),\\(\\gamma=0\\) and \\(\\delta=0\\)), we observe evidence to reject the null hypothesis. Thus, we keep all 3 variables and propose the following linear model to the scientists:\n\\[\ny_i = 1.8 -0.5 \\; x_{i,\\text{Nitrogen}} -0.4 \\; x_{i,\\text{Chlorine}} + 0.2 \\; x_{i,\\text{Potassium}} + \\epsilon_i.\n\\]",
    "crumbs": [
      "Home",
      "Linear modelling",
      "Fitting a model with continuous data"
    ]
  },
  {
    "objectID": "Modelling/Loading in data.html",
    "href": "Modelling/Loading in data.html",
    "title": "Loading in data",
    "section": "",
    "text": "NEED TO WRITE UP HOW TO DO THIS."
  },
  {
    "objectID": "Modelling/Categorical data.html",
    "href": "Modelling/Categorical data.html",
    "title": "Fitting a model with categorical data",
    "section": "",
    "text": "Thus far, we have fit models with continuous data. However, we will often encounter variables that have a finite number of categories (i.e. categorical variables). We can either assign a reference category (treatment coding) or have no intercept term.\n\nSet up\nTo explore categorical data, let us look at the agriculture dataset.\n\n\nCode\n```{r}\n###| Load in the data\nagriculture &lt;- read.csv(\"~/Documents/GitHub/Warwick Statistics Society R Course 2024-2025/Data/agriculture.csv\")\n\n###| First 6 rows\nhead(agriculture)\n```\n\n\n  Variety Block SIZE YIELD\n1       A     1   28    28\n2       B     1   23    23\n3       C     1   27    27\n4       D     1   24    24\n5       E     1   30    30\n6       F     1   30    30\n\n\nIn this dataset, there are 4 variables: Variety, Block, SIZE and YIELD. From the first 6 rows, we see that Variety is a categorical variable with categories at least A-F. However, as we can only see 1 for Block, it is unclear what type of variable it is. Instead, let us look at the summary of the dataset, using the summary() function.\n\n\nCode\n```{r}\n###| Dataset summary\nsummary(agriculture)\n```\n\n\n   Variety              Block           SIZE           YIELD      \n Length:48          Min.   :1.00   Min.   : 19.0   Min.   : 19.0  \n Class :character   1st Qu.:2.75   1st Qu.: 27.0   1st Qu.: 27.0  \n Mode  :character   Median :4.50   Median : 82.0   Median : 82.0  \n                    Mean   :4.50   Mean   :113.0   Mean   :113.0  \n                    3rd Qu.:6.25   3rd Qu.:201.2   3rd Qu.:201.2  \n                    Max.   :8.00   Max.   :261.0   Max.   :261.0  \n\n\nFrom this, we see that SIZE is a continuous variable from 19 to 261 and YIELD is a continuous variable from 19 to 261. (Exploring this further, we note that the size and yield observations are the same for every entry.) We also see that Block takes values from 1 to 8 and Variety is always a character. However, we do not know what values Variety takes.\nTo fix this, we will alter the data using the factor() command.\n\n\nCode\n```{r}\n###| Factor command\nagriculture$Variety &lt;- factor(agriculture$Variety)\n\n###| First 6 rows\nhead(agriculture)\n\n###| Summary\nsummary(agriculture)\n```\n\n\n  Variety Block SIZE YIELD\n1       A     1   28    28\n2       B     1   23    23\n3       C     1   27    27\n4       D     1   24    24\n5       E     1   30    30\n6       F     1   30    30\n Variety     Block           SIZE           YIELD      \n A:8     Min.   :1.00   Min.   : 19.0   Min.   : 19.0  \n B:8     1st Qu.:2.75   1st Qu.: 27.0   1st Qu.: 27.0  \n C:8     Median :4.50   Median : 82.0   Median : 82.0  \n D:8     Mean   :4.50   Mean   :113.0   Mean   :113.0  \n E:8     3rd Qu.:6.25   3rd Qu.:201.2   3rd Qu.:201.2  \n F:8     Max.   :8.00   Max.   :261.0   Max.   :261.0  \n\n\nNow, the Variety column is treated as a categorical variable, rather than as characters/strings. If we look at the new summary of the data, we observe that there are 6 categories (A-F) and each category has 8 observations.\n\n\nFitting a model\nNow, let’s fit a model that uses Variety and Block to predict SIZE. That is, we fit a model of the following from:\n\\[\\begin{align}\nSIZE_i = & \\alpha \\times \\mathbb{I}{(\\text{oberservation i has Variety A})} + \\beta \\times \\mathbb{I}{(\\text{oberservation i has Variety B})} \\\\ & + \\gamma \\times \\mathbb{I}{(\\text{oberservation i has Variety C})} + \\delta \\times \\mathbb{I}{(\\text{oberservation i has Variety D})} \\\\ & + \\epsilon \\times \\mathbb{I}{(\\text{oberservation i has Variety E})} + \\zeta \\times \\mathbb{I}{(\\text{oberservation i has Variety F})} \\\\ & + \\eta \\times Block_i + \\hat{\\epsilon}_i,\n\\end{align}\\]\nwhere \\(\\hat{\\epsilon}_i\\) is the error of the ith observation.\n\n\nCode\n```{r}\n###| SIZE ~ Variety + Block\nm1 &lt;- lm(SIZE ~ 0 + Variety + Block, data = agriculture) # Set intercept to 0\n\n###| Output\nm1\n```\n\n\n\nCall:\nlm(formula = SIZE ~ 0 + Variety + Block, data = agriculture)\n\nCoefficients:\nVarietyA  VarietyB  VarietyC  VarietyD  VarietyE  VarietyF     Block  \n  57.625    62.875    69.625    89.500    73.500    79.875     9.083  \n\n\nReading off of the output, we obtain the following model:\n\\[\\begin{align}\nSIZE_i = &57.6 \\times \\mathbb{I}{(\\text{oberservation i has Variety A})} + 62.9 \\times \\mathbb{I}{(\\text{oberservation i has Variety B})} \\\\ & + 69.6 \\times \\mathbb{I}{(\\text{oberservation i has Variety C})} + 89.5 \\times \\mathbb{I}{(\\text{oberservation i has Variety D})} \\\\ & + 73.5 \\times \\mathbb{I}{(\\text{oberservation i has Variety E})} + 79.9 \\times \\mathbb{I}{(\\text{oberservation i has Variety F})} \\\\ & + 9.1 \\times Block_i + \\hat{\\epsilon}_i.\n\\end{align}\\]\nWe interpret the Block variable as before: holding every other variable constant, a 1 unit increase in the Block is expected to result in a 9.1 unit increase in SIZE.\n\n\n\n\n\n\nImportant\n\n\n\nHowever, we cannot interpret the categorical variable, Variety, in the same way. Instead, we will compare what happens as we change category.\n\n\nFor example,\n\n\nFor a Variety A observation, and holding Block constant, we expect the SIZE to be 5.3 units smaller than if it was Variety B.\nFor a Variety F observation, and holding Block constant, we expect the SIZE to be 22.3 units larger than if it was Variety A.\n\n\n\n\nRefrence categories\nUsing no intercept (by adding the 0 term in the lm() command), we can compare across categories easily. However, suppose we want to compare everything to category A. Instead of finding the estimates and then subtracting them, we can ask R to do this directly by setting up reference categories using relevel().\nNow, our model looks like:\n\\[\\begin{align}\nSIZE_i = & \\tilde{\\alpha} + \\tilde{\\beta} \\times \\mathbb{I}{(\\text{oberservation i has Variety B})} \\\\ & + \\tilde{\\gamma} \\times \\mathbb{I}{(\\text{oberservation i has Variety C})} + \\tilde{\\delta} \\times \\mathbb{I}{(\\text{oberservation i has Variety D})} \\\\ & + \\tilde{\\epsilon} \\times \\mathbb{I}{(\\text{oberservation i has Variety E})} + \\tilde{\\zeta} \\times \\mathbb{I}{(\\text{oberservation i has Variety F})} \\\\ & + \\tilde{\\eta} \\times Block_i + \\hat{\\epsilon}_i,\n\\end{align}\\]\nWe code this up as follows:\n\n\nCode\n```{r}\n###| Setting Category A as the reference category\nagriculture$Variety &lt;- relevel(agriculture$Variety, ref = \"A\")\n\n###| New model\nm2 &lt;- lm(SIZE ~ Variety + Block, data = agriculture) # no specified intercept!\n\n###| Output\nm2\n```\n\n\n\nCall:\nlm(formula = SIZE ~ Variety + Block, data = agriculture)\n\nCoefficients:\n(Intercept)     VarietyB     VarietyC     VarietyD     VarietyE     VarietyF  \n     57.625        5.250       12.000       31.875       15.875       22.250  \n      Block  \n      9.083  \n\n\nNow, our model is: \\[\\begin{align}\nSIZE_i = &57.6 + 5.3 \\times \\mathbb{I}{(\\text{oberservation i has Variety B})} \\\\ & + 12 \\times \\mathbb{I}{(\\text{oberservation i has Variety C})} + 31.9 \\times \\mathbb{I}{(\\text{oberservation i has Variety D})} \\\\ & + 15.7 \\times \\mathbb{I}{(\\text{oberservation i has Variety E})} + 22.3 \\times \\mathbb{I}{(\\text{oberservation i has Variety F})} \\\\ & + 9.1 \\times Block_i + \\hat{\\epsilon}_i.\n\\end{align}\\]\nBoth of these models are equivalent! They are reparametrisations of each other, with \\(\\alpha = \\tilde{\\alpha}\\), \\(\\beta = \\tilde{\\alpha} + \\tilde{\\beta}\\), \\(\\gamma = \\tilde{\\alpha} + \\tilde{\\gamma}\\), …, \\(\\zeta = \\tilde{\\alpha} + \\tilde{\\zeta}\\) and \\(\\eta = \\tilde{\\eta}\\). Based on the context, you should choose to include or not to include the intercept term.\n\n\nInteraction terms\nWhat effect does the Variety category have on the Block estimator? We explore this using interaction terms with a model of the form:\n\\[\\begin{align}\nSIZE_i = & \\alpha + \\beta \\times \\mathbb{I}{(\\text{oberservation i has Variety B})} \\\\ & + ... + \\zeta \\times \\mathbb{I}{(\\text{oberservation i has Variety F})} \\\\ & + \\eta \\times Block_i + \\\\ & \\tilde{\\beta} \\times \\mathbb{I}{(\\text{oberservation i has Variety B})} \\times Block_i \\\\ & + ... + \\tilde{\\zeta} \\times \\mathbb{I}{(\\text{oberservation i has Variety F})} \\times Block_i \\\\ & \\hat{\\epsilon}_i,\n\\end{align}\\] where \\(\\hat{\\epsilon}_i\\) is the error of the ith observation.\n\n\nCode\n```{r}\n###| Model with intercept terms\nm3 &lt;- lm(SIZE ~ Variety + Block + Variety:Block, data = agriculture) \n\n###| Output\nm3\n```\n\n\n\nCall:\nlm(formula = SIZE ~ Variety + Block + Variety:Block, data = agriculture)\n\nCoefficients:\n   (Intercept)        VarietyB        VarietyC        VarietyD        VarietyE  \n        88.000         -29.893         -24.429         -23.679         -20.286  \n      VarietyF           Block  VarietyB:Block  VarietyC:Block  VarietyD:Block  \n         3.286           2.333           7.810           8.095          12.345  \nVarietyE:Block  VarietyF:Block  \n         8.036           4.214  \n\n\nWe interpret the model as follows:\n\n\nIf the observation is Variety B and holding block constant, the SIZE will be 29.9 units smaller than if it was Variety A.\n\nIf the observation is Variety C and holding block constant, the SIZE will be 24.4 units smaller than if it was Variety A.\n\nIf the observation is Variety D and holding block constant, the SIZE will be 23.7 units smaller than if it was Variety A.\n\nIf the observation is Variety E and holding block constant, the SIZE will be 20.3 units smaller than if it was Variety A.\n\nIf the observation is Variety F and holding block constant, the SIZE will be 3.3 units larger than if it was Variety A.\nIf the observation is Variety A, increasing block size by 1 will increase the SIZE by 2.3.\nIf the observation is Variety B, increasing block size by 1 will increase the SIZE by 7.8.\nIf the observation is Variety C, increasing block size by 1 will increase the SIZE by 8.1.\nIf the observation is Variety D, increasing block size by 1 will increase the SIZE by 12.3.\nIf the observation is Variety E, increasing block size by 1 will increase the SIZE by 8.0.\nIf the observation is Variety F, increasing block size by 1 will increase the SIZE by 2.3.\n\n\n\n\n\n\n\n\nImportant\n\n\n\nWhen using interaction terms, it is important to remember the principle of parsimony. If we decide to model the interaction between variable A and variable B, we must include both variables in the model.",
    "crumbs": [
      "Home",
      "Linear modelling",
      "Fitting a model with categorical data"
    ]
  },
  {
    "objectID": "Modelling/Check your understanding.html",
    "href": "Modelling/Check your understanding.html",
    "title": "Check your understanding",
    "section": "",
    "text": "data.csv task\nDownload and load in the data.csv file. This contains 3 variables: x1, x2 and y.\n\n\nPlot y against x1; plot y against x2. What do you notice about the relationships?\nWhat does the design matrix of the following model look like? \\[y_i = \\beta_0 +\\beta_1 x_{1i} + \\beta_2 x_{2i} + \\epsilon_i.\\]\nFit this model in R, find the estimates of \\(\\beta_0\\),\\(\\beta_1\\) and \\(\\beta_2\\) and interpret them.\nFit a new model, \\[y_i = \\gamma_0 +\\gamma_1 x_{1i} + \\gamma_2 x_{2i}^2 + \\epsilon_i.\\] How do the estimates of \\(\\gamma\\) compare to the estimates of \\(\\beta\\)?\n\n\n\n\ncoursework.csv task\nDownload and load in the coursework.csv` file. This is a dataset of the coursework marks, out of 20, and the exam marks, out of 100.\n\n\nCreate coursework and exam variables in R.\nPlot exam against coursework with exam on the y axis.\nFor a simple linear regression model with exam as the response and coursework as the predictor variable.\nAccording to the model, for each extra coursework mark, how many extra exam marks were obtained?\nUsing the ‘fitted’ command in R, calculate the fitted values of the model.\n\nUse ?fitted to get more information about this command.\nThe ith fitted value is the value predicted by the model based on the ith observation.\n\nAdd the fitted line to the graph of exam against coursework.\n\nHint: use the abline function.\n\nCreate a new variable, coursework_percentage, that contains the coursework mark as a percentage.\nFit a new model with coursework_percentage as the predictor variable.\nWhat effect does the rescaling of the coursework marks have on the fitted values and on the parameters?\nPredict the exam score for a student that scored full marks in their coursework. Is there an issue with this prediction?\n\n\n\n\nAnswers to data.csv tasks\n\n\nCode\n```{r}\n###| Loading in file\ndata &lt;- read.csv(\"~/Documents/GitHub/Warwick Statistics Society R Course 2024-2025/Data/data.csv\")\n\n###| Plot\nplot(data$x1, data$y, xlab = \"x1\", ylab = \"y\", \n     main = \"Scatter plots of x1 against y\")\nplot(data$x2, data$y, xlab = \"x2\", ylab = \"y\", \n     main = \"Scatter plots of x2 against y\")\n```\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFrom the 2 graphs, we observe that y increases as x1 increases but y decreases as x2 increases.\nThe design matrix for this model will be of the form:\n\\[\n\\begin{pmatrix} 1 & 2.37 & 20.41 \\\\ 1 & 8.38 & 4.34 \\\\ ... & ... & ... \\end{pmatrix}.\n\\]\n\n\nCode\n```{r}\n###| Fitting the model\nm1 &lt;- lm(y ~ x1 + x2, data = data)\nm1\n```\n\n\n\nCall:\nlm(formula = y ~ x1 + x2, data = data)\n\nCoefficients:\n(Intercept)           x1           x2  \n   5.594377     0.614462    -0.004929  \n\n\nIf \\(x1 = 0\\) and \\(x2= 0\\), we expect \\(y=5.6\\). Assuming \\(x2\\) remains constant, if \\(x1\\) increases by 1, we expect \\(y\\) to increase by 0.6. Assuming \\(x1\\) remains constant, if \\(x1\\) increases by 1, we expect \\(y\\) to decrease by 0.005.\n\n\nCode\n```{r}\n###| Fitting the second model\nm2 &lt;- lm(y ~ x1 + I(x2^2), data = data) # NOTE THAT WE NEED TO USE I()!\nm2\n```\n\n\n\nCall:\nlm(formula = y ~ x1 + I(x2^2), data = data)\n\nCoefficients:\n(Intercept)           x1      I(x2^2)  \n  5.439e+00    6.307e-01   -2.652e-05  \n\n\nIf \\(x1 = 0\\) and \\(x2= 0\\), we expect \\(y=5.4\\). Assuming \\(x2\\) remains constant, if \\(x1\\) increases by 1, we expect \\(y\\) to increase by 0.6. Assuming \\(x1\\) remains constant, if \\(x1\\) increases by 1, we do not expect \\(y\\) to change (to 4 decimal places).\n\n\nAnswers to coursework.csv\n\n\nCode\n```{r}\n###| Loading in file\ncoursework.df &lt;- read.csv(\"~/Documents/GitHub/Warwick Statistics Society R Course 2024-2025/Data/coursework.csv\")\n\n###| Variable assigning\ncoursework &lt;- coursework.df$cw\nexam &lt;- coursework.df$exam\n\n###| Scatter plot\nplot(coursework,exam, xlab = \"Raw coursework mark\",\n     ylab = \"Exam mark\", main = \"Coursework against exam marks\")\n```\n\n\n\n\n\n\n\n\n\nFrom the scatter plot, we observe that a linear relationship between the raw coursework mark and the exam mark, where students who performed well in coursework also performed well on the exam and students who performed badly in the coursework also performed badly in the exam.\n\n\nCode\n```{r}\n###| Raw coursework model\nm1 &lt;- lm(exam ~ cw, data = coursework.df)\nm1\n```\n\n\n\nCall:\nlm(formula = exam ~ cw, data = coursework.df)\n\nCoefficients:\n(Intercept)           cw  \n     19.377        4.383  \n\n\nFor each extra mark obtained on the coursework, we expect the student to gain an extra \\(4.4\\%\\) in the exam.\n\n\nCode\n```{r}\n###| Fitted values\nfitted &lt;- fitted(m1)\n\n###| Adding fitted values as points\nplot(coursework,exam, xlab = \"Raw coursework mark\",\n     ylab = \"Exam mark\", main = \"Coursework against exam marks\")\npoints(coursework,fitted, col = \"blue\")\n\n###| Adding a line through the fitted points\nplot(coursework,exam, xlab = \"Raw coursework mark\",\n     ylab = \"Exam mark\", main = \"Coursework against exam marks\")\npoints(coursework,fitted, col = \"blue\")\nabline(a = m1$coefficients[1], b = m1$coefficients[2], col = \"blue\")\n```\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n```{r}\n###| Coursework as a percentage\ncoursework.df$coursework_perc &lt;- coursework/20\n\nm2 &lt;- lm(exam ~ coursework_perc, data = coursework.df)\nm2\n\nfitted_perc &lt;- fitted(m2)\nfitted_perc\n```\n\n\n\nCall:\nlm(formula = exam ~ coursework_perc, data = coursework.df)\n\nCoefficients:\n    (Intercept)  coursework_perc  \n          19.38            87.66  \n\n       1        2        3        4        5        6 \n41.29114 41.29114 63.20570 71.97152 80.73734 89.50316 \n\n\nThe fitted values and the intercept estimate are the same! However, the \\(\\beta\\) estimate is now 87.66, \\(20\\times 4.383\\).\nIf a student achieves \\(100\\%\\) in their coursework, we expect them to achive \\(19.38 + 87.66 = 107.04\\%\\) in the exam. This is a big problem as a student cannot achieve \\(&gt;100\\%\\)! It is very important to be careful when extrapolating as it is very easy to end up in unrealistic (or even impossible) situations.",
    "crumbs": [
      "Home",
      "Linear modelling",
      "Check your understanding"
    ]
  },
  {
    "objectID": "Data/Raw data.html#agriculture-data",
    "href": "Data/Raw data.html#agriculture-data",
    "title": "Data",
    "section": "Agriculture data",
    "text": "Agriculture data\n\n\nCode\n```{r}\n###| Agriculture data\nagriculture &lt;- data.frame(\"Variety\" = c(\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"A\", \"B\", \"C\", \"D\", \"E\", \"F\"),\n                          \"Block\" = c(1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8),\n                          \"SIZE\" = c(28, 23,27, 24,30,30,202,145,188,201,202,228,22,26,24,28,26, 25,165,201,185,231,178,221,27,28,27,30,26,27, 191,203,185,238,198,207,19,24,28,30,29,24,134,180,220,261,226,204),\n                          \"YIELD\" = c(28, 23,27, 24,30,30,202,145,188,201,202,228,22,26,24,28,26,25,165,201,185,231,178,221,27,28,27,30,26,27,191,203,185,238,198,207,19,24,28,30,29,24,134,180,220,261,226,204))\n```"
  },
  {
    "objectID": "Modelling/Diagnostics.html",
    "href": "Modelling/Diagnostics.html",
    "title": "Model diagnostics",
    "section": "",
    "text": "In the previous pages, we covered what a linear model is and how to fit a linear model. In this page, we will cover how to check a model fits the 4 key assumptions and what to do if it fails to meet an assumption.\nTo recap, the 4 key assumptions are:",
    "crumbs": [
      "Home",
      "Linear modelling",
      "Model diagnostics"
    ]
  },
  {
    "objectID": "Modelling/Diagnostics.html#generating-data",
    "href": "Modelling/Diagnostics.html#generating-data",
    "title": "Model diagnostics",
    "section": "Generating data",
    "text": "Generating data\nWe are going to create some data to illustrate good and bad model assumptions.\n\n\nCode\n```{r}\n###| For reproducability, we set a seed\nset.seed(419)\n\n###| Generating random numbers\na &lt;- runif(n = 100, min = 0, max = 10)\nb &lt;- rpois(n = 100, lambda = 2)\nc &lt;- runif(n = 100, min = -5, max = 10)\n\n###| Generating the response variables\ny1 &lt;- a + b\ny2 &lt;- a + b^2\ny3 &lt;- log(a)\n\n###| Storing as a dataframe\ndata &lt;- data.frame(\"a\" = a,\n                   \"b\" = b,\n                   \"c\" = c,\n                   \"y1\" = y1,\n                   \"y2\" = y2,\n                   \"y3\" = y3)\n\n###| First 6 rows\nhead(data)\n```\n\n\n         a b         c        y1        y2        y3\n1 9.786378 2 -4.673051 11.786378 13.786378 2.2809914\n2 3.318455 5 -3.948319  8.318455 28.318455 1.1994994\n3 8.329044 0 -4.219525  8.329044  8.329044 2.1197487\n4 2.087712 4 -2.410313  6.087712 18.087712 0.7360689\n5 3.048667 1  8.473026  4.048667  4.048667 1.1147043\n6 4.070241 1  3.784801  5.070241  5.070241 1.4037022"
  },
  {
    "objectID": "Modelling/Diagnostics.html#diagnostic-plots",
    "href": "Modelling/Diagnostics.html#diagnostic-plots",
    "title": "Model diagnostics",
    "section": "Diagnostic plots",
    "text": "Diagnostic plots\nOne way to test model assumptions is to look at the residual plots.\n\n\n\n\n\n\nNote\n\n\n\nA residual (or fitting deviation) is an estimate of the unobsereved statistical error. It is the difference between the observed \\(y_i\\) and the estimated \\(\\hat{y}_i\\), the value predicted by the model residuals.\n\n\nWe want our model’s predictions to be as close to the true observed values as possible, that is, we want to minimise the residuals. We also use the residuals to check if we are meeting the linearity and normality assumptions. We can also identify outliers this way.\n\nA good model\nTo explore what ideal residual plots look like, we are going to exactly fit the model \\[y1_i = a_i + b_i + \\epsilon_i.\\] Based on the way we have defined \\(y1\\), we know that this model should fit the data exactly. We plot several different diagnostic plots using the ‘plot()’ command.\nWe will explore each plot one by one:\n\n\nCode\n```{r}\n###| Fitting the model\nm1 &lt;- lm(y1 ~ a + b, data = data)\n\n###| Residual v fitted plot\nplot(m1, which = 1)\n```\n\n\n\n\n\n\n\n\n\nThe residuals v fitted values plot is a scatter plot of with the residuals on the y-axis and the fitted/predicted values on the x-axis. The red line (called the smoother) is a curve fitted to the residuals. If the structural component of the model is correct (i.e. the explanatory variables and not the errors), the smoother will be horizontal around 0.\nIn this example, we see a very flat smoother, centered at 0, with 3 labelled points that deviate from the general trend.\n\n\nCode\n```{r}\n###| Q-Q plot\nplot(m1, which = 2)\n```\n\n\n\n\n\n\n\n\n\nRecall that a model assumption is that the errors are normally distributed. The Q-Q plot allows us to check this assumption by plotting the absolute values of the standardized residuals on the y-axis and the theoretical quantiles of the standard half-normal distribution on the x-axis. If the errors are normally distributed, the dashed line will go through the origin and have a gradient of 1.\nIn this example, we see that the residuals do appear to be normally distributed, although at the tails, we do see 3 points that deviate from this.\n\n\nCode\n```{r}\n###| Cook's distance plot\nplot(m1, which = 4)\n```\n\n\n\n\n\n\n\n\n\nThis graph plots the Cook’s distance against the observation number, with the largest 3 values labelled. The Cook’s distance can be thought of as a measure of the influence of a particular observation. That is, it summarises how much the model changes, when you do and don’t include the ith data point.\nYou may notice that we have skipped several plots, namely: the location-scale plot and the standardized resivual v leverage plot. More information about diasgnotstic plots can be found here for those interested.\n\n\nA bad model\nNow, let us purposefully fit a bad model to see how the diagnostic plots change.\n\n\nCode\n```{r}\n###| Bad model example\nm2 &lt;- lm(y2 ~ a + b, data=data)\n\n###| Residual v fitted plot\nplot(m2, which = 1)\n\n###| Q-Q plot\nplot(m2, which = 2)\n```\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn the residuals v fitted values plot, we observe that the smoother has a parabolic shape. This indicates that there is a problem in how we have constructed our model - specifically we are failing to meet the linearity assumption. If we look back to how we defined y2 (\\(y2 = a + b^2\\)), this makes sense. We cannot capture the \\(b^2\\) nature of our data if we are only using \\(a+b\\) as our explanatory variables.\nIn the Q-Q plot, we note large deviations from the ideal dashed line at the upper tail. This indicates that our errors are not normally distributed, violating that assumption.\nSo, we conclude that \\(y2_i = a_i + b_i +\\epsilon_i\\) is a bad model as it violates the key model assumptions. But, how do we fix this?\n\n\nTransformations\nOn top of altering which explanatory variables we do and do not include in our model, we can transform our variables to make the model fit better.\nFor example, in the \\(y2\\) case, we can create a new variable \\(b2\\) that is \\(b^2\\) and include this transformed variable into our model. However, by the principle of parsimony, we also need to include \\(b\\) into the model as well.\n\n\nCode\n```{r}\n###| Modeeling y2\nm3 &lt;- lm(y2 ~ a + b + I(b^2), data = data)\n\n###| Residuals v fitted plot\nplot(m3, which = 1)\n\n###| Q-Q plot\nplot(m3, which = 2)\n```\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn the residuals plot, we observe a flat smoother. This indicates we are meeting the linearity assumption!\nIn the Q-Q plot, we see that the data follows the dashed line, baring 3 exceptions at the extreme. Thus, the model appears to meet the normally distributed errors assumption.\n\n\nAnother bad model\nTo further explore diagnostic plots, let us consider one more model: \\[y3_i = a_i + \\epsilon.\\]\n\n\nCode\n```{r}\n###| y3 = a\nm4 &lt;- lm(y3 ~ a, data = data)\n\n###| Residual plot\nplot(m4, which = 1)\n```\n\n\n\n\n\n\n\n\n\nFitting this model, we observe a curve shape in the smoother, indicating that we are violating the linearity assumption. As the shape is not symmetric, it doesn’t seem like this is can be corrected by using \\(a^2\\). Instead, we can try using a logarithm.\n\n\nCode\n```{r}\n###| y3 = log(a)\nm5 &lt;- lm(y3 ~ log(a), data = data)\n\n###| Residual plot\nplot(m5, which = 1)\n```\n\n\n\n\n\n\n\n\n\nNow, we observe the correct behaviour of the smoother."
  },
  {
    "objectID": "Modelling/Diagnostics.html#diagnostic-plots-with-noise",
    "href": "Modelling/Diagnostics.html#diagnostic-plots-with-noise",
    "title": "Model diagnostics",
    "section": "Diagnostic plots with noise",
    "text": "Diagnostic plots with noise\nThus far, we have used formulas to generate our response variables. This has resulted in very clearly defined behaviour from our models and diagnostic plots. However, in a normal scenario, the data we are given will have noise. So, we will add some normally distributed noise to our data and repeat the above.\n\n\nCode\n```{r}\n###| Adding noise\ndata2 &lt;- data\ndata2$y1 &lt;- data2$y1 + rnorm(n = 100, mean = 0, sd = 1)\ndata2$y2 &lt;- data2$y2 + rnorm(n = 100, mean = 0, sd = 1)\ndata2$y3 &lt;- data2$y3 + rnorm(n = 100, mean = 0, sd = 1)\n```\n\n\n\nA good model revisited\nOnce again, we will fit the model \\[y1_i = a_i + b_i + \\epsilon_i.\\] However, now we will use the noisy dataset.\n\n\nCode\n```{r}\n###| y1 model\nM1 &lt;- lm(y1 ~ a + b, data = data2)\nplot(M1,which=1)\nplot(M1, which = 2)\n```\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNow, there is a lot more variation in the residuals. However, we still observe a roughly flat smoother so the model does not appear to be violating the linearity assumption.\nThe Q-Q plot still follows the ideal general trend, athough the tails deviate slightly more.\n\n\nA bad model revisited\nNow, we fit both of the following models: \\[\\begin{align}\ny2_i & = a_i + b_i + \\epsilon_i, \\\\\ny2_i & = a_i + b_i + b_i^2 + \\epsilon_i.\n\\end{align}\\]\n(I have placed the graphs side by side for comparison using the ‘par(mfrow = c(1,2)))’ command. More information about this, and graphics more generally, appears here.)\n\n\nCode\n```{r}\n###| a + b\nM2 &lt;- lm(y2 ~ a + b, data = data2)\n\n###| a + b + b^2\nM3 &lt;- lm(y2 ~ a + b + I(b^2), data = data2)\n\n###| Plotting graphs side by side\npar(mfrow = c(1, 2))\n\nplot(M2,which=1)\nplot(M3,which=1)\n\nplot(M2, which = 2)\nplot(M3, which = 2)\n```\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn the residuals plot, we see the same general trends in behaviour that we saw before. The graph on the left, fitted with \\(a+b\\), displays the problematic parabolic behaviour in the smoother. The graph on the right, fitted with \\(a+b+b^2\\), has a flatter smoother.\nSimilarly, in the Q-Q plots, we observe that the left graph deviates at the tails more than the right graph.\n\n\nAnother bad model revisited\nNow, we fit both of the following models: \\[\\begin{align}\ny2_i & = a_i \\epsilon_i, \\\\\ny2_i & = \\log(a_i) + \\epsilon_i.\n\\end{align}\\]\nAgain, for ease, I have plotted the graphs side by side.\n\n\nCode\n```{r}\n###| a \nM4 &lt;- lm(y3 ~ a, data = data2)\n\n###| log(a)\nM5 &lt;- lm(y3 ~ log(a), data = data2)\n\n###| Plotting graphs side by side\npar(mfrow = c(1, 2))\n\nplot(M4,which=1)\nplot(M5,which=1)\n\nplot(M4, which = 2)\nplot(M5, which = 2)\n```\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThis time, it is much less clear which of these two models is better.\nComparing the Q-Q plots, the left graph appears to deviate more on the lower tail. So, the \\(\\log(a)\\) model appears to better meet the normality assumption.\nHowever, both models have issues with the smoother in the residuals v fitted graphs. For the \\(y3 ~ a\\) model, there is a general curve shape to the smoother and residuals that violates the linearity assumption. While this appears to be fixed somewhat by using \\(\\log(a)\\) instead, now the residuals get further and further away from the smoother and the fitted values get larger. (This shape is known as a megaphone.) This violates the assumption that the errors have constant variance.\nThus, we conclude that it appears neither model is a good fit."
  },
  {
    "objectID": "Modelling/Diagnostics.html#a-good-model",
    "href": "Modelling/Diagnostics.html#a-good-model",
    "title": "Model diagnostics",
    "section": "A good model",
    "text": "A good model\nTo explore what ideal residual plots look like, we are going to exactly fit the model \\[y1_i = a_i + b_i + \\epsilon_i.\\] Based on the way we have defined \\(y1\\) (y1 &lt;- a + b), we know that this model should fit the data almost exactly. (The almost stems from the random noise from \\(\\epsilon\\).) We plot several different diagnostic plots using the ‘plot()’ command.\nWe will explore each plot one by one.\n\n\nCode\n```{r}\n###| Fitting the model\nm1 &lt;- lm(y1 ~ a + b, data = data)\n\n###| Residual v fitted plot\nplot(m1, which = 1)\n```\n\n\n\n\n\n\n\n\n\nThe residuals v fitted values plot is a scatter plot of with the residuals on the y-axis and the fitted/predicted values on the x-axis. The red line (called the smoother) is a curve fitted to the residuals. If the structural component of the model is correct (i.e. the explanatory variables and not the errors), the smoother will be horizontal around 0.\nIn this example, we see a very flat smoother, centered at 0, with 3 labelled points that deviate from the general trend.\n\n\nCode\n```{r}\n###| Q-Q plot\nplot(m1, which = 2)\n```\n\n\n\n\n\n\n\n\n\nRecall that a model assumption is that the errors are normally distributed. The Q-Q plot allows us to check this assumption by plotting the absolute values of the standardized residuals on the y-axis and the theoretical quantiles of the standard half-normal distribution on the x-axis. If the errors are normally distributed, the dashed line will go through the origin and have a gradient of 1.\nIn this example, we see that the residuals do appear to be normally distributed, although at the tails, we do see 3 points that deviate from this.\n\n\nCode\n```{r}\n###| Cook's distance plot\nplot(m1, which = 4)\n```\n\n\n\n\n\n\n\n\n\nThis graph plots the Cook’s distance against the observation number, with the largest 3 values labelled. The Cook’s distance can be thought of as a measure of the influence of a particular observation. That is, it summarises how much the model changes, when you do and don’t include the ith data point.\nYou may notice that we have skipped several plots, namely: the location-scale plot and the standardized resivual v leverage plot. More information about diasgnotstic plots can be found here for those interested.",
    "crumbs": [
      "Home",
      "Linear modelling",
      "Model diagnostics"
    ]
  },
  {
    "objectID": "Modelling/Diagnostics.html#a-bad-model",
    "href": "Modelling/Diagnostics.html#a-bad-model",
    "title": "Model diagnostics",
    "section": "A bad model",
    "text": "A bad model\nNow, let us purposefully fit a bad model to see how the diagnostic plots change.\n\n\nCode\n```{r}\n###| Bad model example\nm2 &lt;- lm(y2 ~ a + b, data=data)\n\n###| Residual v fitted plot\nplot(m2, which = 1)\n```\n\n\n\n\n\n\n\n\n\nIn the residuals v fitted values plot, we observe that the smoother has a parabolic shape. This indicates that there is a problem in how we have constructed our model - specifically we are failing to meet the linearity assumption. If we look back to how we defined y2 (y2 &lt;- a + b^2), this makes sense. We cannot capture the \\(b^2\\) nature of our data if we are only using \\(a+b\\) as our explanatory variables.\n\n\nCode\n```{r}\n###| Q-Q plot\nplot(m2, which = 2)\n```\n\n\n\n\n\n\n\n\n\nIn the Q-Q plot, we note large deviations from the ideal dashed line at the upper tail. This indicates that our errors are not normally distributed, violating that assumption.\nSo, we conclude that \\(y2_i = a_i + b_i +\\epsilon_i\\) is a bad model as it violates the key model assumptions. But, how do we fix this?",
    "crumbs": [
      "Home",
      "Linear modelling",
      "Model diagnostics"
    ]
  },
  {
    "objectID": "Modelling/Diagnostics.html#transformations",
    "href": "Modelling/Diagnostics.html#transformations",
    "title": "Model diagnostics",
    "section": "Transformations",
    "text": "Transformations\nOn top of choosing which variables we include in our model, we can transform our variables to make the model fit better.\nFor example, in the \\(y2\\) case, we can create a new variable \\(b2\\) that is \\(b^2\\) and include this transformed variable into our model. However, by the principle of parsimony, we also need to include \\(b\\) into the model as well.\n\n\nCode\n```{r}\n###| Modeeling y2\nm3 &lt;- lm(y2 ~ a + b + I(b^2), data = data)\n\n###| Residuals v fitted plot\nplot(m3, which = 1)\n```\n\n\n\n\n\n\n\n\n\nIn the residuals plot, we observe a flat smoother. This indicates we are meeting the linearity assumption!\n\n\nCode\n```{r}\n###| Q-Q plot\nplot(m3, which = 2)\n```\n\n\n\n\n\n\n\n\n\nIn the Q-Q plot, we see that the data follows the dashed line, baring 3 exceptions at the extreme. Thus, the model appears to meet the normally distributed errors assumption.",
    "crumbs": [
      "Home",
      "Linear modelling",
      "Model diagnostics"
    ]
  },
  {
    "objectID": "Modelling/Diagnostics.html#another-bad-model",
    "href": "Modelling/Diagnostics.html#another-bad-model",
    "title": "Model diagnostics",
    "section": "Another bad model",
    "text": "Another bad model\nTo further explore diagnostic plots, let us consider one more model: \\[y3_i = a_i + \\epsilon.\\]\n\n\nCode\n```{r}\n###| y3 = a\nm4 &lt;- lm(y3 ~ a, data = data)\n\n###| Residual plot\nplot(m4, which = 1)\n```\n\n\n\n\n\n\n\n\n\nFitting this model, we observe a curve shape in the smoother, indicating that we are violating the linearity assumption. As the shape is not symmetric, it doesn’t seem like this is can be corrected by using \\(a^2\\). Instead, we can try using a logarithm.\n\n\nCode\n```{r}\n###| y3 = log(a)\nm5 &lt;- lm(y3 ~ log(a), data = data)\n\n###| Residual plot\nplot(m5, which = 1)\n```\n\n\n\n\n\n\n\n\n\nNow, we observe the correct behaviour of the smoother.",
    "crumbs": [
      "Home",
      "Linear modelling",
      "Model diagnostics"
    ]
  },
  {
    "objectID": "Modelling/Diagnostics.html#a-good-model-revisited",
    "href": "Modelling/Diagnostics.html#a-good-model-revisited",
    "title": "Model diagnostics",
    "section": "A good model revisited",
    "text": "A good model revisited\nOnce again, we will fit the model \\[y1_i = a_i + b_i + \\epsilon_i.\\] However, we will use the noisy dataset.\n\n\nCode\n```{r}\n###| y1 model\nM1 &lt;- lm(y1 ~ a + b, data = data2)\nplot(M1,which=1)\nplot(M1, which = 2)\n```\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNow, there is a lot more variation in the residuals. However, we still observe a roughly flat smoother so the model does not appear to be violating the linearity assumption.\nThe Q-Q plot still follows the ideal general trend, although the tails deviate slightly more.",
    "crumbs": [
      "Home",
      "Linear modelling",
      "Model diagnostics"
    ]
  },
  {
    "objectID": "Modelling/Diagnostics.html#a-bad-model-revisited",
    "href": "Modelling/Diagnostics.html#a-bad-model-revisited",
    "title": "Model diagnostics",
    "section": "A bad model revisited",
    "text": "A bad model revisited\nNow, we fit both of the following models: \\[\\begin{align}\ny2_i & = a_i + b_i + \\epsilon_i, \\\\\ny2_i & = a_i + b_i + b_i^2 + \\epsilon_i.\n\\end{align}\\]\n\n\n\n\n\n\nNote\n\n\n\nI have placed the graphs side by side for comparison using the par(mfrow = c(1,2))) command. More information about this, and graphics more generally, appears here.\n\n\n\n\nCode\n```{r}\n###| a + b\nM2 &lt;- lm(y2 ~ a + b, data = data2)\n\n###| a + b + b^2\nM3 &lt;- lm(y2 ~ a + b + I(b^2), data = data2)\n\n###| Plotting graphs side by side\npar(mfrow = c(1, 2))\nplot(M2,which=1)\nplot(M3,which=1)\n```\n\n\n\n\n\n\n\n\n\n\n\nCode\n```{r}\n###| Plotting graphs side by side\npar(mfrow = c(1, 2))\nplot(M2, which = 2)\nplot(M3, which = 2)\n```\n\n\n\n\n\n\n\n\n\nIn the residuals plot, we see the same general trends in behaviour that we saw before. The graph on the left, fitted with \\(a+b\\), displays the problematic parabolic behaviour in the smoother. The graph on the right, fitted with \\(a+b+b^2\\), has a flatter smoother.\nSimilarly, in the Q-Q plots, we observe that the left graph deviates at the tails more than the right graph.",
    "crumbs": [
      "Home",
      "Linear modelling",
      "Model diagnostics"
    ]
  },
  {
    "objectID": "Modelling/Diagnostics.html#another-bad-model-revisited",
    "href": "Modelling/Diagnostics.html#another-bad-model-revisited",
    "title": "Model diagnostics",
    "section": "Another bad model revisited",
    "text": "Another bad model revisited\nNow, we fit both of the following models: \\[\\begin{align}\ny2_i & = a_i \\epsilon_i, \\\\\ny2_i & = \\log(a_i) + \\epsilon_i.\n\\end{align}\\]\nAgain, for ease, I have plotted the graphs side by side.\n\n\nCode\n```{r}\n###| a \nM4 &lt;- lm(y3 ~ a, data = data2)\n\n###| log(a)\nM5 &lt;- lm(y3 ~ log(a), data = data2)\n\n###| Plotting graphs side by side\npar(mfrow = c(1, 2))\n\nplot(M4,which=1)\nplot(M5,which=1)\n\nplot(M4, which = 2)\nplot(M5, which = 2)\n```\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThis time, it is much less clear which of these two models is better.\nComparing the Q-Q plots, the left graph appears to deviate more on the lower tail. So, the \\(\\log(a)\\) model appears to better meet the normality assumption.\nHowever, both models have issues with the smoother in the residuals v fitted graphs. For the \\(y3 ~ a\\) model, there is a general curve shape to the smoother and residuals that violates the linearity assumption. While this appears to be fixed somewhat by using \\(\\log(a)\\) instead, now the residuals get further and further away from the smoother and the fitted values get larger. (This shape is known as a megaphone.) This violates the assumption that the errors have constant variance.\nThus, we conclude that it appears neither model is a good fit.",
    "crumbs": [
      "Home",
      "Linear modelling",
      "Model diagnostics"
    ]
  },
  {
    "objectID": "EDA/Cars dataset.html",
    "href": "EDA/Cars dataset.html",
    "title": "cars dataset",
    "section": "",
    "text": "A key step when first reviewing a dataset is to determine the variables and the important properties of each variable. For categorical data, this may be finding the names of the different categories and the count of each category (the number of elements). For continuous data, this may be finding the minimum, maximum, mean and median values.\nThis page will go through some practical examples using the inbuilt mtcars dataset.",
    "crumbs": [
      "Home",
      "Exploratory data analysis",
      "cars dataset"
    ]
  },
  {
    "objectID": "EDA/Cars dataset.html#vs-and-am-variables",
    "href": "EDA/Cars dataset.html#vs-and-am-variables",
    "title": "cars dataset",
    "section": "vs and am variables",
    "text": "vs and am variables\nIn the above summary output, we observe that a mean is given for the vs and am variables. However, from the history about the dataset, we know that these variables can only take values \\(0\\) and \\(1\\). Thus, it would be better for these values to be treated as factors.\nThere are several ways to do this. I give the first example using base R. The second uses the dplyr package, a very handy package for data manipulation.\n\n\nCode\n```{r}\n###| Factoring using base R\ncars_data$am &lt;- factor(cars_data$am)\ncars_data$vs &lt;- factor(cars_data$vs)\n\n###| Summary\nsummary(cars_data)\n```\n\n\n      mpg             cyl             disp             hp       \n Min.   :10.40   Min.   :4.000   Min.   : 71.1   Min.   : 52.0  \n 1st Qu.:15.43   1st Qu.:4.000   1st Qu.:120.8   1st Qu.: 96.5  \n Median :19.20   Median :6.000   Median :196.3   Median :123.0  \n Mean   :20.09   Mean   :6.188   Mean   :230.7   Mean   :146.7  \n 3rd Qu.:22.80   3rd Qu.:8.000   3rd Qu.:326.0   3rd Qu.:180.0  \n Max.   :33.90   Max.   :8.000   Max.   :472.0   Max.   :335.0  \n      drat             wt             qsec       vs     am          gear      \n Min.   :2.760   Min.   :1.513   Min.   :14.50   0:18   0:19   Min.   :3.000  \n 1st Qu.:3.080   1st Qu.:2.581   1st Qu.:16.89   1:14   1:13   1st Qu.:3.000  \n Median :3.695   Median :3.325   Median :17.71                 Median :4.000  \n Mean   :3.597   Mean   :3.217   Mean   :17.85                 Mean   :3.688  \n 3rd Qu.:3.920   3rd Qu.:3.610   3rd Qu.:18.90                 3rd Qu.:4.000  \n Max.   :4.930   Max.   :5.424   Max.   :22.90                 Max.   :5.000  \n      carb      \n Min.   :1.000  \n 1st Qu.:2.000  \n Median :2.000  \n Mean   :2.812  \n 3rd Qu.:4.000  \n Max.   :8.000  \n\n\n\n\nCode\n```{r}\n###| Package requirement\n# install.packages(\"dplyr\")\nlibrary(dplyr)\n```\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n\nCode\n```{r}\n###| Save the dataset\ncars_dplyr &lt;- mtcars\n\n###| Factoring variables\ncars_dplyr &lt;- cars_dplyr %&gt;%\n  mutate(vs = factor(vs),\n         am = factor(am))\n\n###| Summary of only vs and am columns\nsummary(cars_data[,c(8,9)])\n```\n\n\n vs     am    \n 0:18   0:19  \n 1:14   1:13",
    "crumbs": [
      "Home",
      "Exploratory data analysis",
      "cars dataset"
    ]
  },
  {
    "objectID": "EDA/Cars dataset.html#observation-names",
    "href": "EDA/Cars dataset.html#observation-names",
    "title": "cars dataset",
    "section": "Observation names",
    "text": "Observation names\nWe can find the names of each row using the rownames() command.\n\n\nCode\n```{r}\n###| Row/observation names\nrownames(cars_data)\n```\n\n\n [1] \"Mazda RX4\"           \"Mazda RX4 Wag\"       \"Datsun 710\"         \n [4] \"Hornet 4 Drive\"      \"Hornet Sportabout\"   \"Valiant\"            \n [7] \"Duster 360\"          \"Merc 240D\"           \"Merc 230\"           \n[10] \"Merc 280\"            \"Merc 280C\"           \"Merc 450SE\"         \n[13] \"Merc 450SL\"          \"Merc 450SLC\"         \"Cadillac Fleetwood\" \n[16] \"Lincoln Continental\" \"Chrysler Imperial\"   \"Fiat 128\"           \n[19] \"Honda Civic\"         \"Toyota Corolla\"      \"Toyota Corona\"      \n[22] \"Dodge Challenger\"    \"AMC Javelin\"         \"Camaro Z28\"         \n[25] \"Pontiac Firebird\"    \"Fiat X1-9\"           \"Porsche 914-2\"      \n[28] \"Lotus Europa\"        \"Ford Pantera L\"      \"Ferrari Dino\"       \n[31] \"Maserati Bora\"       \"Volvo 142E\"         \n\n\nLooking at the list, we can see some cars are made by the same manufacturer. It may be important to consider this in future analysis. So, let us create a new variable, manufacturer, that will account for this.\n\n\nCode\n```{r}\n###| New variable\ncars_data$manufacturer &lt;- factor(rownames(cars_data))\n\n###| Grouping the manufacturers\nlevels(cars_data$manufacturer) &lt;- list(AMC = \"AMC Javelin\", \n                                       Cadillac = \"Cadillac Fleetwood\" ,\n                                       Camaro = \"Camaro Z28\", \n                                       Datsum = \"Datsun 710\",\n                                       Dodge = \"Dodge Challenger\",\n                                       Duster = \"Duster 360\",\n                                       Ferrari = \"Ferrari Dino\",\n                                       Fiat = c(\"Fiat 128\",\"Fiat X1-9\"),\n                                       Ford = \"Ford Pantera L\",\n                                       Honda = \"Honda Civic\",\n                                       Hornet = c(\"Hornet 4 Drive\",\"Hornet Sportabout\"),\n                                       Lincoln = \"Lincoln Continental\",\n                                       Chrysler = \"Chrysler Imperial\",\n                                       Lotus = \"Lotus Europa\",\n                                       Maserati = \"Maserati Bora\",\n                                       Mazda = c(\"Mazda RX4\",\"Mazda RX4 Wag\"),\n                                       Merc = c(\"Merc 230\",\"Merc 240D\",\"Merc 280\",\n                                                \"Merc 280C\",\"Merc 450SE\",\"Merc 450SL\",\n                                                \"Merc 450SLC\"),\n                                       Pontiac = \"Pontiac Firebird\",\n                                       Porsche = \"Porsche 914-2\",\n                                       Toyota = c(\"Toyota Corolla\",\"Toyota Corona\"),\n                                       Valiant = \"Valiant\",\n                                       Volvo = \"Volvo 142E\")\n\n###| Checking output\ncars_data$manufacturer\n```\n\n\n [1] Mazda    Mazda    Datsum   Hornet   Hornet   Valiant  Duster   Merc    \n [9] Merc     Merc     Merc     Merc     Merc     Merc     Cadillac Lincoln \n[17] Chrysler Fiat     Honda    Toyota   Toyota   Dodge    AMC      Camaro  \n[25] Pontiac  Fiat     Porsche  Lotus    Ford     Ferrari  Maserati Volvo   \n22 Levels: AMC Cadillac Camaro Datsum Dodge Duster Ferrari Fiat Ford ... Volvo\n\n\nNow we have a variable that lists manufacturers. We can check the categories using the levels() command.\n\n\nCode\n```{r}\n###| Levels()\nlevels(cars_data$manufacturer)\n```\n\n\n [1] \"AMC\"      \"Cadillac\" \"Camaro\"   \"Datsum\"   \"Dodge\"    \"Duster\"  \n [7] \"Ferrari\"  \"Fiat\"     \"Ford\"     \"Honda\"    \"Hornet\"   \"Lincoln\" \n[13] \"Chrysler\" \"Lotus\"    \"Maserati\" \"Mazda\"    \"Merc\"     \"Pontiac\" \n[19] \"Porsche\"  \"Toyota\"   \"Valiant\"  \"Volvo\"",
    "crumbs": [
      "Home",
      "Exploratory data analysis",
      "cars dataset"
    ]
  },
  {
    "objectID": "EDA/Cars dataset.html#should-it-be-categorical-or-continuous",
    "href": "EDA/Cars dataset.html#should-it-be-categorical-or-continuous",
    "title": "cars dataset",
    "section": "Should it be categorical or continuous?",
    "text": "Should it be categorical or continuous?\nThere a few clear cut instances in the cars dataset where the variables should be categorical. We have addressed these: vm, am and manufacturer. However, there are instances where it is less clear.\nFor example, consider the cylinders variable. In our data, we have observations with 3 distinct categories: 4, 6 and 8. (We can find this with unique() function.)\n\n\nCode\n```{r}\n###| Cylinders\nunique(cars_data$cyl)\n```\n\n\n[1] 6 4 8\n\n\nThus, we could argue we should treat cylinders as categorical data. However, treating cylinders as categorical removes the ability to treat this as a single variable. As one variable, we could test how increasing the number of cylinders impacts performance.\nWhen we come to modelling, we should test models with cylinders treated as a continuous and a categorical variable.",
    "crumbs": [
      "Home",
      "Exploratory data analysis",
      "cars dataset"
    ]
  },
  {
    "objectID": "EDA/summary tables.html",
    "href": "EDA/summary tables.html",
    "title": "dplyr: summary tables",
    "section": "",
    "text": "We begin by loading in the cars dataset we used on the previous page (the code required is available below if needed). Please note that we want to use the version that has the manufacturers included!\n\n\nCode\n```{r}\n#| code-fold: true\n\n###| Code to create the dataset used in previous pages\ncars_data &lt;- mtcars\n\ncars_data$am &lt;- factor(cars_data$am)\ncars_data$vs &lt;- factor(cars_data$vs)\n\ncars_data$manufacturer &lt;- factor(rownames(cars_data))\nlevels(cars_data$manufacturer) &lt;- list(AMC = \"AMC Javelin\", \n                                       Cadillac = \"Cadillac Fleetwood\" ,\n                                       Camaro = \"Camaro Z28\", \n                                       Datsum = \"Datsun 710\",\n                                       Dodge = \"Dodge Challenger\",\n                                       Duster = \"Duster 360\",\n                                       Ferrari = \"Ferrari Dino\",\n                                       Fiat = c(\"Fiat 128\",\"Fiat X1-9\"),\n                                       Ford = \"Ford Pantera L\",\n                                       Honda = \"Honda Civic\",\n                                       Hornet = c(\"Hornet 4 Drive\",\"Hornet Sportabout\"),\n                                       Lincoln = \"Lincoln Continental\",\n                                       Chrysler = \"Chrysler Imperial\",\n                                       Lotus = \"Lotus Europa\",\n                                       Maserati = \"Maserati Bora\",\n                                       Mazda = c(\"Mazda RX4\",\"Mazda RX4 Wag\"),\n                                       Merc = c(\"Merc 230\",\"Merc 240D\",\"Merc 280\",\n                                                \"Merc 280C\",\"Merc 450SE\",\"Merc 450SL\",\n                                                \"Merc 450SLC\"),\n                                       Pontiac = \"Pontiac Firebird\",\n                                       Porsche = \"Porsche 914-2\",\n                                       Toyota = c(\"Toyota Corolla\",\"Toyota Corona\"),\n                                       Valiant = \"Valiant\",\n                                       Volvo = \"Volvo 142E\")\n```\n\n\n\n\nCode\n```{r}\n###| Checking the data is correct\nhead(cars_data)\n```\n\n\n                   mpg cyl disp  hp drat    wt  qsec vs am gear carb\nMazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4\nDatsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1\nHornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1\nHornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2\nValiant           18.1   6  225 105 2.76 3.460 20.22  1  0    3    1\n                  manufacturer\nMazda RX4                Mazda\nMazda RX4 Wag            Mazda\nDatsun 710              Datsum\nHornet 4 Drive          Hornet\nHornet Sportabout       Hornet\nValiant                Valiant\n\n\n\nA basic summary table\nTo create a summary table, we could manually calculate every entry and then create a dataset of these values and then create the table. However, it is much quicker (and easier) to use the summarise() function that comes with the dplyr package.\n\n\n\n\n\n\nNote\n\n\n\nThe dplyr package will be installed/active if you have tidyverse. Alternatively, you can directly install and activate the package with the following commands:\n\n\nCode\n```{r}\n#| warning: false # will remove output messages\n\n###| Package downloading and activating\n# install.packages(\"dplyr\")\nlibrary(dplyr)\n```\n\n\nIf you are using RStudio, you can check which packages are installed using the bottom right window.\n\n\nThe following code gives some examples of how to extract various summary statistics using the summarise() command.\n\n\nCode\n```{r}\n###| Basic summary table on continuous data\ncars_data %&gt;%\n  summarise(\"Num. observations\" = n(),\n            \"Mean mpg\" = mean(mpg),\n            \"Range displacement\" = max(disp)-min(disp),\n            \"Median horsepower\" = median(hp))\n```\n\n\n  Num. observations Mean mpg Range displacement Median horsepower\n1                32 20.09062              400.9               123\n\n\nThings get more complicated for categorical factors. We may need to use the length(), which() and unique() functions to find our desired statistics.\n\n\nCode\n```{r}\n###| Basic summary table on categorical data\ncars_data %&gt;%\n  summarise(\"vs 1\" = length(which(vs == 1)),\n            \"am 0\" = length(which(am == 0)),\n            \"Num. manufacturers\" = length(unique(manufacturer))\n  )\n```\n\n\n  vs 1 am 0 Num. manufacturers\n1   14   19                 22\n\n\n\n\nCylinder level exploration\nRecall that we identified 3 distinct cylinder levels (check using unique(cars_data$cyl)). To do this, we will use the group_by() function.\n\n\nCode\n```{r}\n###| Basic summary table grouped by cylinders\ncars_data %&gt;%\n  group_by(cyl) %&gt;%\n  summarise(\"Num. observations\" = n(),\n            \"Mean mpg\" = mean(mpg),\n            \"Range displacement\" = max(disp)-min(disp),\n            \"Median horsepower\" = median(hp),\n            \"vs 1\" = length(which(vs == 1)),\n            \"am 0\" = length(which(am == 0)),\n            \"Num. manufacturers\" = length(unique(manufacturer))\n  )\n```\n\n\n# A tibble: 3 × 8\n    cyl `Num. observations` `Mean mpg` `Range displacement` `Median horsepower`\n  &lt;dbl&gt;               &lt;int&gt;      &lt;dbl&gt;                &lt;dbl&gt;               &lt;dbl&gt;\n1     4                  11       26.7                 75.6                 91 \n2     6                   7       19.7                113                  110 \n3     8                  14       15.1                196.                 192.\n# ℹ 3 more variables: `vs 1` &lt;int&gt;, `am 0` &lt;int&gt;, `Num. manufacturers` &lt;int&gt;\n\n\n\n\n\n\n\n\nImportant\n\n\n\nIt is important to note that this summary table had \\(3\\) rows and not \\(1\\)! The statistics in each row correspond to the cars that had X number of cylinders. For example, of the \\(11\\) cars with \\(4\\) cylinders, the mean mpg was \\(26.6\\), the displacement range \\(75.6\\) etc…\n\n\nWhen reading off this table, we can note a few things about the different types of cars:\n\n\nFewer cars had \\(6\\) cylinders than \\(4\\) or \\(8\\).\nAs the number of cylinders increased, the mean mpg decreased, the displacement range increased, and the median horsepower increased.\nNo \\(8\\) cylinder cars had vs 1.\nThere is no clear pattern in the am 0 or manufacturer identifiable from this table.\n\n\n\n\nMaking the tables more readable\nThus far, we have relied on the raw R output to read the tables. This is not ideal for reports or long periods of work. Instead, we can use the kable() function from the kableExtra package for neat tables.\n\n\nCode\n```{r}\n###| Package\n# install.packages(\"kableExtra\")\nlibrary(kableExtra)\n```\n\n\n\nAttaching package: 'kableExtra'\n\n\nThe following object is masked from 'package:dplyr':\n\n    group_rows\n\n\nCode\n```{r}\n###| Grouped summary table \nsummary &lt;- cars_data %&gt;%\n  group_by(cyl) %&gt;%\n  summarise(\"Num. observations\" = n(),\n            \"Mean mpg\" = mean(mpg),\n            \"Range displacement\" = max(disp)-min(disp),\n            \"Median horsepower\" = median(hp),\n            \"vs 1\" = length(which(vs == 1)),\n            \"am 0\" = length(which(am == 0)),\n            \"Num. manufacturers\" = length(unique(manufacturer))\n  )\n\n###| Output\nkable(summary)\n```\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncyl\nNum. observations\nMean mpg\nRange displacement\nMedian horsepower\nvs 1\nam 0\nNum. manufacturers\n\n\n\n\n4\n11\n26.66364\n75.6\n91.0\n10\n3\n8\n\n\n6\n7\n19.74286\n113.0\n110.0\n4\n4\n5\n\n\n8\n14\n15.10000\n196.2\n192.5\n0\n12\n12\n\n\n\n\n\nWe can continue to change various arguments of the kable function to get truly beautiful tables. An excellent site for this is LINK. A quick example of some commands are the following:\n\n\nCode\n```{r}\n###| Example kable extra\nkable(summary, booktabs = TRUE, \n      col.names = c(\"Cylinders\",\"Total\",\"Mean MPG\",\"Displacement range\",\n                    \"Median horsepower\",\"Num vs 1\",\"Num am 0\",\n                    \"Num unique manufacturers\")) %&gt;%\n  add_header_above(c(\" \" = 1, \"Summary Statistics\" = 7))\n```\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSummary Statistics\n\n\n\nCylinders\nTotal\nMean MPG\nDisplacement range\nMedian horsepower\nNum vs 1\nNum am 0\nNum unique manufacturers\n\n\n\n\n4\n11\n26.66364\n75.6\n91.0\n10\n3\n8\n\n\n6\n7\n19.74286\n113.0\n110.0\n4\n4\n5\n\n\n8\n14\n15.10000\n196.2\n192.5\n0\n12\n12",
    "crumbs": [
      "Home",
      "Exploratory data analysis",
      "dplyr: summary tables"
    ]
  },
  {
    "objectID": "Modelling/Linear modelling intro.html",
    "href": "Modelling/Linear modelling intro.html",
    "title": "Introduction",
    "section": "",
    "text": "This section will begin by introducing a linear model, the key assumptions we must make to fit such a model and model diagnostics.\nSpecifically, the pages cover the following:\n\n\nWhat is a linear model?\n\nModel assumptions, with extra notes on linearity\nPrinciple of parsimony\n\nA continuous data example\n\nUsing lm() and anova()\n\nA categorical data example\n\nIntercepts and reference terms\nInteraction terms\n\nCheck your understanding by fitting various models on the data.csv and coursework.csv files.",
    "crumbs": [
      "Home",
      "Linear modelling",
      "Introduction"
    ]
  },
  {
    "objectID": "Data/Raw data.html#data.csv",
    "href": "Data/Raw data.html#data.csv",
    "title": "Data",
    "section": "data.csv",
    "text": "data.csv\n\n\nCode\n```{r}\n###| data.csv data\ndata &lt;- data.frame(\"x1\" = c(2.37, 8.38, 7.70, 5.52, 4.41, 5.98, 3.53, 2.28, 2.88, 5.91, 6.88, 2.75, 8.17, 3.38, 8.39, 3.36, 9.53, 3.61, 7.80, 2.20, 9.04, 5.21, 3.96, 9.07, 4.90, 9.27, 6.81, 6.64, 5.26, 8.31, 6.27, 5.17, 5.37, 3.25, 2.60, 4.68, 8.11, 4.82, 5.15, 4.24, 9.17, 4.48, 9.45, 4.99, 4.84, 9.83, 8.19, 2.56, 2.89, 9.75, 9.78, 7.12, 7.41, 6.30, 8.51, 6.65, 3.19, 5.43, 9.14, 7.60, 7.12, 9.26, 2.42, 9.65, 7.43, 2.67, 2.32, 9.05, 4.44, 7.25, 5.85, 2.26, 2.31, 2.10, 5.88, 8.54, 8.32, 4.32, 2.78, 5.69, 3.67, 2.38, 6.95, 6.19, 7.02, 4.96, 9.28, 7.69, 2.32, 6.96, 6.61, 4.63, 5.66, 3.22, 5.88, 4.41, 8.54, 8.73, 5.41, 8.25),\n                   \"x2\" = c(20.41, 4.34, 8.42, 3.59, 10.91, 9.56, 12.69, 138.84, 23.59, 2.31, 11.70, 59.57, 4.87, 18.75, 2.93, 17.42, 5.20, 5.28, 3.87, 20.17, 3.96, 10.24, 18.88, 3.98, 26.57, 4.15, 6.16, 5.98, 11.39, 3.53, 12.69, 6.26, 10.55, 42.94, 43.11, 52.78, 2.40, 17.09, 9.06, 21.93, 2.74, 10.55, 4.15, 23.82, 13.05, 1.82, 3.47, 31.44, 19.23, 3.43, 1.95, 12.40, 6.09, 3.36, 8.02, 8.91, 35.90, 15.56, 1.27, 5.13, 5.02, 2.90, 40.68, 6.46, 5.82, 12.67, 16.56, 1.34, 23.58, 9.46, 5.93, 13.97, 58.33, 61.60, 5.84, 2.96, 4.49, 8.51, 40.62, 5.56, 14.71, 25.94, 3.14, 13.14, 2.35, 22.47, 2.36, 2.05, 40.24, 6.95, 14.36, 8.20, 7.19, 24.89, 6.31, 28.04, 4.33, 5.26, 17.58, 15.15),\n                  \"y\" =  c(6.53, 10.72, 10.18,  8.85, 8.31, 9.29, 8.06, 6.53, 7.21, 9.28, 9.91, 7.04, 10.49, 7.67, 10.64, 7.86, 11.43, 8.13, 10.48, 6.30, 11.18, 8.71, 7.97, 11.20, 8.57, 10.90, 9.40, 9.51, 8.80, 10.54, 9.66,8.83,  9.12,  7.25,  6.52,  8.54, 10.99,  8.90 , 8.83 , 8.08, 11.07, 8.62, 11.03, 8.43, 8.68, 11.18, 10.58, 6.93, 7.08, 11.41, 11.27, 9.96, 10.48, 9.75, 10.66, 9.85, 7.24, 9.04, 11.18, 10.32, 10.14, 11.04, 6.49, 11.41, 10.06, 7.15, 6.65, 10.91, 8.51, 9.83, 9.42, 6.54, 6.90, 6.36, 9.07, 10.81, 10.91, 8.04, 7.15, 9.14, 7.60, 6.59, 9.97, 9.24, 9.95, 8.35, 11.03, 10.61, 6.57, 9.66, 10.09, 8.74, 9.03, 7.28, 9.52, 8.45, 10.79, 11.08, 9.09, 10.50))\n```"
  },
  {
    "objectID": "Data/Raw data.html#coursework.csv",
    "href": "Data/Raw data.html#coursework.csv",
    "title": "Data",
    "section": "coursework.csv",
    "text": "coursework.csv\n\n\nCode\n```{r}\n###| coursework data\ncoursework &lt;- data.frame(\"cw\" = c(5,5,10,12,14,16),\n                         \"exam\" = c(38,45,69,65,75,96))\n```"
  }
]